{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: \n",
    "\n",
    "Approximating the non-linear data space that makes up a PyPSA simulation. Specifically, approximating a modified IEEE 13 bus topology with a uniform (grid) input. The approximation is time sensitive.\n",
    "\n",
    "**Objective**:\n",
    "\n",
    "This notebook will only look at [random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) (RF) models. Per [1], the approximation should have a root mean sqaure error < 0.002 to ensure the approximation is not the largest source of error in the simulation. A standard linear regression will also be calculated for baseline comparison. Since the approximation is time sensitive, a search for the ball park number of samples required for reasonable scores is performed. Once the number of samples to produce reasonable results is found, a grid search can be ran to determine optimal training parameters.\n",
    "\n",
    "**Hypothesis**: \n",
    "\n",
    "Previously, a linear regression model outperformed a non-linear model (artificial neural network) when tested on simple, small radial networks [2]. Since the modified IEEE 13 bus network contains two transformers whos behaviour can become non-linear if their power limit is exceeded (which is allowed in power flow [3]), I suspect there are two possible scenarios:\n",
    "\n",
    "1. Transformer limit not exceeded: Linear regression outperforms RF model\n",
    "2. Transformer limit exceeded: RF outperforms linear regressor because a RF model can capture non-linearity \n",
    "\n",
    "As for the number of samples required, historically 1e5-1e6 samples produces K-fold cross validation scores with low variance if the feature-label correlation is reasonable.\n",
    "\n",
    "**Experimental Procedure**:\n",
    "\n",
    "1. Determine the number of samples required to return reasonable scores with SVR K-fold cross validation. Reasonable scores is defined as:\n",
    "  * R2 > 0.8\n",
    "  * RMSE < 0.002\n",
    "  * K-fold R2 variance one degree of magnitude less than R2\n",
    "2. Using approximately that number of samples, run grid search to determine optimal parameters/hyperparameters\n",
    "\n",
    "**Results**:\n",
    "\n",
    "* 1e5 samples (mean R2: 0.85, std dev: 0.0005)\n",
    "* 1e4 samples (mean R2: 0.81, std dev: 0.005)\n",
    "\n",
    "Running a randomized grid search with 1e5 samples produced the following results:\n",
    "\n",
    "1. n_estimators: 99, max_depth: 73, mean training time: 226s (mean R2: 0.85 std dev: 0.0006)\n",
    "2. n_estimators: 89, max_depth: 62, mean training time: 208s (mean R2: 0.85 std dev: 0.0006)\n",
    "3. .\n",
    "4. .\n",
    "\n",
    "\n",
    "18. n_estimators: 24, max_depth: 68, mean training time: 54s (mean R2: 0.84 std dev: 0.001)\n",
    "19. n_estimators: 3, max_depth: 19, mean training time: 7s (mean R2: 0.77 std dev: 0.001)\n",
    "20. n_estimators: 36, max_depth: 9, mean training time: 55s (mean R2: 0.74 std dev: 0.002)\n",
    "\n",
    "**Discussion**:\n",
    "\n",
    "One approach to reduce the cost of simulation-based research is to copy the underlying model and evaluate the approximation [1][4].\n",
    "\n",
    "It takes roughly 7 hours to create 1e5 samples (by running PyPSA sim) on Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz\n",
    "\n",
    "\n",
    "**Bibliography**\n",
    "\n",
    "[1] https://github.com/mbardwell/masters\n",
    "\n",
    "[2] Enhancing Power Flow Simulations Using Function Mapping. Michael Bardwell ; Petr Musilek. 2019 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)\n",
    "\n",
    "[3] https://groups.google.com/forum/#!searchin/pypsa/mikey%7Csort:date/pypsa/FqfC_UR85k0/vBc7HYP_EQAJ\n",
    "\n",
    "[4] ieee-13_timing-pfsim-vs-evaluating-models.ipynb\n",
    "\n",
    "\n",
    "Table of Contents:\n",
    "* Source data\n",
    "* Analyse data\n",
    "* Setup models\n",
    "* Determine number of samples to get reasonable scores\n",
    "* Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypsa\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger = logging.getLogger(\"pypsa\")\n",
    "logger.setLevel(\"WARNING\")\n",
    "%matplotlib inline\n",
    "\n",
    "import copy\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import pypsa\n",
    "from n_dimensional_datasets import *\n",
    "from plotter import *\n",
    "\n",
    "from IPython.display import display # for better Pandas printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalise_column_names(df, name):\n",
    "        new_columns = []\n",
    "        for column in df.columns:\n",
    "            new_columns.append(name +  \"-\" + str(column))\n",
    "        df.columns = new_columns\n",
    "        return pd.DataFrame(df)\n",
    "\n",
    "def collect_data(path_to_powerflow_data, data):\n",
    "    '''\n",
    "    Assumes folder tree has\n",
    "    path_to_powerflow_data/\n",
    "    -->datafiles\n",
    "    -->results/\n",
    "    '''\n",
    "    data[\"loads\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"loads-p_set.csv\"), \"load\")\n",
    "    data[\"vmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"vmags.csv\"), \"vmag\")\n",
    "    data[\"vangs\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"vangs.csv\"), \"vang\")\n",
    "    data[\"qmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"qmags.csv\"), \"qmag\")\n",
    "    data[\"linemags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"linemags.csv\"), \"linemag\")\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "def set_gaussian_sample_size(path_to_powerflow_data, data_to_change, n_samples, seed=None):\n",
    "    '''\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_to_change: list of strings.\n",
    "        ex: [\"loads-p_set\", \"generators-p_max_pu\", \"snapshots\"] \n",
    "    '''\n",
    "    n_original_samples = 2 # sample_1 from IEEE-13 paper, sample_2=0.9*sample_1\n",
    "\n",
    "    data = {}\n",
    "    for datatype in data_to_change:\n",
    "        data[datatype] = pd.read_csv(path_to_powerflow_data + datatype + \".csv\")\n",
    "        \n",
    "\n",
    "    def increase_data(dataframe, n_samples, seed=None):\n",
    "        addon = {}\n",
    "        new_df_list = []\n",
    "        for idx, column in enumerate(dataframe):\n",
    "            if dataframe[column].dtype == np.float64 or dataframe[column].dtype == np.int64:  \n",
    "                addon[column] = np.abs(\n",
    "                    np.random.RandomState(seed=seed).normal(loc=dataframe[column][0:n_original_samples].mean(), \n",
    "                                                            scale=dataframe[column][0:n_original_samples].std(), \n",
    "                                                            size=n_samples))\n",
    "            elif dataframe[column].dtype == object:\n",
    "                # assuming object is datetime column\n",
    "                latest_datetime = pd.to_datetime(dataframe[column][n_original_samples-1])\n",
    "                addon[column] = []\n",
    "                for sample in range(n_samples):\n",
    "                    addon[column].append(latest_datetime + pd.Timedelta(hours=(1+sample)))\n",
    "            else:\n",
    "                raise TypeError(\"dataframe[column] type: {} should be object or float64/int64\".format(\n",
    "                    type(dataframe[column].dtype)))\n",
    "        addon_dataframe = pd.DataFrame(addon)\n",
    "        return dataframe.head(n_original_samples).append(addon_dataframe)            \n",
    "\n",
    "            \n",
    "    def cap_data(dataframe, min_value, max_value):\n",
    "        for column in dataframe:\n",
    "            if dataframe[column].dtype == np.float64 or dataframe[column].dtype == np.int64:\n",
    "                for i, val in enumerate(dataframe[column]):\n",
    "                    if val > max_value:\n",
    "                        dataframe[column][i] = max_value\n",
    "                    elif val < min_value:\n",
    "                        dataframe[column][i] = min_value\n",
    "        return dataframe\n",
    "    \n",
    "\n",
    "    if n_samples > n_original_samples:\n",
    "        for datatype in data:\n",
    "            data[datatype] = increase_data(data[datatype], n_samples-n_original_samples, seed)\n",
    "            if datatype == \"generators-p_max_pu\":\n",
    "                data[datatype] = cap_data(data[datatype], 0, 1)\n",
    "        \n",
    "    for datatype in data:\n",
    "        data[datatype].to_csv(path_to_powerflow_data + datatype + \".csv\", index=False)\n",
    "        print(\"Datatype {} stored\".format(datatype))\n",
    "\n",
    "def create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None):\n",
    "    import os\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "    import pypsa\n",
    "\n",
    "    if not os.path.isdir(path_to_powerflow_data):\n",
    "        src = Path(path_to_powerflow_data).parents[0] / \"ieee-13-with-load-gen/\" # original modified IEEE model\n",
    "        shutil.copytree(src, path_to_powerflow_data)\n",
    "\n",
    "    set_gaussian_sample_size(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "\n",
    "    network = pypsa.Network(import_name=path_to_powerflow_data)\n",
    "    network.pf()\n",
    "\n",
    "    save_path = path_to_powerflow_data + \"results/\"\n",
    "    network.buses_t.v_mag_pu.to_csv(save_path + \"vmags.csv\")\n",
    "    network.buses_t.v_ang.to_csv(save_path + \"vangs.csv\")\n",
    "    network.buses_t.q.to_csv(save_path + \"qmags.csv\")\n",
    "    network.lines_t.p0.to_csv(save_path + \"linemags.csv\")\n",
    "    \n",
    "def backup_samples(src, dest):\n",
    "    '''\n",
    "    thanks https://www.pythoncentral.io/how-to-recursively-copy-a-directory-folder-in-python/\n",
    "    '''\n",
    "    import os\n",
    "    import errno\n",
    "    import shutil\n",
    "    \n",
    "    try:\n",
    "        if os.path.isdir(dest):\n",
    "            shutil.rmtree(dest)\n",
    "        shutil.copytree(src, dest)\n",
    "        print(\"Backup to {} successful\".format(dest))\n",
    "    except OSError as e:\n",
    "        # If the error was caused because the source wasn't a directory\n",
    "        if e.errno == errno.ENOTDIR:\n",
    "            shutil.copy(src, dest)\n",
    "        else:\n",
    "            print('Directory not copied. Error: %s' % e)                          + str(sample_size) +\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER INPUT\n",
    "sample_size = 100000 # this is the max number of samples available\n",
    "\n",
    "data_to_change = [\"loads-p_set\", \"snapshots\", \"loads-q_set\"]\n",
    "\n",
    "path_to_powerflow_example = \"../../pypsa/examples/ieee-13/\"\n",
    "path_to_powerflow_data = (path_to_powerflow_example +\n",
    "                          \"/ieee-13-with-load-gen-gaussian-data-\"\n",
    "                          + str(sample_size) +\n",
    "                          \"-samples/\")\n",
    "path_to_powerflow_results = path_to_powerflow_data + \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure [y/n]? This could erase hours worth of datay\n",
      "Directory not copied. Error: [Errno 2] No such file or directory: '../../pypsa/examples/ieee-13//ieee-13-with-load-gen-gaussian-data-100000-samples/results/'\n",
      "Datatype loads-p_set stored\n",
      "Datatype snapshots stored\n",
      "Datatype loads-q_set stored\n"
     ]
    }
   ],
   "source": [
    "## Uncomment to generate load samples for modified IEEE-13 network\n",
    "if sample_size > 10000:\n",
    "    user = input(\"Are you sure [y/n]? This could erase hours worth of data\")\n",
    "    if user == \"y\":\n",
    "        backup_samples(path_to_powerflow_results, path_to_powerflow_data + \"results-backup/\")\n",
    "        create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "else:\n",
    "    create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "\n",
    "data = {\"loads\": [], \"vmags\": [], \"vangs\": [], \"qmags\": [], \"linemags\": []}\n",
    "collect_data(path_to_powerflow_data, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[\"loads\"].drop(\"load-name\", axis=1)\n",
    "labels = data[\"vmags\"].drop([\"vmag-name\", \"vmag-Substation\"], axis=1) #loc[:,[\"vmag-632\", \"vmag-671\", \"vmag-675\"]]\n",
    "features_and_labels = features.join(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc8b0dd90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7312150>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7306590>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7251a10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7fe5d10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7f9a790>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7f95a90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7f0a750>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7f0a650>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7cc3810>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7d2d090>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7cab890>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7c53750>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7c1d910>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7bc8750>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7b7e3d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7b3d790>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7b50110>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7b10610>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7afc950>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7aa7810>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7a73990>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7a1d850>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc79e89d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3bc7992890>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load-632</th>\n",
       "      <th>load-634</th>\n",
       "      <th>load-645</th>\n",
       "      <th>load-646</th>\n",
       "      <th>load-652</th>\n",
       "      <th>load-671</th>\n",
       "      <th>load-675</th>\n",
       "      <th>load-692</th>\n",
       "      <th>load-611</th>\n",
       "      <th>row average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>vmag-650</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>-0.134912</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0.012292</td>\n",
       "      <td>-0.091244</td>\n",
       "      <td>-0.137399</td>\n",
       "      <td>-0.111013</td>\n",
       "      <td>-0.050161</td>\n",
       "      <td>-0.019930</td>\n",
       "      <td>-0.056731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-646</td>\n",
       "      <td>-0.075102</td>\n",
       "      <td>-0.243435</td>\n",
       "      <td>-0.153393</td>\n",
       "      <td>-0.297267</td>\n",
       "      <td>-0.142804</td>\n",
       "      <td>-0.563048</td>\n",
       "      <td>-0.421137</td>\n",
       "      <td>-0.099218</td>\n",
       "      <td>-0.098410</td>\n",
       "      <td>-0.232646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-645</td>\n",
       "      <td>-0.078678</td>\n",
       "      <td>-0.245490</td>\n",
       "      <td>-0.155140</td>\n",
       "      <td>-0.228137</td>\n",
       "      <td>-0.143392</td>\n",
       "      <td>-0.574592</td>\n",
       "      <td>-0.427127</td>\n",
       "      <td>-0.102543</td>\n",
       "      <td>-0.100118</td>\n",
       "      <td>-0.228357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-632</td>\n",
       "      <td>-0.079974</td>\n",
       "      <td>-0.249377</td>\n",
       "      <td>-0.058542</td>\n",
       "      <td>-0.102455</td>\n",
       "      <td>-0.148531</td>\n",
       "      <td>-0.596171</td>\n",
       "      <td>-0.437501</td>\n",
       "      <td>-0.108841</td>\n",
       "      <td>-0.099245</td>\n",
       "      <td>-0.208960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-633</td>\n",
       "      <td>-0.077283</td>\n",
       "      <td>-0.356019</td>\n",
       "      <td>-0.055181</td>\n",
       "      <td>-0.102521</td>\n",
       "      <td>-0.144726</td>\n",
       "      <td>-0.577364</td>\n",
       "      <td>-0.419764</td>\n",
       "      <td>-0.102999</td>\n",
       "      <td>-0.093009</td>\n",
       "      <td>-0.214319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-634</td>\n",
       "      <td>-0.010840</td>\n",
       "      <td>-0.276802</td>\n",
       "      <td>-0.009663</td>\n",
       "      <td>-0.029756</td>\n",
       "      <td>-0.064641</td>\n",
       "      <td>-0.274859</td>\n",
       "      <td>-0.206299</td>\n",
       "      <td>-0.061779</td>\n",
       "      <td>-0.008524</td>\n",
       "      <td>-0.104796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-611</td>\n",
       "      <td>-0.054882</td>\n",
       "      <td>-0.166390</td>\n",
       "      <td>-0.033259</td>\n",
       "      <td>-0.074525</td>\n",
       "      <td>-0.177280</td>\n",
       "      <td>-0.693963</td>\n",
       "      <td>-0.507999</td>\n",
       "      <td>-0.122130</td>\n",
       "      <td>-0.192113</td>\n",
       "      <td>-0.224727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-684</td>\n",
       "      <td>-0.056175</td>\n",
       "      <td>-0.168136</td>\n",
       "      <td>-0.032136</td>\n",
       "      <td>-0.074845</td>\n",
       "      <td>-0.179226</td>\n",
       "      <td>-0.697899</td>\n",
       "      <td>-0.510811</td>\n",
       "      <td>-0.122561</td>\n",
       "      <td>-0.155550</td>\n",
       "      <td>-0.221927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-671</td>\n",
       "      <td>-0.056743</td>\n",
       "      <td>-0.170133</td>\n",
       "      <td>-0.032302</td>\n",
       "      <td>-0.074533</td>\n",
       "      <td>-0.153910</td>\n",
       "      <td>-0.702383</td>\n",
       "      <td>-0.515142</td>\n",
       "      <td>-0.123008</td>\n",
       "      <td>-0.119938</td>\n",
       "      <td>-0.216455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-692</td>\n",
       "      <td>-0.056730</td>\n",
       "      <td>-0.170106</td>\n",
       "      <td>-0.032296</td>\n",
       "      <td>-0.074529</td>\n",
       "      <td>-0.153892</td>\n",
       "      <td>-0.702288</td>\n",
       "      <td>-0.515314</td>\n",
       "      <td>-0.123044</td>\n",
       "      <td>-0.119927</td>\n",
       "      <td>-0.216459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-675</td>\n",
       "      <td>-0.050391</td>\n",
       "      <td>-0.157788</td>\n",
       "      <td>-0.029869</td>\n",
       "      <td>-0.073219</td>\n",
       "      <td>-0.145090</td>\n",
       "      <td>-0.656845</td>\n",
       "      <td>-0.593762</td>\n",
       "      <td>-0.118496</td>\n",
       "      <td>-0.114721</td>\n",
       "      <td>-0.215576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-652</td>\n",
       "      <td>-0.057504</td>\n",
       "      <td>-0.166609</td>\n",
       "      <td>-0.029002</td>\n",
       "      <td>-0.075841</td>\n",
       "      <td>-0.240259</td>\n",
       "      <td>-0.692607</td>\n",
       "      <td>-0.504392</td>\n",
       "      <td>-0.121807</td>\n",
       "      <td>-0.151990</td>\n",
       "      <td>-0.226668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-680</td>\n",
       "      <td>-0.056743</td>\n",
       "      <td>-0.170133</td>\n",
       "      <td>-0.032302</td>\n",
       "      <td>-0.074533</td>\n",
       "      <td>-0.153910</td>\n",
       "      <td>-0.702383</td>\n",
       "      <td>-0.515142</td>\n",
       "      <td>-0.123008</td>\n",
       "      <td>-0.119938</td>\n",
       "      <td>-0.216455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>column average</td>\n",
       "      <td>-0.053724</td>\n",
       "      <td>-0.205795</td>\n",
       "      <td>-0.049534</td>\n",
       "      <td>-0.097682</td>\n",
       "      <td>-0.149146</td>\n",
       "      <td>-0.582446</td>\n",
       "      <td>-0.437339</td>\n",
       "      <td>-0.106123</td>\n",
       "      <td>-0.107186</td>\n",
       "      <td>-0.198775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                load-632  load-634  load-645  load-646  load-652  load-671  \\\n",
       "vmag-650        0.012636 -0.134912  0.009150  0.012292 -0.091244 -0.137399   \n",
       "vmag-646       -0.075102 -0.243435 -0.153393 -0.297267 -0.142804 -0.563048   \n",
       "vmag-645       -0.078678 -0.245490 -0.155140 -0.228137 -0.143392 -0.574592   \n",
       "vmag-632       -0.079974 -0.249377 -0.058542 -0.102455 -0.148531 -0.596171   \n",
       "vmag-633       -0.077283 -0.356019 -0.055181 -0.102521 -0.144726 -0.577364   \n",
       "vmag-634       -0.010840 -0.276802 -0.009663 -0.029756 -0.064641 -0.274859   \n",
       "vmag-611       -0.054882 -0.166390 -0.033259 -0.074525 -0.177280 -0.693963   \n",
       "vmag-684       -0.056175 -0.168136 -0.032136 -0.074845 -0.179226 -0.697899   \n",
       "vmag-671       -0.056743 -0.170133 -0.032302 -0.074533 -0.153910 -0.702383   \n",
       "vmag-692       -0.056730 -0.170106 -0.032296 -0.074529 -0.153892 -0.702288   \n",
       "vmag-675       -0.050391 -0.157788 -0.029869 -0.073219 -0.145090 -0.656845   \n",
       "vmag-652       -0.057504 -0.166609 -0.029002 -0.075841 -0.240259 -0.692607   \n",
       "vmag-680       -0.056743 -0.170133 -0.032302 -0.074533 -0.153910 -0.702383   \n",
       "column average -0.053724 -0.205795 -0.049534 -0.097682 -0.149146 -0.582446   \n",
       "\n",
       "                load-675  load-692  load-611  row average  \n",
       "vmag-650       -0.111013 -0.050161 -0.019930    -0.056731  \n",
       "vmag-646       -0.421137 -0.099218 -0.098410    -0.232646  \n",
       "vmag-645       -0.427127 -0.102543 -0.100118    -0.228357  \n",
       "vmag-632       -0.437501 -0.108841 -0.099245    -0.208960  \n",
       "vmag-633       -0.419764 -0.102999 -0.093009    -0.214319  \n",
       "vmag-634       -0.206299 -0.061779 -0.008524    -0.104796  \n",
       "vmag-611       -0.507999 -0.122130 -0.192113    -0.224727  \n",
       "vmag-684       -0.510811 -0.122561 -0.155550    -0.221927  \n",
       "vmag-671       -0.515142 -0.123008 -0.119938    -0.216455  \n",
       "vmag-692       -0.515314 -0.123044 -0.119927    -0.216459  \n",
       "vmag-675       -0.593762 -0.118496 -0.114721    -0.215576  \n",
       "vmag-652       -0.504392 -0.121807 -0.151990    -0.226668  \n",
       "vmag-680       -0.515142 -0.123008 -0.119938    -0.216455  \n",
       "column average -0.437339 -0.106123 -0.107186    -0.198775  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = labels.join(features).corr()\n",
    "\n",
    "# only loads for columns\n",
    "cols = [c for i, c in enumerate(corr_matrix.columns) if corr_matrix.keys().str.contains(\"^load\", regex=True)[i]]\n",
    "reduced_corr_matrix = corr_matrix[cols]\n",
    "reduced_corr_matrix[\"row average\"] = pd.Series(reduced_corr_matrix.mean(axis=1))\n",
    "# only voltages for rows\n",
    "rows = reduced_corr_matrix.index[reduced_corr_matrix.index.str.contains(\"load\")]\n",
    "reduced_corr_matrix.drop(rows, inplace=True)\n",
    "reduced_corr_matrix = reduced_corr_matrix.append(pd.Series(reduced_corr_matrix.mean(), name=\"column average\"))\n",
    "\n",
    "display(reduced_corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from scoring import rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def set_data_size(n_samples, n_training_samples):\n",
    "    X_train, X_val, y_train, y_val, test_idx, train_idx = train_test_split(features,\n",
    "                                                                           labels,\n",
    "                                                                           range(features.shape[0]),\n",
    "                                                                           train_size=n_training_samples,\n",
    "                                                                           test_size=n_samples-n_training_samples,\n",
    "                                                                           random_state=None)\n",
    "    X_train = X_train.values\n",
    "    y_train = y_train.values\n",
    "    X_val = X_val.values\n",
    "    y_val = y_val.values\n",
    "\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine number of samples to get reasonable scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model parameters/hyperparameters\n",
    "\n",
    "'''\n",
    "dnn hyperparameters are chosen from sandbox testing. On average the model attempts to converge \n",
    "(with other parameters it sometimes gives up early).\n",
    "'''\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=None)\n",
    "\n",
    "linear = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Run:  0\n",
      "n_training_samples:  80\n",
      "n_validation_samples:  20\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF\n",
      "\n",
      "\n",
      "cross validation training time 1.3524\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.110896</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.495420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.109646</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>0.444909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.105972</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.554424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.115606</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.485012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.130301</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.659086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf_fit_time  rf_score_time  rf_test_score\n",
       "0     0.110896       0.006425       0.495420\n",
       "1     0.109646       0.007320       0.444909\n",
       "2     0.105972       0.006288       0.554424\n",
       "3     0.115606       0.007122       0.485012\n",
       "4     0.130301       0.008294       0.659086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.9339916186598655\n",
      "validation score:  0.344923767761198\n",
      "rmse:  0.0071490201286817925\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.049087\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.036883</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.867815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.035001</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.877943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.874488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.818003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.909008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   linear_fit_time  linear_score_time  linear_test_score\n",
       "0         0.036883           0.000584           0.867815\n",
       "1         0.035001           0.000624           0.877943\n",
       "2         0.001012           0.000586           0.874488\n",
       "3         0.000860           0.000523           0.818003\n",
       "4         0.000769           0.000701           0.909008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.9163827658436261\n",
      "validation score:  0.8995918741505837\n",
      "rmse:  0.0014528532309112843\n",
      "\n",
      "\n",
      "Run:  1\n",
      "n_training_samples:  800\n",
      "n_validation_samples:  200\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF\n",
      "\n",
      "\n",
      "cross validation training time 1.8951\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.720907</td>\n",
       "      <td>0.010676</td>\n",
       "      <td>0.727136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.610899</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.702023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.628827</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.741247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.602864</td>\n",
       "      <td>0.012140</td>\n",
       "      <td>0.670512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.596581</td>\n",
       "      <td>0.009748</td>\n",
       "      <td>0.717082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf_fit_time  rf_score_time  rf_test_score\n",
       "0     0.720907       0.010676       0.727136\n",
       "1     0.610899       0.010670       0.702023\n",
       "2     0.628827       0.011750       0.741247\n",
       "3     0.602864       0.012140       0.670512\n",
       "4     0.596581       0.009748       0.717082"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.9609072831786946\n",
      "validation score:  0.7323838860566172\n",
      "rmse:  0.0043356551744515425\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.017804\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.905695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.901053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.902635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.906900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.905400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   linear_fit_time  linear_score_time  linear_test_score\n",
       "0         0.003929           0.000908           0.905695\n",
       "1         0.001454           0.000454           0.901053\n",
       "2         0.001023           0.000425           0.902635\n",
       "3         0.001023           0.000426           0.906900\n",
       "4         0.000993           0.000448           0.905400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.907537607780207\n",
      "validation score:  0.8989295617735344\n",
      "rmse:  0.0015184944621667296\n",
      "\n",
      "\n",
      "Run:  2\n",
      "n_training_samples:  8000\n",
      "n_validation_samples:  2000\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF\n",
      "\n",
      "\n",
      "cross validation training time 22.981\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.588874</td>\n",
       "      <td>0.066067</td>\n",
       "      <td>0.799829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.597608</td>\n",
       "      <td>0.093956</td>\n",
       "      <td>0.804329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.594231</td>\n",
       "      <td>0.067965</td>\n",
       "      <td>0.804885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.420056</td>\n",
       "      <td>0.078523</td>\n",
       "      <td>0.811381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.639505</td>\n",
       "      <td>0.066204</td>\n",
       "      <td>0.807828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf_fit_time  rf_score_time  rf_test_score\n",
       "0     7.588874       0.066067       0.799829\n",
       "1     7.597608       0.093956       0.804329\n",
       "2     7.594231       0.067965       0.804885\n",
       "3     7.420056       0.078523       0.811381\n",
       "4     7.639505       0.066204       0.807828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.9731189517099799\n",
      "validation score:  0.8098179673664383\n",
      "rmse:  0.0034043066464187256\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.051679\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.905314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.906182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.903689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.905873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.905444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   linear_fit_time  linear_score_time  linear_test_score\n",
       "0         0.006047           0.001056           0.905314\n",
       "1         0.006931           0.001021           0.906182\n",
       "2         0.004909           0.000984           0.903689\n",
       "3         0.004776           0.000963           0.905873\n",
       "4         0.004795           0.000962           0.905444"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.9056681800512134\n",
      "validation score:  0.9057412338069443\n",
      "rmse:  0.0013931534879083958\n",
      "\n",
      "\n",
      "Run:  3\n",
      "n_training_samples:  80000\n",
      "n_validation_samples:  20000\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7cd75ecf2ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                          \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                          \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                          scoring=make_scorer(r2_score)))\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtime_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cross validation training time {:.5}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_rf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sim-approx/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 231\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sim-approx/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sim-approx/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sim-approx/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sim-approx/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sim-approx/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cell works, may just be commented out because it is an expensive process and user can just skip to grid search\n",
    "rf_xval_scores = []\n",
    "linear_xval_scores = []\n",
    "for i, n_samples in enumerate([100, 1000, 10000, 100000]):\n",
    "    current_iteration = i\n",
    "\n",
    "    n_training_samples = int(n_samples*(80/100))\n",
    "    X_train, y_train, X_val, y_val = set_data_size(n_samples, n_training_samples)\n",
    "\n",
    "    print(\"\\n\\nRun: \", current_iteration)\n",
    "    print(\"n_training_samples: \", n_training_samples)\n",
    "    print(\"n_validation_samples: \", n_samples-n_training_samples)\n",
    "    print(\"n_features: \", X_train.shape[1])\n",
    "    print(\"n_labels: \", y_train.shape[1])\n",
    "\n",
    "    ## rf\n",
    "    print(\"\\n\\nRF\\n\\n\")\n",
    "    time_start = time.time()\n",
    "    rf_xval_scores.append(cross_validate(rf, \n",
    "                                         X_train, \n",
    "                                         y_train, \n",
    "                                         cv=5, \n",
    "                                         n_jobs=-1, \n",
    "                                         scoring=make_scorer(r2_score)))\n",
    "    time_rf = time.time()\n",
    "    print(\"cross validation training time {:.5}\".format(time_rf-time_start))\n",
    "    print(\"cross validation training scores: \")\n",
    "    rf_results = pd.DataFrame(rf_xval_scores[current_iteration])\n",
    "    rf_results.columns = [\"rf_\"+col for col in rf_results.columns]   \n",
    "    display(rf_results)\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"non-cross validation model scores for reference:\")\n",
    "    print(\"training score: \", r2_score(y_train, rf.predict(X_train)))\n",
    "    print(\"validation score: \", r2_score(y_val, rf.predict(X_val)))\n",
    "    print(\"rmse: \", rmse(rf.predict(X_val), y_val))\n",
    "\n",
    "\n",
    "\n",
    "    ## linear regression\n",
    "    print(\"\\n\\nLINEAR REGRESSION\\n\\n\")\n",
    "    time_start = time.time()\n",
    "    linear_xval_scores.append(cross_validate(linear,\n",
    "                                             X_train,\n",
    "                                             y_train,\n",
    "                                             cv=5,\n",
    "                                             n_jobs=-1,\n",
    "                                             scoring=make_scorer(r2_score)))\n",
    "\n",
    "    time_linear = time.time()\n",
    "    print(\"cross validation training time {:.5}\".format(time_linear-time_start))\n",
    "    print(\"cross validation training scores: \")\n",
    "    linear_results = pd.DataFrame(linear_xval_scores[current_iteration])\n",
    "    linear_results.columns = [\"linear_\"+col for col in linear_results.columns]\n",
    "    display(linear_results)\n",
    "\n",
    "    linear.fit(X_train, y_train)\n",
    "    print(\"non-cross validation model scores for reference:\")\n",
    "    print(\"training score: \", r2_score(y_train, linear.predict(X_train)))\n",
    "    print(\"validation score: \", r2_score(y_val, linear.predict(X_val)))\n",
    "    print(\"rmse: \", rmse(linear.predict(X_val), y_val))\n",
    "\n",
    "    ## model statistics\n",
    "    datetimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "    results_to_save = rf_results.join(linear_results).round(3)\n",
    "    results_to_save.to_csv(path_to_powerflow_data + \n",
    "                           \"/results/approximating_with_rf_results-{}_samples-{}.csv\".format(n_samples, \n",
    "                                                                                             datetimestamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100000\n",
    "if n_samples < 100000:\n",
    "    raise ValueError(\"So you don't accidentally run this on 100 samples again\")\n",
    "n_training_samples = int(n_samples*(80/100))\n",
    "X_train, y_train, X_val, y_val = set_data_size(n_samples, n_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "params = {\"n_estimators\": range(100), \n",
    "          \"max_depth\": [None]+[i for i in range(1, 100)]}\n",
    "grid = RandomizedSearchCV(rf, params, cv=5, n_iter=20, n_jobs=-1, refit=False,\n",
    "                          scoring={\"r2\": make_scorer(r2_score), \"rmse\": make_scorer(rmse)}, iid=False, verbose=10)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\\nRF\\n\\n\")\n",
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "display(grid_results.sort_values(by=[\"rank_test_r2\"]))\n",
    "datetimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "filepath = (path_to_powerflow_data + \n",
    "            \"/results/approximating_with_rf_grid_results-{}_samples-{}.csv\".format(n_samples, datetimestamp))\n",
    "print(\"Saving to \", filepath)\n",
    "grid_results.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for reading values if you closed the notebook\n",
    "imported_results = pd.read_csv(filepath)\n",
    "display(imported_results.sort_values(by=[\"rank_test_r2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search after removing bad label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100000\n",
    "if n_samples < 100000:\n",
    "    raise ValueError(\"So you don't accidentally run this on 100 samples again\")\n",
    "n_training_samples = int(n_samples*(80/100))\n",
    "X_train, y_train, X_val, y_val = set_data_size(n_samples, n_training_samples)\n",
    "# remove bad label\n",
    "y_train = y_train.T[1:].T\n",
    "y_val = y_val.T[1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  6.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RF\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_r2</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>66.531391</td>\n",
       "      <td>0.622077</td>\n",
       "      <td>2.545954</td>\n",
       "      <td>0.086762</td>\n",
       "      <td>80</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_estimators': 80, 'max_depth': 29}</td>\n",
       "      <td>0.921858</td>\n",
       "      <td>0.922751</td>\n",
       "      <td>0.922099</td>\n",
       "      <td>0.922236</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>59.921115</td>\n",
       "      <td>0.734938</td>\n",
       "      <td>2.203448</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>72</td>\n",
       "      <td>98</td>\n",
       "      <td>{'n_estimators': 72, 'max_depth': 98}</td>\n",
       "      <td>0.921811</td>\n",
       "      <td>0.921741</td>\n",
       "      <td>0.921164</td>\n",
       "      <td>0.921572</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>52.694661</td>\n",
       "      <td>0.098162</td>\n",
       "      <td>2.040517</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>{'n_estimators': 64, 'max_depth': 33}</td>\n",
       "      <td>0.921495</td>\n",
       "      <td>0.921932</td>\n",
       "      <td>0.921088</td>\n",
       "      <td>0.921505</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>42.708556</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>1.667782</td>\n",
       "      <td>0.055191</td>\n",
       "      <td>52</td>\n",
       "      <td>71</td>\n",
       "      <td>{'n_estimators': 52, 'max_depth': 71}</td>\n",
       "      <td>0.920678</td>\n",
       "      <td>0.921160</td>\n",
       "      <td>0.921027</td>\n",
       "      <td>0.920955</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>49.611883</td>\n",
       "      <td>0.197651</td>\n",
       "      <td>1.920520</td>\n",
       "      <td>0.055440</td>\n",
       "      <td>60</td>\n",
       "      <td>93</td>\n",
       "      <td>{'n_estimators': 60, 'max_depth': 93}</td>\n",
       "      <td>0.920492</td>\n",
       "      <td>0.921506</td>\n",
       "      <td>0.920086</td>\n",
       "      <td>0.920695</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32.702112</td>\n",
       "      <td>0.183965</td>\n",
       "      <td>1.336063</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>{'n_estimators': 40, 'max_depth': 74}</td>\n",
       "      <td>0.918704</td>\n",
       "      <td>0.919897</td>\n",
       "      <td>0.919109</td>\n",
       "      <td>0.919237</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.698034</td>\n",
       "      <td>0.078871</td>\n",
       "      <td>0.903889</td>\n",
       "      <td>0.030214</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>{'n_estimators': 25, 'max_depth': 73}</td>\n",
       "      <td>0.915674</td>\n",
       "      <td>0.917252</td>\n",
       "      <td>0.916619</td>\n",
       "      <td>0.916515</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.139486</td>\n",
       "      <td>0.097723</td>\n",
       "      <td>0.843532</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 66}</td>\n",
       "      <td>0.915774</td>\n",
       "      <td>0.915434</td>\n",
       "      <td>0.915281</td>\n",
       "      <td>0.915496</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.422979</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.468810</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>{'n_estimators': 10, 'max_depth': 48}</td>\n",
       "      <td>0.903202</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>0.903273</td>\n",
       "      <td>0.903725</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>9</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.304425</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.322273</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 4}</td>\n",
       "      <td>0.475762</td>\n",
       "      <td>0.463664</td>\n",
       "      <td>0.459374</td>\n",
       "      <td>0.466267</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>10</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      66.531391      0.622077         2.545954        0.086762   \n",
       "5      59.921115      0.734938         2.203448        0.029155   \n",
       "7      52.694661      0.098162         2.040517        0.075283   \n",
       "9      42.708556      0.272464         1.667782        0.055191   \n",
       "6      49.611883      0.197651         1.920520        0.055440   \n",
       "4      32.702112      0.183965         1.336063        0.059603   \n",
       "1      20.698034      0.078871         0.903889        0.030214   \n",
       "2      19.139486      0.097723         0.843532        0.018133   \n",
       "3       8.422979      0.240346         0.468810        0.022842   \n",
       "8       6.304425      0.014633         0.322273        0.010596   \n",
       "\n",
       "  param_n_estimators param_max_depth                                 params  \\\n",
       "0                 80              29  {'n_estimators': 80, 'max_depth': 29}   \n",
       "5                 72              98  {'n_estimators': 72, 'max_depth': 98}   \n",
       "7                 64              33  {'n_estimators': 64, 'max_depth': 33}   \n",
       "9                 52              71  {'n_estimators': 52, 'max_depth': 71}   \n",
       "6                 60              93  {'n_estimators': 60, 'max_depth': 93}   \n",
       "4                 40              74  {'n_estimators': 40, 'max_depth': 74}   \n",
       "1                 25              73  {'n_estimators': 25, 'max_depth': 73}   \n",
       "2                 23              66  {'n_estimators': 23, 'max_depth': 66}   \n",
       "3                 10              48  {'n_estimators': 10, 'max_depth': 48}   \n",
       "8                 23               4   {'n_estimators': 23, 'max_depth': 4}   \n",
       "\n",
       "   split0_test_r2  split1_test_r2  split2_test_r2  mean_test_r2  std_test_r2  \\\n",
       "0        0.921858        0.922751        0.922099      0.922236     0.000377   \n",
       "5        0.921811        0.921741        0.921164      0.921572     0.000290   \n",
       "7        0.921495        0.921932        0.921088      0.921505     0.000345   \n",
       "9        0.920678        0.921160        0.921027      0.920955     0.000203   \n",
       "6        0.920492        0.921506        0.920086      0.920695     0.000597   \n",
       "4        0.918704        0.919897        0.919109      0.919237     0.000495   \n",
       "1        0.915674        0.917252        0.916619      0.916515     0.000648   \n",
       "2        0.915774        0.915434        0.915281      0.915496     0.000206   \n",
       "3        0.903202        0.904700        0.903273      0.903725     0.000690   \n",
       "8        0.475762        0.463664        0.459374      0.466267     0.006939   \n",
       "\n",
       "   rank_test_r2  split0_test_rmse  split1_test_rmse  split2_test_rmse  \\\n",
       "0             1          0.002894          0.002883          0.002889   \n",
       "5             2          0.002894          0.002901          0.002907   \n",
       "7             3          0.002899          0.002897          0.002909   \n",
       "9             4          0.002914          0.002911          0.002911   \n",
       "6             5          0.002919          0.002905          0.002928   \n",
       "4             6          0.002951          0.002934          0.002942   \n",
       "1             7          0.003008          0.002984          0.002990   \n",
       "2             8          0.003007          0.003020          0.003011   \n",
       "3             9          0.003218          0.003203          0.003221   \n",
       "8            10          0.007396          0.007507          0.007516   \n",
       "\n",
       "   mean_test_rmse  std_test_rmse  rank_test_rmse  \n",
       "0        0.002889       0.000004              10  \n",
       "5        0.002901       0.000005               9  \n",
       "7        0.002902       0.000005               8  \n",
       "9        0.002912       0.000001               7  \n",
       "6        0.002917       0.000009               6  \n",
       "4        0.002942       0.000007               5  \n",
       "1        0.002994       0.000010               4  \n",
       "2        0.003013       0.000005               3  \n",
       "3        0.003214       0.000008               2  \n",
       "8        0.007473       0.000054               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to  ../../pypsa/examples/ieee-13//ieee-13-with-load-gen-uniform-data-100000-samples//results/approximating_with_rf_grid_results-100000_samples-2019-09-13-07-25.csv\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "params = {\"n_estimators\": range(100), \n",
    "          \"max_depth\": [None]+[i for i in range(1, 100)]}\n",
    "grid = RandomizedSearchCV(rf, params, cv=3, n_iter=10, n_jobs=-1, refit=False,\n",
    "                          scoring={\"r2\": make_scorer(r2_score), \"rmse\": make_scorer(rmse)}, iid=False, verbose=10)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\\nRF\\n\\n\")\n",
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "display(grid_results.sort_values(by=[\"rank_test_r2\"]))\n",
    "datetimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "filepath = (path_to_powerflow_data + \n",
    "            \"/results/approximating_with_rf_grid_results-{}_samples-{}.csv\".format(n_samples, datetimestamp))\n",
    "print(\"Saving to \", filepath)\n",
    "grid_results.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_r2</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.531391</td>\n",
       "      <td>0.622077</td>\n",
       "      <td>2.545954</td>\n",
       "      <td>0.086762</td>\n",
       "      <td>80</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_estimators': 80, 'max_depth': 29}</td>\n",
       "      <td>0.921858</td>\n",
       "      <td>0.922751</td>\n",
       "      <td>0.922099</td>\n",
       "      <td>0.922236</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>59.921115</td>\n",
       "      <td>0.734938</td>\n",
       "      <td>2.203448</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>72</td>\n",
       "      <td>98</td>\n",
       "      <td>{'n_estimators': 72, 'max_depth': 98}</td>\n",
       "      <td>0.921811</td>\n",
       "      <td>0.921741</td>\n",
       "      <td>0.921164</td>\n",
       "      <td>0.921572</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>52.694661</td>\n",
       "      <td>0.098162</td>\n",
       "      <td>2.040517</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>{'n_estimators': 64, 'max_depth': 33}</td>\n",
       "      <td>0.921495</td>\n",
       "      <td>0.921932</td>\n",
       "      <td>0.921088</td>\n",
       "      <td>0.921505</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>42.708556</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>1.667782</td>\n",
       "      <td>0.055191</td>\n",
       "      <td>52</td>\n",
       "      <td>71</td>\n",
       "      <td>{'n_estimators': 52, 'max_depth': 71}</td>\n",
       "      <td>0.920678</td>\n",
       "      <td>0.921160</td>\n",
       "      <td>0.921027</td>\n",
       "      <td>0.920955</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>49.611883</td>\n",
       "      <td>0.197651</td>\n",
       "      <td>1.920520</td>\n",
       "      <td>0.055440</td>\n",
       "      <td>60</td>\n",
       "      <td>93</td>\n",
       "      <td>{'n_estimators': 60, 'max_depth': 93}</td>\n",
       "      <td>0.920492</td>\n",
       "      <td>0.921506</td>\n",
       "      <td>0.920086</td>\n",
       "      <td>0.920695</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32.702112</td>\n",
       "      <td>0.183965</td>\n",
       "      <td>1.336063</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>{'n_estimators': 40, 'max_depth': 74}</td>\n",
       "      <td>0.918704</td>\n",
       "      <td>0.919897</td>\n",
       "      <td>0.919109</td>\n",
       "      <td>0.919237</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.698034</td>\n",
       "      <td>0.078871</td>\n",
       "      <td>0.903889</td>\n",
       "      <td>0.030214</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>{'n_estimators': 25, 'max_depth': 73}</td>\n",
       "      <td>0.915674</td>\n",
       "      <td>0.917252</td>\n",
       "      <td>0.916619</td>\n",
       "      <td>0.916515</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19.139486</td>\n",
       "      <td>0.097723</td>\n",
       "      <td>0.843532</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 66}</td>\n",
       "      <td>0.915774</td>\n",
       "      <td>0.915434</td>\n",
       "      <td>0.915281</td>\n",
       "      <td>0.915496</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8.422979</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.468810</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>{'n_estimators': 10, 'max_depth': 48}</td>\n",
       "      <td>0.903202</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>0.903273</td>\n",
       "      <td>0.903725</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>9</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6.304425</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.322273</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 4}</td>\n",
       "      <td>0.475762</td>\n",
       "      <td>0.463664</td>\n",
       "      <td>0.459374</td>\n",
       "      <td>0.466267</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>10</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0      66.531391      0.622077         2.545954        0.086762   \n",
       "5           5      59.921115      0.734938         2.203448        0.029155   \n",
       "7           7      52.694661      0.098162         2.040517        0.075283   \n",
       "9           9      42.708556      0.272464         1.667782        0.055191   \n",
       "6           6      49.611883      0.197651         1.920520        0.055440   \n",
       "4           4      32.702112      0.183965         1.336063        0.059603   \n",
       "1           1      20.698034      0.078871         0.903889        0.030214   \n",
       "2           2      19.139486      0.097723         0.843532        0.018133   \n",
       "3           3       8.422979      0.240346         0.468810        0.022842   \n",
       "8           8       6.304425      0.014633         0.322273        0.010596   \n",
       "\n",
       "   param_n_estimators  param_max_depth                                 params  \\\n",
       "0                  80               29  {'n_estimators': 80, 'max_depth': 29}   \n",
       "5                  72               98  {'n_estimators': 72, 'max_depth': 98}   \n",
       "7                  64               33  {'n_estimators': 64, 'max_depth': 33}   \n",
       "9                  52               71  {'n_estimators': 52, 'max_depth': 71}   \n",
       "6                  60               93  {'n_estimators': 60, 'max_depth': 93}   \n",
       "4                  40               74  {'n_estimators': 40, 'max_depth': 74}   \n",
       "1                  25               73  {'n_estimators': 25, 'max_depth': 73}   \n",
       "2                  23               66  {'n_estimators': 23, 'max_depth': 66}   \n",
       "3                  10               48  {'n_estimators': 10, 'max_depth': 48}   \n",
       "8                  23                4   {'n_estimators': 23, 'max_depth': 4}   \n",
       "\n",
       "   split0_test_r2  split1_test_r2  split2_test_r2  mean_test_r2  std_test_r2  \\\n",
       "0        0.921858        0.922751        0.922099      0.922236     0.000377   \n",
       "5        0.921811        0.921741        0.921164      0.921572     0.000290   \n",
       "7        0.921495        0.921932        0.921088      0.921505     0.000345   \n",
       "9        0.920678        0.921160        0.921027      0.920955     0.000203   \n",
       "6        0.920492        0.921506        0.920086      0.920695     0.000597   \n",
       "4        0.918704        0.919897        0.919109      0.919237     0.000495   \n",
       "1        0.915674        0.917252        0.916619      0.916515     0.000648   \n",
       "2        0.915774        0.915434        0.915281      0.915496     0.000206   \n",
       "3        0.903202        0.904700        0.903273      0.903725     0.000690   \n",
       "8        0.475762        0.463664        0.459374      0.466267     0.006939   \n",
       "\n",
       "   rank_test_r2  split0_test_rmse  split1_test_rmse  split2_test_rmse  \\\n",
       "0             1          0.002894          0.002883          0.002889   \n",
       "5             2          0.002894          0.002901          0.002907   \n",
       "7             3          0.002899          0.002897          0.002909   \n",
       "9             4          0.002914          0.002911          0.002911   \n",
       "6             5          0.002919          0.002905          0.002928   \n",
       "4             6          0.002951          0.002934          0.002942   \n",
       "1             7          0.003008          0.002984          0.002990   \n",
       "2             8          0.003007          0.003020          0.003011   \n",
       "3             9          0.003218          0.003203          0.003221   \n",
       "8            10          0.007396          0.007507          0.007516   \n",
       "\n",
       "   mean_test_rmse  std_test_rmse  rank_test_rmse  \n",
       "0        0.002889       0.000004              10  \n",
       "5        0.002901       0.000005               9  \n",
       "7        0.002902       0.000005               8  \n",
       "9        0.002912       0.000001               7  \n",
       "6        0.002917       0.000009               6  \n",
       "4        0.002942       0.000007               5  \n",
       "1        0.002994       0.000010               4  \n",
       "2        0.003013       0.000005               3  \n",
       "3        0.003214       0.000008               2  \n",
       "8        0.007473       0.000054               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for reading values if you closed the notebook\n",
    "imported_results = pd.read_csv(filepath)\n",
    "display(imported_results.sort_values(by=[\"rank_test_r2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
