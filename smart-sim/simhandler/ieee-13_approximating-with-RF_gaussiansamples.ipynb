{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: \n",
    "\n",
    "Approximating the non-linear data space that makes up a PyPSA simulation. Specifically, approximating a modified IEEE 13 bus topology with a uniform (grid) input. The approximation is time sensitive.\n",
    "\n",
    "**Objective**:\n",
    "\n",
    "This notebook will only look at [random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) (RF) models. Per [1], the approximation should have a root mean sqaure error < 0.002 to ensure the approximation is not the largest source of error in the simulation. A standard linear regression will also be calculated for baseline comparison. Since the approximation is time sensitive, a search for the ball park number of samples required for reasonable scores is performed. Once the number of samples to produce reasonable results is found, a grid search can be ran to determine optimal training parameters.\n",
    "\n",
    "**Hypothesis**: \n",
    "\n",
    "Previously, a linear regression model outperformed a non-linear model (artificial neural network) when tested on simple, small radial networks [2]. Since the modified IEEE 13 bus network contains two transformers whos behaviour can become non-linear if their power limit is exceeded (which is allowed in power flow [3]), I suspect there are two possible scenarios:\n",
    "\n",
    "1. Transformer limit not exceeded: Linear regression outperforms RF model\n",
    "2. Transformer limit exceeded: RF outperforms linear regressor because a RF model can capture non-linearity \n",
    "\n",
    "As for the number of samples required, historically 1e5-1e6 samples produces K-fold cross validation scores with low variance if the feature-label correlation is reasonable.\n",
    "\n",
    "**Experimental Procedure**:\n",
    "\n",
    "1. Determine the number of samples required to return reasonable scores with SVR K-fold cross validation. Reasonable scores is defined as:\n",
    "  * R2 > 0.8\n",
    "  * RMSE < 0.002\n",
    "  * K-fold R2 variance one degree of magnitude less than R2\n",
    "2. Using approximately that number of samples, run grid search to determine optimal parameters/hyperparameters\n",
    "\n",
    "**Results**:\n",
    "\n",
    "* 1e5 samples (mean R2: 0.85, std dev: 0.0005)\n",
    "* 1e4 samples (mean R2: 0.81, std dev: 0.005)\n",
    "\n",
    "Running a randomized grid search with 1e5 samples produced the following results:\n",
    "\n",
    "1. n_estimators: 99, max_depth: 73, mean training time: 226s (mean R2: 0.85 std dev: 0.0006)\n",
    "2. n_estimators: 89, max_depth: 62, mean training time: 208s (mean R2: 0.85 std dev: 0.0006)\n",
    "3. .\n",
    "4. .\n",
    "\n",
    "\n",
    "18. n_estimators: 24, max_depth: 68, mean training time: 54s (mean R2: 0.84 std dev: 0.001)\n",
    "19. n_estimators: 3, max_depth: 19, mean training time: 7s (mean R2: 0.77 std dev: 0.001)\n",
    "20. n_estimators: 36, max_depth: 9, mean training time: 55s (mean R2: 0.74 std dev: 0.002)\n",
    "\n",
    "**Discussion**:\n",
    "\n",
    "One approach to reduce the cost of simulation-based research is to copy the underlying model and evaluate the approximation [1][4].\n",
    "\n",
    "It takes roughly 7 hours to create 1e5 samples (by running PyPSA sim) on Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz\n",
    "\n",
    "\n",
    "**Bibliography**\n",
    "\n",
    "[1] https://github.com/mbardwell/masters\n",
    "\n",
    "[2] Enhancing Power Flow Simulations Using Function Mapping. Michael Bardwell ; Petr Musilek. 2019 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)\n",
    "\n",
    "[3] https://groups.google.com/forum/#!searchin/pypsa/mikey%7Csort:date/pypsa/FqfC_UR85k0/vBc7HYP_EQAJ\n",
    "\n",
    "[4] ieee-13_timing-pfsim-vs-evaluating-models.ipynb\n",
    "\n",
    "\n",
    "Table of Contents:\n",
    "* Source data\n",
    "* Analyse data\n",
    "* Setup models\n",
    "* Determine number of samples to get reasonable scores\n",
    "* Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import importlib\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pypsa\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger = logging.getLogger(\"pypsa\")\n",
    "logger.setLevel(\"WARNING\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalise_column_names(df, name):\n",
    "        new_columns = []\n",
    "        for column in df.columns:\n",
    "            new_columns.append(name + \"-\" + str(column))\n",
    "        df.columns = new_columns\n",
    "        return pd.DataFrame(df)\n",
    "\n",
    "\n",
    "def collect_data(path_to_powerflow_data, data):\n",
    "    '''\n",
    "    Assumes folder tree has\n",
    "    path_to_powerflow_data/\n",
    "    -->datafiles\n",
    "    -->results/\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    data[\"loads\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"loads-p_set.csv\"), \"load\")\n",
    "    data[\"vmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"vmags.csv\"), \"vmag\")\n",
    "    data[\"vangs\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"vangs.csv\"), \"vang\")\n",
    "    data[\"qmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"qmags.csv\"), \"qmag\")\n",
    "    data[\"linemags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"linemags.csv\"), \"linemag\")\n",
    "\n",
    "\n",
    "def set_gaussian_sample_size(path_to_powerflow_data, data_to_change, n_samples, seed=None):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_to_change: list of strings.\n",
    "        ex: [\"loads-p_set\", \"generators-p_max_pu\", \"snapshots\"]\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    n_original_samples = 2  # sample_1 from IEEE-13 paper, sample_2=0.9*sample_1\n",
    "\n",
    "    data = {}\n",
    "    for datatype in data_to_change:\n",
    "        data[datatype] = pd.read_csv(path_to_powerflow_data + datatype + \".csv\")\n",
    "\n",
    "    def increase_data(dataframe, n_samples, seed=None):\n",
    "        addon = {}\n",
    "        new_df_list = []\n",
    "        for idx, column in enumerate(dataframe):\n",
    "            if dataframe[column].dtype == np.float64 or dataframe[column].dtype == np.int64:\n",
    "                addon[column] = np.abs(\n",
    "                    np.random.RandomState(seed=seed).normal(loc=dataframe[column][0:n_original_samples].mean(),\n",
    "                                                            scale=dataframe[column][0:n_original_samples].std(),\n",
    "                                                            size=n_samples))\n",
    "            elif dataframe[column].dtype == object:\n",
    "                # assuming object is datetime column\n",
    "                latest_datetime = pd.to_datetime(dataframe[column][n_original_samples-1])\n",
    "                addon[column] = []\n",
    "                for sample in range(n_samples):\n",
    "                    addon[column].append(latest_datetime + pd.Timedelta(hours=(1+sample)))\n",
    "            else:\n",
    "                raise TypeError(\"dataframe[column] type: {} should be object or float64/int64\".format(\n",
    "                    type(dataframe[column].dtype)))\n",
    "        addon_dataframe = pd.DataFrame(addon)\n",
    "        return dataframe.head(n_original_samples).append(addon_dataframe)\n",
    "\n",
    "    def cap_data(dataframe, min_value, max_value):\n",
    "        for column in dataframe:\n",
    "            if dataframe[column].dtype == np.float64 or dataframe[column].dtype == np.int64:\n",
    "                for i, val in enumerate(dataframe[column]):\n",
    "                    if val > max_value:\n",
    "                        dataframe[column][i] = max_value\n",
    "                    elif val < min_value:\n",
    "                        dataframe[column][i] = min_value\n",
    "        return dataframe\n",
    "\n",
    "    if n_samples > n_original_samples:\n",
    "        for datatype in data:\n",
    "            data[datatype] = increase_data(data[datatype], n_samples-n_original_samples, seed)\n",
    "            if datatype == \"generators-p_max_pu\":\n",
    "                data[datatype] = cap_data(data[datatype], 0, 1)\n",
    "\n",
    "    for datatype in data:\n",
    "        data[datatype].to_csv(path_to_powerflow_data + datatype + \".csv\", index=False)\n",
    "        print(\"Datatype {} stored\".format(datatype))\n",
    "\n",
    "\n",
    "def create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import shutil\n",
    "    \n",
    "    import pypsa\n",
    "\n",
    "    if not os.path.isdir(path_to_powerflow_data):\n",
    "        src = Path(path_to_powerflow_data).parents[0] / \"ieee-13-with-load-gen/\"  # original modified IEEE model\n",
    "        shutil.copytree(src, path_to_powerflow_data)\n",
    "\n",
    "    set_gaussian_sample_size(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "\n",
    "    network = pypsa.Network(import_name=path_to_powerflow_data)\n",
    "    network.pf()\n",
    "\n",
    "    save_path = path_to_powerflow_data + \"results/\"\n",
    "    network.buses_t.v_mag_pu.to_csv(save_path + \"vmags.csv\")\n",
    "    network.buses_t.v_ang.to_csv(save_path + \"vangs.csv\")\n",
    "    network.buses_t.q.to_csv(save_path + \"qmags.csv\")\n",
    "    network.lines_t.p0.to_csv(save_path + \"linemags.csv\")\n",
    "\n",
    "\n",
    "def backup_samples(src, dest):\n",
    "    '''\n",
    "    thanks https://www.pythoncentral.io/how-to-recursively-copy-a-directory-folder-in-python/\n",
    "    '''\n",
    "    import errno\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    try:\n",
    "        if os.path.isdir(dest):\n",
    "            shutil.rmtree(dest)\n",
    "        shutil.copytree(src, dest)\n",
    "        print(\"Backup to {} successful\".format(dest))\n",
    "    except OSError as e:\n",
    "        # If the error was caused because the source wasn't a directory\n",
    "        if e.errno == errno.ENOTDIR:\n",
    "            shutil.copy(src, dest)\n",
    "        else:\n",
    "            print('Directory not copied. Error: %s' % e)\n",
    "\n",
    "\n",
    "def add_mean_and_std_rows(dataframe):\n",
    "    mean = dataframe.mean()\n",
    "    std = dataframe.std()\n",
    "    dataframe.loc[\"mean\"] = mean\n",
    "    dataframe.loc[\"std\"] = std\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def maxae(y, y_pred, **kwargs):\n",
    "    import numpy as np\n",
    "    return max(np.abs(y-y_pred).ravel())\n",
    "\n",
    "def rmse(y, y_pred, **kwargs):\n",
    "    import operator\n",
    "    return np.sqrt(np.mean(np.square(list(map(operator.sub, y, y_pred)))))\n",
    "\n",
    "def set_data_size(features, labels, n_samples, n_training_samples):\n",
    "    from sklearn.model_selection import train_test_split    \n",
    "    X_train, X_val, y_train, y_val, test_idx, train_idx = train_test_split(features,\n",
    "                                                                           labels,\n",
    "                                                                           range(features.shape[0]),\n",
    "                                                                           train_size=n_training_samples,\n",
    "                                                                           test_size=n_samples-n_training_samples,\n",
    "                                                                           random_state=None)\n",
    "    X_train = X_train.values\n",
    "    y_train = y_train.values\n",
    "    X_val = X_val.values\n",
    "    y_val = y_val.values\n",
    "\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER INPUT\n",
    "sample_size = 100000 # this is the max number of samples available\n",
    "\n",
    "data_to_change = [\"loads-p_set\", \"snapshots\", \"loads-q_set\"]\n",
    "\n",
    "path_to_powerflow_example = \"../../pypsa/examples/ieee-13/\"\n",
    "path_to_powerflow_data = (path_to_powerflow_example + \"/ieee-13-with-load-gen-gaussian-data-\" +\n",
    "                          str(sample_size) + \"-samples/\")\n",
    "path_to_powerflow_results = path_to_powerflow_data + \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Uncomment to generate load samples for modified IEEE-13 network\n",
    "# if sample_size > 10000:\n",
    "#     user = input(\"Are you sure [y/n]? This could erase hours worth of data\")\n",
    "#     if user == \"y\":\n",
    "#         backup_samples(path_to_powerflow_results, path_to_powerflow_data + \"results-backup/\")\n",
    "#         create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "# else:\n",
    "#     create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "\n",
    "data = {\"loads\": [], \"vmags\": [], \"vangs\": [], \"qmags\": [], \"linemags\": []}\n",
    "collect_data(path_to_powerflow_data, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[\"loads\"].drop(\"load-name\", axis=1)\n",
    "labels = data[\"vmags\"].drop([\"vmag-name\", \"vmag-Substation\"], axis=1)\n",
    "features_and_labels = features.join(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff7206cb890>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff722990c50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff7229458d0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7ff721a9dc50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff721a52910>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff721a89c90>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7ff721a3c950>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff7219f5190>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff7219f5cd0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff720ae4210>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff720aa9a90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff720ad4e10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff720a8aad0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7ff720a46e50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff7209feb10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff7209bbf90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff72096fb50>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7ff72097b6d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff72093d090>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff7208a9f10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff7208ddbd0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7ff72089ef50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff720851c10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff720812f90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff71dd12c50>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load-632</th>\n",
       "      <th>load-634</th>\n",
       "      <th>load-645</th>\n",
       "      <th>load-646</th>\n",
       "      <th>load-652</th>\n",
       "      <th>load-671</th>\n",
       "      <th>load-675</th>\n",
       "      <th>load-692</th>\n",
       "      <th>load-611</th>\n",
       "      <th>row average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>vmag-650</td>\n",
       "      <td>-0.020046</td>\n",
       "      <td>-0.132160</td>\n",
       "      <td>-0.021454</td>\n",
       "      <td>-0.021495</td>\n",
       "      <td>-0.019223</td>\n",
       "      <td>-0.137006</td>\n",
       "      <td>-0.110304</td>\n",
       "      <td>-0.024238</td>\n",
       "      <td>-0.023217</td>\n",
       "      <td>-0.056572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-646</td>\n",
       "      <td>-0.086474</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.174776</td>\n",
       "      <td>-0.298769</td>\n",
       "      <td>-0.067853</td>\n",
       "      <td>-0.547298</td>\n",
       "      <td>-0.412960</td>\n",
       "      <td>-0.084970</td>\n",
       "      <td>-0.085142</td>\n",
       "      <td>-0.220738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-645</td>\n",
       "      <td>-0.088140</td>\n",
       "      <td>-0.233107</td>\n",
       "      <td>-0.178247</td>\n",
       "      <td>-0.228672</td>\n",
       "      <td>-0.069011</td>\n",
       "      <td>-0.558910</td>\n",
       "      <td>-0.421875</td>\n",
       "      <td>-0.086483</td>\n",
       "      <td>-0.086819</td>\n",
       "      <td>-0.216807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-632</td>\n",
       "      <td>-0.090864</td>\n",
       "      <td>-0.241835</td>\n",
       "      <td>-0.086768</td>\n",
       "      <td>-0.103492</td>\n",
       "      <td>-0.071260</td>\n",
       "      <td>-0.579590</td>\n",
       "      <td>-0.437670</td>\n",
       "      <td>-0.089086</td>\n",
       "      <td>-0.089764</td>\n",
       "      <td>-0.198925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-633</td>\n",
       "      <td>-0.087539</td>\n",
       "      <td>-0.351729</td>\n",
       "      <td>-0.083343</td>\n",
       "      <td>-0.099481</td>\n",
       "      <td>-0.069388</td>\n",
       "      <td>-0.557443</td>\n",
       "      <td>-0.421417</td>\n",
       "      <td>-0.085484</td>\n",
       "      <td>-0.085808</td>\n",
       "      <td>-0.204626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-634</td>\n",
       "      <td>-0.038337</td>\n",
       "      <td>-0.264779</td>\n",
       "      <td>-0.040705</td>\n",
       "      <td>-0.041729</td>\n",
       "      <td>-0.031290</td>\n",
       "      <td>-0.253145</td>\n",
       "      <td>-0.190968</td>\n",
       "      <td>-0.039854</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>-0.104544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-611</td>\n",
       "      <td>-0.059673</td>\n",
       "      <td>-0.159657</td>\n",
       "      <td>-0.060138</td>\n",
       "      <td>-0.066237</td>\n",
       "      <td>-0.110490</td>\n",
       "      <td>-0.682213</td>\n",
       "      <td>-0.512931</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.181470</td>\n",
       "      <td>-0.215222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-684</td>\n",
       "      <td>-0.059961</td>\n",
       "      <td>-0.160856</td>\n",
       "      <td>-0.060472</td>\n",
       "      <td>-0.066622</td>\n",
       "      <td>-0.111234</td>\n",
       "      <td>-0.686586</td>\n",
       "      <td>-0.516017</td>\n",
       "      <td>-0.104635</td>\n",
       "      <td>-0.144018</td>\n",
       "      <td>-0.212267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-671</td>\n",
       "      <td>-0.060145</td>\n",
       "      <td>-0.162090</td>\n",
       "      <td>-0.060937</td>\n",
       "      <td>-0.067011</td>\n",
       "      <td>-0.083057</td>\n",
       "      <td>-0.691941</td>\n",
       "      <td>-0.519826</td>\n",
       "      <td>-0.105176</td>\n",
       "      <td>-0.106685</td>\n",
       "      <td>-0.206319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-692</td>\n",
       "      <td>-0.060137</td>\n",
       "      <td>-0.162069</td>\n",
       "      <td>-0.060930</td>\n",
       "      <td>-0.067001</td>\n",
       "      <td>-0.083047</td>\n",
       "      <td>-0.691848</td>\n",
       "      <td>-0.519997</td>\n",
       "      <td>-0.105211</td>\n",
       "      <td>-0.106673</td>\n",
       "      <td>-0.206324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-675</td>\n",
       "      <td>-0.056085</td>\n",
       "      <td>-0.152016</td>\n",
       "      <td>-0.057545</td>\n",
       "      <td>-0.062143</td>\n",
       "      <td>-0.077964</td>\n",
       "      <td>-0.647404</td>\n",
       "      <td>-0.598233</td>\n",
       "      <td>-0.098894</td>\n",
       "      <td>-0.100393</td>\n",
       "      <td>-0.205631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-652</td>\n",
       "      <td>-0.059816</td>\n",
       "      <td>-0.159748</td>\n",
       "      <td>-0.059785</td>\n",
       "      <td>-0.066187</td>\n",
       "      <td>-0.176738</td>\n",
       "      <td>-0.679954</td>\n",
       "      <td>-0.511062</td>\n",
       "      <td>-0.103743</td>\n",
       "      <td>-0.142542</td>\n",
       "      <td>-0.217731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-680</td>\n",
       "      <td>-0.060145</td>\n",
       "      <td>-0.162090</td>\n",
       "      <td>-0.060937</td>\n",
       "      <td>-0.067011</td>\n",
       "      <td>-0.083057</td>\n",
       "      <td>-0.691941</td>\n",
       "      <td>-0.519826</td>\n",
       "      <td>-0.105176</td>\n",
       "      <td>-0.106685</td>\n",
       "      <td>-0.206319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>column average</td>\n",
       "      <td>-0.063643</td>\n",
       "      <td>-0.197733</td>\n",
       "      <td>-0.077388</td>\n",
       "      <td>-0.096604</td>\n",
       "      <td>-0.081047</td>\n",
       "      <td>-0.569637</td>\n",
       "      <td>-0.437930</td>\n",
       "      <td>-0.087473</td>\n",
       "      <td>-0.099946</td>\n",
       "      <td>-0.190156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                load-632  load-634  load-645  load-646  load-652  load-671  \\\n",
       "vmag-650       -0.020046 -0.132160 -0.021454 -0.021495 -0.019223 -0.137006   \n",
       "vmag-646       -0.086474 -0.228395 -0.174776 -0.298769 -0.067853 -0.547298   \n",
       "vmag-645       -0.088140 -0.233107 -0.178247 -0.228672 -0.069011 -0.558910   \n",
       "vmag-632       -0.090864 -0.241835 -0.086768 -0.103492 -0.071260 -0.579590   \n",
       "vmag-633       -0.087539 -0.351729 -0.083343 -0.099481 -0.069388 -0.557443   \n",
       "vmag-634       -0.038337 -0.264779 -0.040705 -0.041729 -0.031290 -0.253145   \n",
       "vmag-611       -0.059673 -0.159657 -0.060138 -0.066237 -0.110490 -0.682213   \n",
       "vmag-684       -0.059961 -0.160856 -0.060472 -0.066622 -0.111234 -0.686586   \n",
       "vmag-671       -0.060145 -0.162090 -0.060937 -0.067011 -0.083057 -0.691941   \n",
       "vmag-692       -0.060137 -0.162069 -0.060930 -0.067001 -0.083047 -0.691848   \n",
       "vmag-675       -0.056085 -0.152016 -0.057545 -0.062143 -0.077964 -0.647404   \n",
       "vmag-652       -0.059816 -0.159748 -0.059785 -0.066187 -0.176738 -0.679954   \n",
       "vmag-680       -0.060145 -0.162090 -0.060937 -0.067011 -0.083057 -0.691941   \n",
       "column average -0.063643 -0.197733 -0.077388 -0.096604 -0.081047 -0.569637   \n",
       "\n",
       "                load-675  load-692  load-611  row average  \n",
       "vmag-650       -0.110304 -0.024238 -0.023217    -0.056572  \n",
       "vmag-646       -0.412960 -0.084970 -0.085142    -0.220738  \n",
       "vmag-645       -0.421875 -0.086483 -0.086819    -0.216807  \n",
       "vmag-632       -0.437670 -0.089086 -0.089764    -0.198925  \n",
       "vmag-633       -0.421417 -0.085484 -0.085808    -0.204626  \n",
       "vmag-634       -0.190968 -0.039854 -0.040087    -0.104544  \n",
       "vmag-611       -0.512931 -0.104191 -0.181470    -0.215222  \n",
       "vmag-684       -0.516017 -0.104635 -0.144018    -0.212267  \n",
       "vmag-671       -0.519826 -0.105176 -0.106685    -0.206319  \n",
       "vmag-692       -0.519997 -0.105211 -0.106673    -0.206324  \n",
       "vmag-675       -0.598233 -0.098894 -0.100393    -0.205631  \n",
       "vmag-652       -0.511062 -0.103743 -0.142542    -0.217731  \n",
       "vmag-680       -0.519826 -0.105176 -0.106685    -0.206319  \n",
       "column average -0.437930 -0.087473 -0.099946    -0.190156  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = labels.join(features).corr()\n",
    "\n",
    "# only loads for columns\n",
    "cols = [c for i, c in enumerate(corr_matrix.columns) if corr_matrix.keys().str.contains(\"^load\", regex=True)[i]]\n",
    "reduced_corr_matrix = corr_matrix[cols]\n",
    "reduced_corr_matrix[\"row average\"] = pd.Series(reduced_corr_matrix.mean(axis=1))\n",
    "# only voltages for rows\n",
    "rows = reduced_corr_matrix.index[reduced_corr_matrix.index.str.contains(\"load\")]\n",
    "reduced_corr_matrix.drop(rows, inplace=True)\n",
    "reduced_corr_matrix = reduced_corr_matrix.append(pd.Series(reduced_corr_matrix.mean(), name=\"column average\"))\n",
    "\n",
    "display(reduced_corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine number of samples to get reasonable scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model parameters/hyperparameters\n",
    "\n",
    "'''\n",
    "dnn hyperparameters are chosen from sandbox testing. On average the model attempts to converge \n",
    "(with other parameters it sometimes gives up early).\n",
    "'''\n",
    "\n",
    "regression_model = RandomForestRegressor(n_estimators=100, max_depth=None)\n",
    "regression_model_name = \"rf\"\n",
    "\n",
    "linear = LinearRegression()\n",
    "\n",
    "common_cross_validate_variables = {\"cv\": 5,\n",
    "                                   \"n_jobs\": -1,\n",
    "                                   \"scoring\": {\"r2\": make_scorer(r2_score), \n",
    "                                               \"rmse\": make_scorer(rmse),\n",
    "                                               \"mae\": make_scorer(mae),\n",
    "                                               \"maxae\": make_scorer(maxae)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add on extra descriptor to saved file (ex: -testing_maxae)? -no_input_preprocessing\n",
      "\n",
      "\n",
      "Run:  0\n",
      "n_training_samples:  80\n",
      "n_validation_samples:  20\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 1.5511\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_r2</th>\n",
       "      <th>rf_test_rmse</th>\n",
       "      <th>rf_test_mae</th>\n",
       "      <th>rf_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.121119</td>\n",
       "      <td>0.024256</td>\n",
       "      <td>0.483088</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.011826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.025760</td>\n",
       "      <td>0.600844</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.013764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.123380</td>\n",
       "      <td>0.024803</td>\n",
       "      <td>0.412259</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.008640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.114624</td>\n",
       "      <td>0.023931</td>\n",
       "      <td>0.369323</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.022681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.113937</td>\n",
       "      <td>0.023496</td>\n",
       "      <td>0.392132</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.018082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.120261</td>\n",
       "      <td>0.024449</td>\n",
       "      <td>0.451529</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.014999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.093700</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.005490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rf_fit_time  rf_score_time  rf_test_r2  rf_test_rmse  rf_test_mae  \\\n",
       "0        0.121119       0.024256    0.483088      0.002660     0.001759   \n",
       "1        0.128247       0.025760    0.600844      0.003044     0.002134   \n",
       "2        0.123380       0.024803    0.412259      0.002058     0.001577   \n",
       "3        0.114624       0.023931    0.369323      0.003622     0.002270   \n",
       "4        0.113937       0.023496    0.392132      0.003719     0.002784   \n",
       "mean     0.120261       0.024449    0.451529      0.003021     0.002105   \n",
       "std      0.006042       0.000874    0.093700      0.000690     0.000471   \n",
       "\n",
       "      rf_test_maxae  \n",
       "0          0.011826  \n",
       "1          0.013764  \n",
       "2          0.008640  \n",
       "3          0.022681  \n",
       "4          0.018082  \n",
       "mean       0.014999  \n",
       "std        0.005490  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.935944626433426\n",
      "validation score:  0.4781036514841169\n",
      "rmse:  0.0028331047370057996\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.029402\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "      <th>linear_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.615345</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.012137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.675255</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.010666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.457552</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.007724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.363265</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.025616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.655161</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.016594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.553316</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.014547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.136363</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.006967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.008281           0.001379        0.615345          0.002313   \n",
       "1            0.006947           0.001129        0.675255          0.002492   \n",
       "2            0.000707           0.001083        0.457552          0.001929   \n",
       "3            0.000705           0.001085        0.363265          0.003620   \n",
       "4            0.000686           0.001030        0.655161          0.002814   \n",
       "mean         0.003465           0.001142        0.553316          0.002634   \n",
       "std          0.003816           0.000138        0.136363          0.000637   \n",
       "\n",
       "      linear_test_mae  linear_test_maxae  \n",
       "0            0.001517           0.012137  \n",
       "1            0.001674           0.010666  \n",
       "2            0.001365           0.007724  \n",
       "3            0.002077           0.025616  \n",
       "4            0.001976           0.016594  \n",
       "mean         0.001722           0.014547  \n",
       "std          0.000301           0.006967  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.7006874102126406\n",
      "validation score:  0.5771666780886703\n",
      "rmse:  0.0025723391426298223\n",
      "\n",
      "\n",
      "Run:  1\n",
      "n_training_samples:  800\n",
      "n_validation_samples:  200\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 2.0905\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_r2</th>\n",
       "      <th>rf_test_rmse</th>\n",
       "      <th>rf_test_mae</th>\n",
       "      <th>rf_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.693621</td>\n",
       "      <td>0.042073</td>\n",
       "      <td>0.565301</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.026803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.713497</td>\n",
       "      <td>0.059317</td>\n",
       "      <td>0.588240</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.015705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.603055</td>\n",
       "      <td>0.036456</td>\n",
       "      <td>0.604086</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.020223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.636287</td>\n",
       "      <td>0.057028</td>\n",
       "      <td>0.581922</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.017739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.613202</td>\n",
       "      <td>0.054163</td>\n",
       "      <td>0.585289</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.022906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.651932</td>\n",
       "      <td>0.049807</td>\n",
       "      <td>0.584968</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.020675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.049148</td>\n",
       "      <td>0.009995</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.004360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rf_fit_time  rf_score_time  rf_test_r2  rf_test_rmse  rf_test_mae  \\\n",
       "0        0.693621       0.042073    0.565301      0.002912     0.002054   \n",
       "1        0.713497       0.059317    0.588240      0.002451     0.001785   \n",
       "2        0.603055       0.036456    0.604086      0.002623     0.001832   \n",
       "3        0.636287       0.057028    0.581922      0.002559     0.001795   \n",
       "4        0.613202       0.054163    0.585289      0.002592     0.001751   \n",
       "mean     0.651932       0.049807    0.584968      0.002627     0.001844   \n",
       "std      0.049148       0.009995    0.013896      0.000172     0.000121   \n",
       "\n",
       "      rf_test_maxae  \n",
       "0          0.026803  \n",
       "1          0.015705  \n",
       "2          0.020223  \n",
       "3          0.017739  \n",
       "4          0.022906  \n",
       "mean       0.020675  \n",
       "std        0.004360  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.943914326586029\n",
      "validation score:  0.6081361443268153\n",
      "rmse:  0.002717947119188441\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.071963\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "      <th>linear_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.676898</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.026224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.652348</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.016341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.651938</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.022060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.647122</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.016187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.642123</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.023243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.654086</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.020811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.004420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.003504           0.002755        0.676898          0.002547   \n",
       "1            0.002986           0.002227        0.652348          0.002262   \n",
       "2            0.002041           0.003372        0.651938          0.002484   \n",
       "3            0.001138           0.001943        0.647122          0.002336   \n",
       "4            0.001072           0.001957        0.642123          0.002454   \n",
       "mean         0.002148           0.002451        0.654086          0.002417   \n",
       "std          0.001087           0.000611        0.013413          0.000115   \n",
       "\n",
       "      linear_test_mae  linear_test_maxae  \n",
       "0            0.001760           0.026224  \n",
       "1            0.001584           0.016341  \n",
       "2            0.001683           0.022060  \n",
       "3            0.001586           0.016187  \n",
       "4            0.001585           0.023243  \n",
       "mean         0.001640           0.020811  \n",
       "std          0.000080           0.004420  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.6674915217525021\n",
      "validation score:  0.6876502470724287\n",
      "rmse:  0.0024225870001674953\n",
      "\n",
      "\n",
      "Run:  2\n",
      "n_training_samples:  8000\n",
      "n_validation_samples:  2000\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 26.06\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_r2</th>\n",
       "      <th>rf_test_rmse</th>\n",
       "      <th>rf_test_mae</th>\n",
       "      <th>rf_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.455497</td>\n",
       "      <td>0.372040</td>\n",
       "      <td>0.615654</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.024538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.682538</td>\n",
       "      <td>0.361752</td>\n",
       "      <td>0.625918</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.024799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.241995</td>\n",
       "      <td>0.328748</td>\n",
       "      <td>0.631514</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.026170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.370659</td>\n",
       "      <td>0.340640</td>\n",
       "      <td>0.606769</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.022499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.161981</td>\n",
       "      <td>0.316322</td>\n",
       "      <td>0.606019</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.023677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>8.382534</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.617175</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.024336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.202399</td>\n",
       "      <td>0.022974</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rf_fit_time  rf_score_time  rf_test_r2  rf_test_rmse  rf_test_mae  \\\n",
       "0        8.455497       0.372040    0.615654      0.002584     0.001795   \n",
       "1        8.682538       0.361752    0.625918      0.002547     0.001785   \n",
       "2        8.241995       0.328748    0.631514      0.002554     0.001789   \n",
       "3        8.370659       0.340640    0.606769      0.002566     0.001805   \n",
       "4        8.161981       0.316322    0.606019      0.002536     0.001765   \n",
       "mean     8.382534       0.343900    0.617175      0.002557     0.001788   \n",
       "std      0.202399       0.022974    0.011370      0.000018     0.000015   \n",
       "\n",
       "      rf_test_maxae  \n",
       "0          0.024538  \n",
       "1          0.024799  \n",
       "2          0.026170  \n",
       "3          0.022499  \n",
       "4          0.023677  \n",
       "mean       0.024336  \n",
       "std        0.001363  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.9452551206792441\n",
      "validation score:  0.6288067328003943\n",
      "rmse:  0.0025509099879578263\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.10161\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "      <th>linear_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.018971</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.652125</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.023741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007764</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>0.666757</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.672694</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.026205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>0.646810</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.021684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.655039</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.022525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.010227</td>\n",
       "      <td>0.658685</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.023891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.001878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.018971           0.009469        0.652125          0.002470   \n",
       "1            0.007764           0.013659        0.666757          0.002415   \n",
       "2            0.005025           0.009049        0.672694          0.002417   \n",
       "3            0.004812           0.009784        0.646810          0.002443   \n",
       "4            0.004661           0.009172        0.655039          0.002386   \n",
       "mean         0.008247           0.010227        0.658685          0.002426   \n",
       "std          0.006129           0.001940        0.010709          0.000032   \n",
       "\n",
       "      linear_test_mae  linear_test_maxae  \n",
       "0            0.001700           0.023741  \n",
       "1            0.001668           0.025300  \n",
       "2            0.001663           0.026205  \n",
       "3            0.001691           0.021684  \n",
       "4            0.001636           0.022525  \n",
       "mean         0.001671           0.023891  \n",
       "std          0.000025           0.001878  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.6598137007719379\n",
      "validation score:  0.6683308286380966\n",
      "rmse:  0.0024318256795411654\n",
      "\n",
      "\n",
      "Run:  3\n",
      "n_training_samples:  80000\n",
      "n_validation_samples:  20000\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 378.75\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_r2</th>\n",
       "      <th>rf_test_rmse</th>\n",
       "      <th>rf_test_mae</th>\n",
       "      <th>rf_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>121.143495</td>\n",
       "      <td>4.877568</td>\n",
       "      <td>0.638478</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.026525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>120.938856</td>\n",
       "      <td>4.981207</td>\n",
       "      <td>0.635507</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.029580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>121.428209</td>\n",
       "      <td>4.822083</td>\n",
       "      <td>0.630660</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.026272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>120.457680</td>\n",
       "      <td>4.709242</td>\n",
       "      <td>0.638398</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.024188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>122.330581</td>\n",
       "      <td>4.935086</td>\n",
       "      <td>0.635455</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.026476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>121.259764</td>\n",
       "      <td>4.865037</td>\n",
       "      <td>0.635700</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.026608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.695497</td>\n",
       "      <td>0.105684</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rf_fit_time  rf_score_time  rf_test_r2  rf_test_rmse  rf_test_mae  \\\n",
       "0      121.143495       4.877568    0.638478      0.002520     0.001752   \n",
       "1      120.938856       4.981207    0.635507      0.002520     0.001746   \n",
       "2      121.428209       4.822083    0.630660      0.002490     0.001735   \n",
       "3      120.457680       4.709242    0.638398      0.002502     0.001734   \n",
       "4      122.330581       4.935086    0.635455      0.002516     0.001749   \n",
       "mean   121.259764       4.865037    0.635700      0.002510     0.001743   \n",
       "std      0.695497       0.105684    0.003182      0.000013     0.000008   \n",
       "\n",
       "      rf_test_maxae  \n",
       "0          0.026525  \n",
       "1          0.029580  \n",
       "2          0.026272  \n",
       "3          0.024188  \n",
       "4          0.026476  \n",
       "mean       0.026608  \n",
       "std        0.001925  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.9484932247338643\n",
      "validation score:  0.636775088068054\n",
      "rmse:  0.00250913839076402\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.96597\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "      <th>linear_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.217829</td>\n",
       "      <td>0.165992</td>\n",
       "      <td>0.666148</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.028248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.165349</td>\n",
       "      <td>0.152520</td>\n",
       "      <td>0.660470</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.028361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.076194</td>\n",
       "      <td>0.142294</td>\n",
       "      <td>0.656742</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.025590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.090317</td>\n",
       "      <td>0.165237</td>\n",
       "      <td>0.664634</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.024641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086697</td>\n",
       "      <td>0.186167</td>\n",
       "      <td>0.662581</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.025395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.127277</td>\n",
       "      <td>0.162442</td>\n",
       "      <td>0.662115</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.026447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.061789</td>\n",
       "      <td>0.016490</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.217829           0.165992        0.666148          0.002429   \n",
       "1            0.165349           0.152520        0.660470          0.002441   \n",
       "2            0.076194           0.142294        0.656742          0.002407   \n",
       "3            0.090317           0.165237        0.664634          0.002418   \n",
       "4            0.086697           0.186167        0.662581          0.002431   \n",
       "mean         0.127277           0.162442        0.662115          0.002425   \n",
       "std          0.061789           0.016490        0.003688          0.000013   \n",
       "\n",
       "      linear_test_mae  linear_test_maxae  \n",
       "0            0.001671           0.028248  \n",
       "1            0.001680           0.028361  \n",
       "2            0.001668           0.025590  \n",
       "3            0.001663           0.024641  \n",
       "4            0.001673           0.025395  \n",
       "mean         0.001671           0.026447  \n",
       "std          0.000006           0.001733  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.6623151816181319\n",
      "validation score:  0.6637186851920581\n",
      "rmse:  0.0024232301711452076\n"
     ]
    }
   ],
   "source": [
    "# cell works, may just be commented out because it is an expensive process and user can just skip to grid search\n",
    "\n",
    "savefile_descriptor_addon = input(\"Add on extra descriptor to saved file (ex: -testing_maxae)? \")\n",
    "\n",
    "\n",
    "for i, n_samples in enumerate([100, 1000, 10000, 100000]):\n",
    "    current_iteration = i\n",
    "\n",
    "    n_training_samples = int(n_samples*(80/100))\n",
    "    X_train, y_train, X_val, y_val = set_data_size(features, labels, n_samples, n_training_samples)\n",
    "\n",
    "    print(\"\\n\\nRun: \", current_iteration)\n",
    "    print(\"n_training_samples: \", n_training_samples)\n",
    "    print(\"n_validation_samples: \", n_samples-n_training_samples)\n",
    "    print(\"n_features: \", X_train.shape[1])\n",
    "    print(\"n_labels: \", y_train.shape[1])\n",
    "\n",
    "    ## regression model to evaluate\n",
    "    print(\"\\n\\n{} REGRESSION\\n\\n\".format(regression_model_name.upper()))\n",
    "    time_start = time.time()\n",
    "    regression_model_results = pd.DataFrame(cross_validate(regression_model, \n",
    "                                                           X_train, \n",
    "                                                           y_train, \n",
    "                                                           **common_cross_validate_variables))\n",
    "    time_regression_model = time.time()\n",
    "    print(\"cross validation training time {:.5}\".format(time_regression_model-time_start))\n",
    "    print(\"cross validation training scores: \")\n",
    "    regression_model_results.columns = [regression_model_name+\"_\"+col for col in regression_model_results.columns]\n",
    "    regression_model_results = add_mean_and_std_rows(regression_model_results)\n",
    "    display(regression_model_results)\n",
    "\n",
    "    regression_model.fit(X_train, y_train)\n",
    "    print(\"non-cross validation model scores for reference:\")\n",
    "    print(\"training score: \", r2_score(y_train, regression_model.predict(X_train)))\n",
    "    print(\"validation score: \", r2_score(y_val, regression_model.predict(X_val)))\n",
    "    print(\"rmse: \", rmse(regression_model.predict(X_val), y_val))\n",
    "\n",
    "\n",
    "\n",
    "    ## linear regression for baseline comparison\n",
    "    print(\"\\n\\nLINEAR REGRESSION\\n\\n\")\n",
    "    time_start = time.time()\n",
    "    linear_results = pd.DataFrame(cross_validate(linear, X_train, y_train, **common_cross_validate_variables))\n",
    "    time_linear = time.time()\n",
    "    print(\"cross validation training time {:.5}\".format(time_linear-time_start))\n",
    "    print(\"cross validation training scores: \")\n",
    "    linear_results.columns = [\"linear_\"+col for col in linear_results.columns]\n",
    "    linear_results = add_mean_and_std_rows(linear_results)\n",
    "    display(linear_results)\n",
    "\n",
    "    linear.fit(X_train, y_train)\n",
    "    print(\"non-cross validation model scores for reference:\")\n",
    "    print(\"training score: \", r2_score(y_train, linear.predict(X_train)))\n",
    "    print(\"validation score: \", r2_score(y_val, linear.predict(X_val)))\n",
    "    print(\"rmse: \", rmse(linear.predict(X_val), y_val))\n",
    "\n",
    "        \n",
    "\n",
    "    ## save models\n",
    "    datetimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "    results_to_save = regression_model_results.join(linear_results)\n",
    "    results_to_save.to_csv(path_to_powerflow_data + \n",
    "                           \"/results/approximating_with_{}_model_results-{}_samples-gaussian_input-{}{}.csv\".format(\n",
    "                               regression_model_name,\n",
    "                               n_samples, \n",
    "                               datetimestamp,\n",
    "                               savefile_descriptor_addon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100000\n",
    "if n_samples < 100000:\n",
    "    raise ValueError(\"So you don't accidentally run this on 100 samples again\")\n",
    "\n",
    "n_training_samples = int(n_samples*(80/100))\n",
    "X_train, y_train, X_val, y_val = set_data_size(n_samples, n_training_samples)\n",
    "# remove bad label\n",
    "y_train = y_train.T[1:].T\n",
    "y_val = y_val.T[1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  6.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RF\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_r2</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>66.531391</td>\n",
       "      <td>0.622077</td>\n",
       "      <td>2.545954</td>\n",
       "      <td>0.086762</td>\n",
       "      <td>80</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_estimators': 80, 'max_depth': 29}</td>\n",
       "      <td>0.921858</td>\n",
       "      <td>0.922751</td>\n",
       "      <td>0.922099</td>\n",
       "      <td>0.922236</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>59.921115</td>\n",
       "      <td>0.734938</td>\n",
       "      <td>2.203448</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>72</td>\n",
       "      <td>98</td>\n",
       "      <td>{'n_estimators': 72, 'max_depth': 98}</td>\n",
       "      <td>0.921811</td>\n",
       "      <td>0.921741</td>\n",
       "      <td>0.921164</td>\n",
       "      <td>0.921572</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>52.694661</td>\n",
       "      <td>0.098162</td>\n",
       "      <td>2.040517</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>{'n_estimators': 64, 'max_depth': 33}</td>\n",
       "      <td>0.921495</td>\n",
       "      <td>0.921932</td>\n",
       "      <td>0.921088</td>\n",
       "      <td>0.921505</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>42.708556</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>1.667782</td>\n",
       "      <td>0.055191</td>\n",
       "      <td>52</td>\n",
       "      <td>71</td>\n",
       "      <td>{'n_estimators': 52, 'max_depth': 71}</td>\n",
       "      <td>0.920678</td>\n",
       "      <td>0.921160</td>\n",
       "      <td>0.921027</td>\n",
       "      <td>0.920955</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>49.611883</td>\n",
       "      <td>0.197651</td>\n",
       "      <td>1.920520</td>\n",
       "      <td>0.055440</td>\n",
       "      <td>60</td>\n",
       "      <td>93</td>\n",
       "      <td>{'n_estimators': 60, 'max_depth': 93}</td>\n",
       "      <td>0.920492</td>\n",
       "      <td>0.921506</td>\n",
       "      <td>0.920086</td>\n",
       "      <td>0.920695</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32.702112</td>\n",
       "      <td>0.183965</td>\n",
       "      <td>1.336063</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>{'n_estimators': 40, 'max_depth': 74}</td>\n",
       "      <td>0.918704</td>\n",
       "      <td>0.919897</td>\n",
       "      <td>0.919109</td>\n",
       "      <td>0.919237</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.698034</td>\n",
       "      <td>0.078871</td>\n",
       "      <td>0.903889</td>\n",
       "      <td>0.030214</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>{'n_estimators': 25, 'max_depth': 73}</td>\n",
       "      <td>0.915674</td>\n",
       "      <td>0.917252</td>\n",
       "      <td>0.916619</td>\n",
       "      <td>0.916515</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.139486</td>\n",
       "      <td>0.097723</td>\n",
       "      <td>0.843532</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 66}</td>\n",
       "      <td>0.915774</td>\n",
       "      <td>0.915434</td>\n",
       "      <td>0.915281</td>\n",
       "      <td>0.915496</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.422979</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.468810</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>{'n_estimators': 10, 'max_depth': 48}</td>\n",
       "      <td>0.903202</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>0.903273</td>\n",
       "      <td>0.903725</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>9</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.304425</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.322273</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 4}</td>\n",
       "      <td>0.475762</td>\n",
       "      <td>0.463664</td>\n",
       "      <td>0.459374</td>\n",
       "      <td>0.466267</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>10</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      66.531391      0.622077         2.545954        0.086762   \n",
       "5      59.921115      0.734938         2.203448        0.029155   \n",
       "7      52.694661      0.098162         2.040517        0.075283   \n",
       "9      42.708556      0.272464         1.667782        0.055191   \n",
       "6      49.611883      0.197651         1.920520        0.055440   \n",
       "4      32.702112      0.183965         1.336063        0.059603   \n",
       "1      20.698034      0.078871         0.903889        0.030214   \n",
       "2      19.139486      0.097723         0.843532        0.018133   \n",
       "3       8.422979      0.240346         0.468810        0.022842   \n",
       "8       6.304425      0.014633         0.322273        0.010596   \n",
       "\n",
       "  param_n_estimators param_max_depth                                 params  \\\n",
       "0                 80              29  {'n_estimators': 80, 'max_depth': 29}   \n",
       "5                 72              98  {'n_estimators': 72, 'max_depth': 98}   \n",
       "7                 64              33  {'n_estimators': 64, 'max_depth': 33}   \n",
       "9                 52              71  {'n_estimators': 52, 'max_depth': 71}   \n",
       "6                 60              93  {'n_estimators': 60, 'max_depth': 93}   \n",
       "4                 40              74  {'n_estimators': 40, 'max_depth': 74}   \n",
       "1                 25              73  {'n_estimators': 25, 'max_depth': 73}   \n",
       "2                 23              66  {'n_estimators': 23, 'max_depth': 66}   \n",
       "3                 10              48  {'n_estimators': 10, 'max_depth': 48}   \n",
       "8                 23               4   {'n_estimators': 23, 'max_depth': 4}   \n",
       "\n",
       "   split0_test_r2  split1_test_r2  split2_test_r2  mean_test_r2  std_test_r2  \\\n",
       "0        0.921858        0.922751        0.922099      0.922236     0.000377   \n",
       "5        0.921811        0.921741        0.921164      0.921572     0.000290   \n",
       "7        0.921495        0.921932        0.921088      0.921505     0.000345   \n",
       "9        0.920678        0.921160        0.921027      0.920955     0.000203   \n",
       "6        0.920492        0.921506        0.920086      0.920695     0.000597   \n",
       "4        0.918704        0.919897        0.919109      0.919237     0.000495   \n",
       "1        0.915674        0.917252        0.916619      0.916515     0.000648   \n",
       "2        0.915774        0.915434        0.915281      0.915496     0.000206   \n",
       "3        0.903202        0.904700        0.903273      0.903725     0.000690   \n",
       "8        0.475762        0.463664        0.459374      0.466267     0.006939   \n",
       "\n",
       "   rank_test_r2  split0_test_rmse  split1_test_rmse  split2_test_rmse  \\\n",
       "0             1          0.002894          0.002883          0.002889   \n",
       "5             2          0.002894          0.002901          0.002907   \n",
       "7             3          0.002899          0.002897          0.002909   \n",
       "9             4          0.002914          0.002911          0.002911   \n",
       "6             5          0.002919          0.002905          0.002928   \n",
       "4             6          0.002951          0.002934          0.002942   \n",
       "1             7          0.003008          0.002984          0.002990   \n",
       "2             8          0.003007          0.003020          0.003011   \n",
       "3             9          0.003218          0.003203          0.003221   \n",
       "8            10          0.007396          0.007507          0.007516   \n",
       "\n",
       "   mean_test_rmse  std_test_rmse  rank_test_rmse  \n",
       "0        0.002889       0.000004              10  \n",
       "5        0.002901       0.000005               9  \n",
       "7        0.002902       0.000005               8  \n",
       "9        0.002912       0.000001               7  \n",
       "6        0.002917       0.000009               6  \n",
       "4        0.002942       0.000007               5  \n",
       "1        0.002994       0.000010               4  \n",
       "2        0.003013       0.000005               3  \n",
       "3        0.003214       0.000008               2  \n",
       "8        0.007473       0.000054               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to  ../../pypsa/examples/ieee-13//ieee-13-with-load-gen-uniform-data-100000-samples//results/approximating_with_rf_grid_results-100000_samples-2019-09-13-07-25.csv\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "params = {\"n_estimators\": range(100), \n",
    "          \"max_depth\": [None]+[i for i in range(1, 100)]}\n",
    "grid = RandomizedSearchCV(rf, params, cv=3, n_iter=10, n_jobs=-1, refit=False,\n",
    "                          scoring={\"r2\": make_scorer(r2_score), \"rmse\": make_scorer(rmse), \"mae\": make_scorer(mae)}, \n",
    "                          iid=False, verbose=10)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\\nRF\\n\\n\")\n",
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "display(grid_results.sort_values(by=[\"rank_test_r2\"]))\n",
    "datetimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "filepath = (path_to_powerflow_data + \n",
    "            \"/results/approximating_with_rf_grid_results-{}_samples-{}.csv\".format(n_samples, datetimestamp))\n",
    "print(\"Saving to \", filepath)\n",
    "grid_results.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_r2</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.531391</td>\n",
       "      <td>0.622077</td>\n",
       "      <td>2.545954</td>\n",
       "      <td>0.086762</td>\n",
       "      <td>80</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_estimators': 80, 'max_depth': 29}</td>\n",
       "      <td>0.921858</td>\n",
       "      <td>0.922751</td>\n",
       "      <td>0.922099</td>\n",
       "      <td>0.922236</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>59.921115</td>\n",
       "      <td>0.734938</td>\n",
       "      <td>2.203448</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>72</td>\n",
       "      <td>98</td>\n",
       "      <td>{'n_estimators': 72, 'max_depth': 98}</td>\n",
       "      <td>0.921811</td>\n",
       "      <td>0.921741</td>\n",
       "      <td>0.921164</td>\n",
       "      <td>0.921572</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>52.694661</td>\n",
       "      <td>0.098162</td>\n",
       "      <td>2.040517</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>{'n_estimators': 64, 'max_depth': 33}</td>\n",
       "      <td>0.921495</td>\n",
       "      <td>0.921932</td>\n",
       "      <td>0.921088</td>\n",
       "      <td>0.921505</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>42.708556</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>1.667782</td>\n",
       "      <td>0.055191</td>\n",
       "      <td>52</td>\n",
       "      <td>71</td>\n",
       "      <td>{'n_estimators': 52, 'max_depth': 71}</td>\n",
       "      <td>0.920678</td>\n",
       "      <td>0.921160</td>\n",
       "      <td>0.921027</td>\n",
       "      <td>0.920955</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>49.611883</td>\n",
       "      <td>0.197651</td>\n",
       "      <td>1.920520</td>\n",
       "      <td>0.055440</td>\n",
       "      <td>60</td>\n",
       "      <td>93</td>\n",
       "      <td>{'n_estimators': 60, 'max_depth': 93}</td>\n",
       "      <td>0.920492</td>\n",
       "      <td>0.921506</td>\n",
       "      <td>0.920086</td>\n",
       "      <td>0.920695</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32.702112</td>\n",
       "      <td>0.183965</td>\n",
       "      <td>1.336063</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>{'n_estimators': 40, 'max_depth': 74}</td>\n",
       "      <td>0.918704</td>\n",
       "      <td>0.919897</td>\n",
       "      <td>0.919109</td>\n",
       "      <td>0.919237</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.698034</td>\n",
       "      <td>0.078871</td>\n",
       "      <td>0.903889</td>\n",
       "      <td>0.030214</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>{'n_estimators': 25, 'max_depth': 73}</td>\n",
       "      <td>0.915674</td>\n",
       "      <td>0.917252</td>\n",
       "      <td>0.916619</td>\n",
       "      <td>0.916515</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19.139486</td>\n",
       "      <td>0.097723</td>\n",
       "      <td>0.843532</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 66}</td>\n",
       "      <td>0.915774</td>\n",
       "      <td>0.915434</td>\n",
       "      <td>0.915281</td>\n",
       "      <td>0.915496</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8.422979</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.468810</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>{'n_estimators': 10, 'max_depth': 48}</td>\n",
       "      <td>0.903202</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>0.903273</td>\n",
       "      <td>0.903725</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>9</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6.304425</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.322273</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 4}</td>\n",
       "      <td>0.475762</td>\n",
       "      <td>0.463664</td>\n",
       "      <td>0.459374</td>\n",
       "      <td>0.466267</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>10</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0      66.531391      0.622077         2.545954        0.086762   \n",
       "5           5      59.921115      0.734938         2.203448        0.029155   \n",
       "7           7      52.694661      0.098162         2.040517        0.075283   \n",
       "9           9      42.708556      0.272464         1.667782        0.055191   \n",
       "6           6      49.611883      0.197651         1.920520        0.055440   \n",
       "4           4      32.702112      0.183965         1.336063        0.059603   \n",
       "1           1      20.698034      0.078871         0.903889        0.030214   \n",
       "2           2      19.139486      0.097723         0.843532        0.018133   \n",
       "3           3       8.422979      0.240346         0.468810        0.022842   \n",
       "8           8       6.304425      0.014633         0.322273        0.010596   \n",
       "\n",
       "   param_n_estimators  param_max_depth                                 params  \\\n",
       "0                  80               29  {'n_estimators': 80, 'max_depth': 29}   \n",
       "5                  72               98  {'n_estimators': 72, 'max_depth': 98}   \n",
       "7                  64               33  {'n_estimators': 64, 'max_depth': 33}   \n",
       "9                  52               71  {'n_estimators': 52, 'max_depth': 71}   \n",
       "6                  60               93  {'n_estimators': 60, 'max_depth': 93}   \n",
       "4                  40               74  {'n_estimators': 40, 'max_depth': 74}   \n",
       "1                  25               73  {'n_estimators': 25, 'max_depth': 73}   \n",
       "2                  23               66  {'n_estimators': 23, 'max_depth': 66}   \n",
       "3                  10               48  {'n_estimators': 10, 'max_depth': 48}   \n",
       "8                  23                4   {'n_estimators': 23, 'max_depth': 4}   \n",
       "\n",
       "   split0_test_r2  split1_test_r2  split2_test_r2  mean_test_r2  std_test_r2  \\\n",
       "0        0.921858        0.922751        0.922099      0.922236     0.000377   \n",
       "5        0.921811        0.921741        0.921164      0.921572     0.000290   \n",
       "7        0.921495        0.921932        0.921088      0.921505     0.000345   \n",
       "9        0.920678        0.921160        0.921027      0.920955     0.000203   \n",
       "6        0.920492        0.921506        0.920086      0.920695     0.000597   \n",
       "4        0.918704        0.919897        0.919109      0.919237     0.000495   \n",
       "1        0.915674        0.917252        0.916619      0.916515     0.000648   \n",
       "2        0.915774        0.915434        0.915281      0.915496     0.000206   \n",
       "3        0.903202        0.904700        0.903273      0.903725     0.000690   \n",
       "8        0.475762        0.463664        0.459374      0.466267     0.006939   \n",
       "\n",
       "   rank_test_r2  split0_test_rmse  split1_test_rmse  split2_test_rmse  \\\n",
       "0             1          0.002894          0.002883          0.002889   \n",
       "5             2          0.002894          0.002901          0.002907   \n",
       "7             3          0.002899          0.002897          0.002909   \n",
       "9             4          0.002914          0.002911          0.002911   \n",
       "6             5          0.002919          0.002905          0.002928   \n",
       "4             6          0.002951          0.002934          0.002942   \n",
       "1             7          0.003008          0.002984          0.002990   \n",
       "2             8          0.003007          0.003020          0.003011   \n",
       "3             9          0.003218          0.003203          0.003221   \n",
       "8            10          0.007396          0.007507          0.007516   \n",
       "\n",
       "   mean_test_rmse  std_test_rmse  rank_test_rmse  \n",
       "0        0.002889       0.000004              10  \n",
       "5        0.002901       0.000005               9  \n",
       "7        0.002902       0.000005               8  \n",
       "9        0.002912       0.000001               7  \n",
       "6        0.002917       0.000009               6  \n",
       "4        0.002942       0.000007               5  \n",
       "1        0.002994       0.000010               4  \n",
       "2        0.003013       0.000005               3  \n",
       "3        0.003214       0.000008               2  \n",
       "8        0.007473       0.000054               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for reading values if you closed the notebook\n",
    "imported_results = pd.read_csv(filepath)\n",
    "display(imported_results.sort_values(by=[\"rank_test_r2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
