{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: \n",
    "\n",
    "Approximating the non-linear data space that makes up a PyPSA simulation. Specifically, approximating a modified IEEE 13 bus topology with a uniform (grid) input. The approximation is time sensitive.\n",
    "\n",
    "**Objective**:\n",
    "\n",
    "This notebook will only look at [random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) (RF) models. Per [1], the approximation should have a root mean sqaure error < 0.002 to ensure the approximation is not the largest source of error in the simulation. A standard linear regression will also be calculated for baseline comparison. Since the approximation is time sensitive, a search for the ball park number of samples required for reasonable scores is performed. Once the number of samples to produce reasonable results is found, a grid search can be ran to determine optimal training parameters.\n",
    "\n",
    "**Hypothesis**: \n",
    "\n",
    "Previously, a linear regression model outperformed a non-linear model (artificial neural network) when tested on simple, small radial networks [2]. Since the modified IEEE 13 bus network contains two transformers whos behaviour can become non-linear if their power limit is exceeded (which is allowed in power flow [3]), I suspect there are two possible scenarios:\n",
    "\n",
    "1. Transformer limit not exceeded: Linear regression outperforms RF model\n",
    "2. Transformer limit exceeded: RF outperforms linear regressor because a RF model can capture non-linearity \n",
    "\n",
    "As for the number of samples required, historically 1e5-1e6 samples produces K-fold cross validation scores with low variance if the feature-label correlation is reasonable.\n",
    "\n",
    "**Experimental Procedure**:\n",
    "\n",
    "1. Determine the number of samples required to return reasonable scores with SVR K-fold cross validation. Reasonable scores is defined as:\n",
    "  * R2 > 0.8\n",
    "  * RMSE < 0.002\n",
    "  * K-fold R2 variance one degree of magnitude less than R2\n",
    "2. Using approximately that number of samples, run grid search to determine optimal parameters/hyperparameters\n",
    "\n",
    "**Results**:\n",
    "\n",
    "* Testing different sample sizes\n",
    "\n",
    "| n_samples         |        100 |       1000 |       10000 |       100000 |\n",
    "|:------------------|-----------:|-----------:|------------:|-------------:|\n",
    "| rf_fit_time       | 0.124259   | 0.825855   | 10.8118     | 145.014      |\n",
    "| rf_score_time     | 0.0288108  | 0.042241   |  0.48812    |   6.37943    |\n",
    "| rf_test_r2        | 0.414773   | 0.588604   |  0.644128   |   0.816647   |\n",
    "| rf_test_rmse      | 0.00304963 | 0.00267007 |  0.00247768 |   0.00177921 |\n",
    "| rf_test_mae       | 0.00226547 | 0.00190567 |  0.00170158 |   0.00105475 |\n",
    "| rf_test_maxae     | 0.0144659  | 0.0166441  |  0.0251789  |   0.0260118  |\n",
    "| linear_fit_time   | 0.00410957 | 0.00195227 |  0.00799651 |   0.134568   |\n",
    "| linear_score_time | 0.00166116 | 0.00310507 |  0.0118873  |   0.208881   |\n",
    "| linear_test_r2    | 0.571123   | 0.661088   |  0.663526   |   0.664543   |\n",
    "| linear_test_rmse  | 0.00263566 | 0.00243879 |  0.00241882 |   0.00241745 |\n",
    "| linear_test_mae   | 0.00184378 | 0.00169448 |  0.00166478 |   0.00166503 |\n",
    "| linear_test_maxae | 0.0140767  | 0.0175159  |  0.0247341  |   0.0266285  |\n",
    "\n",
    "* With outlier removal\n",
    "\n",
    "Scores with outliers removed by 1-sigma filter: \n",
    "r2 score: 0.4404498935663021\n",
    "rmse score: 0.003034414566557147\n",
    "mae score: 0.0021592306465658987\n",
    "maxae score: 0.035390213912141255\n",
    "\n",
    "\n",
    "Scores with all data (incl. outliers): \n",
    "r2 score: 0.6081998730762346\n",
    "rmse score: 0.0025391462103004363\n",
    "mae score: 0.0017673716999786135\n",
    "maxae score: 0.027288566908512002\n",
    "\n",
    "\n",
    "Scores with outliers removed by 2-sigma filter: \n",
    "r2 score: 0.5925082825055584\n",
    "rmse score: 0.0025894934456937415\n",
    "mae score: 0.0018033819467131692\n",
    "maxae score: 0.03320194821203448\n",
    "\n",
    "\n",
    "Scores with all data (incl. outliers): \n",
    "r2 score: 0.610869572762153\n",
    "rmse score: 0.00253048063774992\n",
    "mae score: 0.0017622837122290849\n",
    "maxae score: 0.02927787708931051\n",
    "\n",
    "\n",
    "Scores with outliers removed by 3-sigma filter: \n",
    "r2 score: 0.6164294160372116\n",
    "rmse score: 0.0025123380160403997\n",
    "mae score: 0.001746826357674079\n",
    "maxae score: 0.030153409116718932\n",
    "\n",
    "\n",
    "Scores with all data (incl. outliers): \n",
    "r2 score: 0.6115149513901053\n",
    "rmse score: 0.002528381346988403\n",
    "mae score: 0.0017568386856197083\n",
    "maxae score: 0.03159176440636857\n",
    "\n",
    "\n",
    "Scores with outliers removed by 4-sigma filter: \n",
    "r2 score: 0.6175159883119533\n",
    "rmse score: 0.002508777038023244\n",
    "mae score: 0.0017428954539859967\n",
    "maxae score: 0.030179614116119247\n",
    "\n",
    "\n",
    "Scores with all data (incl. outliers): \n",
    "r2 score: 0.6115996800150866\n",
    "rmse score: 0.0025281056118504745\n",
    "mae score: 0.0017562971945968868\n",
    "maxae score: 0.03096774043314543\n",
    "\n",
    "\n",
    "Scores with outliers removed by 5-sigma filter: \n",
    "r2 score: 0.6174213385182905\n",
    "rmse score: 0.0025090874307891384\n",
    "mae score: 0.0017437805133288754\n",
    "maxae score: 0.02922835862930573\n",
    "\n",
    "\n",
    "Scores with all data (incl. outliers): \n",
    "r2 score: 0.6113852914221456\n",
    "rmse score: 0.002528803245458144\n",
    "mae score: 0.0017584102241693942\n",
    "maxae score: 0.028532719258111516\n",
    "\n",
    "\n",
    "* Normalising the input:\n",
    "\n",
    "\n",
    "| n_samples         |       100000 |\n",
    "|:------------------|-------------:|\n",
    "| rf_fit_time       | 151.992      |\n",
    "| rf_score_time     |   6.01919    |\n",
    "| rf_test_r2        |   0.637793   |\n",
    "| rf_test_rmse      |   0.00244126 |\n",
    "| rf_test_mae       |   0.00156085 |\n",
    "| rf_test_maxae     |   0.0292717  |\n",
    "\n",
    "* Permutation importance\n",
    "\n",
    "| Weight          | Feature |\n",
    "|-----------------|---------|\n",
    "| 0.9104 ± 0.0853 | x5      |\n",
    "| 0.5800 ± 0.0346 | x6      |\n",
    "| 0.1351 ± 0.0108 | x1      |\n",
    "| 0.0541 ± 0.0024 | x3      |\n",
    "| 0.0539 ± 0.0046 | x2      |\n",
    "| 0.0511 ± 0.0022 | x8      |\n",
    "| 0.0501 ± 0.0028 | x0      |\n",
    "\n",
    "* Principle component analysis\n",
    "\n",
    "| n_components = 1  |      100000 |\n",
    "|:------------------|------------:|\n",
    "| rf_fit_time       | 44.9403     |\n",
    "| rf_score_time     |  6.55428    |\n",
    "| rf_test_r2        |  0.477186   |\n",
    "| rf_test_rmse      |  0.00297056 |\n",
    "| rf_test_mae       |  0.00188972 |\n",
    "| rf_test_maxae     |  0.0360935  |\n",
    "\n",
    "| n_components = 2  |      100000 |\n",
    "|:------------------|------------:|\n",
    "| rf_fit_time       | 49.6014     |\n",
    "| rf_score_time     |  6.23458    |\n",
    "| rf_test_r2        |  0.736134   |\n",
    "| rf_test_rmse      |  0.00211407 |\n",
    "| rf_test_mae       |  0.00128355 |\n",
    "| rf_test_maxae     |  0.0295565  |\n",
    "\n",
    "\n",
    "| n_components = 3  |      100000 |\n",
    "|:------------------|------------:|\n",
    "| rf_fit_time       | 61.4906     |\n",
    "| rf_score_time     |  6.12341    |\n",
    "| rf_test_r2        |  0.775859   |\n",
    "| rf_test_rmse      |  0.00194902 |\n",
    "| rf_test_mae       |  0.00118029 |\n",
    "| rf_test_maxae     |  0.0269413  |\n",
    "\n",
    "| n_components = 4  |      100000 |\n",
    "|:------------------|------------:|\n",
    "| rf_fit_time       | 74.3325     |\n",
    "| rf_score_time     |  5.71738    |\n",
    "| rf_test_r2        |  0.793577   |\n",
    "| rf_test_rmse      |  0.00188306 |\n",
    "| rf_test_mae       |  0.00113203 |\n",
    "| rf_test_maxae     |  0.0276649  |\n",
    "\n",
    "| n_components = 5  |      100000 |\n",
    "|:------------------|------------:|\n",
    "| rf_fit_time       | 89.4412     |\n",
    "| rf_score_time     |  5.71935    |\n",
    "| rf_test_r2        |  0.797644   |\n",
    "| rf_test_rmse      |  0.00186955 |\n",
    "| rf_test_mae       |  0.00112346 |\n",
    "| rf_test_maxae     |  0.0273177  |\n",
    "\n",
    "Running a randomized grid search with 1e5 samples produced the following results:\n",
    "\n",
    "1. n_estimators: 99, max_depth: 73, mean training time: 226s (mean R2: 0.85 std dev: 0.0006)\n",
    "2. n_estimators: 89, max_depth: 62, mean training time: 208s (mean R2: 0.85 std dev: 0.0006)\n",
    "3. .\n",
    "4. .\n",
    "\n",
    "\n",
    "18. n_estimators: 24, max_depth: 68, mean training time: 54s (mean R2: 0.84 std dev: 0.001)\n",
    "19. n_estimators: 3, max_depth: 19, mean training time: 7s (mean R2: 0.77 std dev: 0.001)\n",
    "20. n_estimators: 36, max_depth: 9, mean training time: 55s (mean R2: 0.74 std dev: 0.002)\n",
    "\n",
    "**Discussion**:\n",
    "\n",
    "One approach to reduce the cost of simulation-based research is to copy the underlying model and evaluate the approximation [1][4].\n",
    "\n",
    "It takes roughly 7 hours to create 1e5 samples (by running PyPSA sim) on Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz\n",
    "\n",
    "\n",
    "**Bibliography**\n",
    "\n",
    "[1] https://github.com/mbardwell/masters\n",
    "\n",
    "[2] Enhancing Power Flow Simulations Using Function Mapping. Michael Bardwell ; Petr Musilek. 2019 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)\n",
    "\n",
    "[3] https://groups.google.com/forum/#!searchin/pypsa/mikey%7Csort:date/pypsa/FqfC_UR85k0/vBc7HYP_EQAJ\n",
    "\n",
    "[4] ieee-13_timing-pfsim-vs-evaluating-models.ipynb\n",
    "\n",
    "\n",
    "Table of Contents:\n",
    "* Source data\n",
    "* Analyse data\n",
    "* Setup models\n",
    "* Determine number of samples to get reasonable scores\n",
    "* Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import importlib\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pypsa\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger = logging.getLogger(\"pypsa\")\n",
    "logger.setLevel(\"WARNING\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalise_column_names(df, name):\n",
    "        new_columns = []\n",
    "        for column in df.columns:\n",
    "            new_columns.append(name + \"-\" + str(column))\n",
    "        df.columns = new_columns\n",
    "        return pd.DataFrame(df)\n",
    "\n",
    "\n",
    "def collect_data(path_to_powerflow_data, data):\n",
    "    '''\n",
    "    Assumes folder tree has\n",
    "    path_to_powerflow_data/\n",
    "    -->datafiles\n",
    "    -->results/\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    \n",
    "    data[\"loads\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"loads-p_set.csv\"), \"load\")\n",
    "    data[\"vmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"vmags.csv\"), \"vmag\")\n",
    "    data[\"vangs\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"vangs.csv\"), \"vang\")\n",
    "    data[\"qmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"qmags.csv\"), \"qmag\")\n",
    "    data[\"linemags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"linemags.csv\"), \"linemag\")\n",
    "\n",
    "\n",
    "def set_gaussian_sample_size(path_to_powerflow_data, data_to_change, n_samples, seed=None):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_to_change: list of strings.\n",
    "        ex: [\"loads-p_set\", \"generators-p_max_pu\", \"snapshots\"]\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    n_original_samples = 2  # sample_1 from IEEE-13 paper, sample_2=0.9*sample_1\n",
    "\n",
    "    data = {}\n",
    "    for datatype in data_to_change:\n",
    "        data[datatype] = pd.read_csv(path_to_powerflow_data + datatype + \".csv\")\n",
    "\n",
    "    def increase_data(dataframe, n_samples, seed=None):\n",
    "        addon = {}\n",
    "        new_df_list = []\n",
    "        for idx, column in enumerate(dataframe):\n",
    "            if dataframe[column].dtype == np.float64 or dataframe[column].dtype == np.int64:\n",
    "                addon[column] = np.abs(\n",
    "                    np.random.RandomState(seed=seed).normal(loc=dataframe[column][0:n_original_samples].mean(),\n",
    "                                                            scale=dataframe[column][0:n_original_samples].std(),\n",
    "                                                            size=n_samples))\n",
    "            elif dataframe[column].dtype == object:\n",
    "                # assuming object is datetime column\n",
    "                latest_datetime = pd.to_datetime(dataframe[column][n_original_samples-1])\n",
    "                addon[column] = []\n",
    "                for sample in range(n_samples):\n",
    "                    addon[column].append(latest_datetime + pd.Timedelta(hours=(1+sample)))\n",
    "            else:\n",
    "                raise TypeError(\"dataframe[column] type: {} should be object or float64/int64\".format(\n",
    "                    type(dataframe[column].dtype)))\n",
    "        addon_dataframe = pd.DataFrame(addon)\n",
    "        return dataframe.head(n_original_samples).append(addon_dataframe)\n",
    "\n",
    "    def cap_data(dataframe, min_value, max_value):\n",
    "        for column in dataframe:\n",
    "            if dataframe[column].dtype == np.float64 or dataframe[column].dtype == np.int64:\n",
    "                for i, val in enumerate(dataframe[column]):\n",
    "                    if val > max_value:\n",
    "                        dataframe[column][i] = max_value\n",
    "                    elif val < min_value:\n",
    "                        dataframe[column][i] = min_value\n",
    "        return dataframe\n",
    "\n",
    "    if n_samples > n_original_samples:\n",
    "        for datatype in data:\n",
    "            data[datatype] = increase_data(data[datatype], n_samples-n_original_samples, seed)\n",
    "            if datatype == \"generators-p_max_pu\":\n",
    "                data[datatype] = cap_data(data[datatype], 0, 1)\n",
    "\n",
    "    for datatype in data:\n",
    "        data[datatype].to_csv(path_to_powerflow_data + datatype + \".csv\", index=False)\n",
    "        print(\"Datatype {} stored\".format(datatype))\n",
    "\n",
    "\n",
    "def create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import shutil\n",
    "    \n",
    "    import pypsa\n",
    "\n",
    "    if not os.path.isdir(path_to_powerflow_data):\n",
    "        src = Path(path_to_powerflow_data).parents[0] / \"ieee-13-with-load-gen/\"  # original modified IEEE model\n",
    "        shutil.copytree(src, path_to_powerflow_data)\n",
    "\n",
    "    set_gaussian_sample_size(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "\n",
    "    network = pypsa.Network(import_name=path_to_powerflow_data)\n",
    "    network.pf()\n",
    "\n",
    "    save_path = path_to_powerflow_data + \"results/\"\n",
    "    network.buses_t.v_mag_pu.to_csv(save_path + \"vmags.csv\")\n",
    "    network.buses_t.v_ang.to_csv(save_path + \"vangs.csv\")\n",
    "    network.buses_t.q.to_csv(save_path + \"qmags.csv\")\n",
    "    network.lines_t.p0.to_csv(save_path + \"linemags.csv\")\n",
    "\n",
    "\n",
    "def backup_samples(src, dest):\n",
    "    '''\n",
    "    thanks https://www.pythoncentral.io/how-to-recursively-copy-a-directory-folder-in-python/\n",
    "    '''\n",
    "    import errno\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    try:\n",
    "        if os.path.isdir(dest):\n",
    "            shutil.rmtree(dest)\n",
    "        shutil.copytree(src, dest)\n",
    "        print(\"Backup to {} successful\".format(dest))\n",
    "    except OSError as e:\n",
    "        # If the error was caused because the source wasn't a directory\n",
    "        if e.errno == errno.ENOTDIR:\n",
    "            shutil.copy(src, dest)\n",
    "        else:\n",
    "            print('Directory not copied. Error: %s' % e)\n",
    "\n",
    "\n",
    "def add_mean_and_std_rows(dataframe):\n",
    "    mean = dataframe.mean()\n",
    "    std = dataframe.std()\n",
    "    dataframe.loc[\"mean\"] = mean\n",
    "    dataframe.loc[\"std\"] = std\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def maxae(y, y_pred, **kwargs):\n",
    "    import numpy as np\n",
    "    return max(np.abs(y-y_pred).ravel())\n",
    "\n",
    "def rmse(y, y_pred, **kwargs):\n",
    "    import operator\n",
    "    return np.sqrt(np.mean(np.square(list(map(operator.sub, y, y_pred)))))\n",
    "\n",
    "def set_data_size(features, labels, n_samples, n_training_samples):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_val, y_train, y_val, train_idx, test_idx = train_test_split(features,\n",
    "                                                                           labels,\n",
    "                                                                           range(features.shape[0]),\n",
    "                                                                           train_size=n_training_samples,\n",
    "                                                                           test_size=n_samples-n_training_samples,\n",
    "                                                                           random_state=None)\n",
    "\n",
    "    X_train = X_train.values\n",
    "    y_train = y_train.values\n",
    "    X_val = X_val.values\n",
    "    y_val = y_val.values\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, test_idx, train_idx\n",
    "\n",
    "def train_models_on_given_sample_size(regression_model, features, labels, n_samples_array=[100, 1000, 10000, 100000], prompt=True):\n",
    "    \"\"\"\n",
    "    Trains regression model on a variety of sample sizes\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    features: pandas DataFrame\n",
    "    labels: pandas DataFrame\n",
    "    n_sample_array: array\n",
    "        ex: [100, 1000, 10000, 100000]\n",
    "    regression_model: sklearn regressor\n",
    "        ex: RandomForestRegressor\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import make_scorer, r2_score\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "    from sklearn.model_selection import cross_validate, train_test_split\n",
    "    from tabulate import tabulate\n",
    "    \n",
    "    if prompt:\n",
    "        savefile_descriptor_addon = input(\"Add on extra descriptor to saved file (ex: -testing_maxae)? \")\n",
    "    else:\n",
    "        savefile_descriptor_addon = ''\n",
    "    linear = LinearRegression()\n",
    "    common_cross_validate_variables = {\"cv\": 5,\n",
    "                                       \"n_jobs\": -1,\n",
    "                                       \"scoring\": {\"r2\": make_scorer(r2_score), \n",
    "                                                   \"rmse\": make_scorer(rmse),\n",
    "                                                   \"mae\": make_scorer(mae),\n",
    "                                                   \"maxae\": make_scorer(maxae)}}\n",
    "    summary = {}\n",
    "\n",
    "    for i, n_samples in enumerate(n_samples_array):\n",
    "        current_iteration = i\n",
    "\n",
    "        # do not split data into train/val; cross_validate will automatically do that\n",
    "        samples_to_use = np.random.randint(0, features.shape[0], n_samples)\n",
    "        X = features.iloc[samples_to_use].values\n",
    "        y = labels.iloc[samples_to_use].values\n",
    "        \n",
    "        print(\"\\n\\nRun: \", current_iteration)\n",
    "        print(\"n_samples for k fold cross validation: \", n_samples)\n",
    "        print(\"n_features: \", X.shape[1])\n",
    "        print(\"n_labels: \", y.shape[1])\n",
    "\n",
    "        ## regression model to evaluate\n",
    "        print(\"\\n\\n{} REGRESSION\\n\\n\".format(regression_model_name.upper()))\n",
    "        time_start = time.time()\n",
    "        regression_model_results = pd.DataFrame(cross_validate(regression_model, X, y, \n",
    "                                                               **common_cross_validate_variables))\n",
    "        time_regression_model = time.time()\n",
    "        print(\"cross validation training time {:.5}\".format(time_regression_model-time_start))\n",
    "        print(\"cross validation training scores: \")\n",
    "        regression_model_results.columns = [regression_model_name+\"_\"+col for col in regression_model_results.columns]\n",
    "        regression_model_results = add_mean_and_std_rows(regression_model_results)\n",
    "        display(regression_model_results)\n",
    "\n",
    "        print(\"non-cross validation model scores for reference:\")\n",
    "        n_training_samples = int(n_samples*80/100)\n",
    "        X_train, y_train, X_val, y_val, _, _ = set_data_size(features, labels, n_samples, n_training_samples)\n",
    "        regression_model.fit(X_train, y_train)\n",
    "        print(\"n_training_samples: \", n_training_samples)\n",
    "        print(\"n_validation_samples: \", n_samples-n_training_samples)\n",
    "        print(\"training score: \", r2_score(y_train, regression_model.predict(X_train)))\n",
    "        print(\"validation score: \", r2_score(y_val, regression_model.predict(X_val)))\n",
    "        print(\"rmse: \", rmse(regression_model.predict(X_val), y_val))\n",
    "\n",
    "\n",
    "\n",
    "        ## linear regression for baseline comparison\n",
    "        print(\"\\n\\nLINEAR REGRESSION\\n\\n\")\n",
    "        time_start = time.time()\n",
    "        linear_results = pd.DataFrame(cross_validate(linear, X, y, **common_cross_validate_variables))\n",
    "        time_linear = time.time()\n",
    "        print(\"cross validation training time {:.5}\".format(time_linear-time_start))\n",
    "        print(\"cross validation training scores: \")\n",
    "        linear_results.columns = [\"linear_\"+col for col in linear_results.columns]\n",
    "        linear_results = add_mean_and_std_rows(linear_results)\n",
    "        display(linear_results)\n",
    "\n",
    "        linear.fit(X_train, y_train)\n",
    "        print(\"non-cross validation model scores for reference:\")\n",
    "        print(\"training score: \", r2_score(y_train, linear.predict(X_train)))\n",
    "        print(\"validation score: \", r2_score(y_val, linear.predict(X_val)))\n",
    "        print(\"rmse: \", rmse(linear.predict(X_val), y_val))\n",
    "\n",
    "\n",
    "\n",
    "        ## save models\n",
    "        datetimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "        results_to_save = regression_model_results.join(linear_results)\n",
    "        results_to_save.to_csv(path_to_powerflow_data + \n",
    "                               \"/results/approximating_with_{}_model_results-{}_samples-gaussian_input-{}{}.csv\".format(\n",
    "                                   regression_model_name,\n",
    "                                   n_samples, \n",
    "                                   datetimestamp,\n",
    "                                   savefile_descriptor_addon))\n",
    "        \n",
    "        summary[n_samples] = results_to_save.loc[\"mean\"].values\n",
    "\n",
    "    summary = pd.DataFrame(summary, index=results_to_save.columns)\n",
    "    summary_table = tabulate(summary, tablefmt=\"pipe\", headers=\"keys\")\n",
    "    print(\"\\n\\nSUMMARY\\n\\n\", summary_table)\n",
    "    with open(path_to_powerflow_data + \"/results/approximating_with_{}_model_summary-gaussian_input-{}{}.txt\".format(\n",
    "                  regression_model_name,\n",
    "                  datetimestamp,\n",
    "                  savefile_descriptor_addon), \"w\") as f:\n",
    "        f.write(summary_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER INPUT\n",
    "sample_size = 100000 # this is the max number of samples available\n",
    "\n",
    "data_to_change = [\"loads-p_set\", \"snapshots\", \"loads-q_set\"]\n",
    "\n",
    "path_to_powerflow_example = \"../../pypsa/examples/ieee-13/\"\n",
    "path_to_powerflow_data = (path_to_powerflow_example + \"/ieee-13-with-load-gen-gaussian-data-\" +\n",
    "                          str(sample_size) + \"-samples/\")\n",
    "path_to_powerflow_results = path_to_powerflow_data + \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Uncomment to generate load samples for modified IEEE-13 network\n",
    "# if sample_size > 10000:\n",
    "#     user = input(\"Are you sure [y/n]? This could erase hours worth of data\")\n",
    "#     if user == \"y\":\n",
    "#         backup_samples(path_to_powerflow_results, path_to_powerflow_data + \"results-backup/\")\n",
    "#         create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "# else:\n",
    "#     create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "\n",
    "data = {\"loads\": [], \"vmags\": [], \"vangs\": [], \"qmags\": [], \"linemags\": []}\n",
    "collect_data(path_to_powerflow_data, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[\"loads\"].drop(\"load-name\", axis=1)\n",
    "labels = data[\"vmags\"].drop([\"vmag-name\", \"vmag-Substation\"], axis=1)\n",
    "features_and_labels = features.join(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fc36b84c890>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc3679d3c90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc367a06f90>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc3679c42d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc36797a5d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc36792e8d0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc3678e0c90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc367894ed0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc36789da50>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fc36b8101d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc365e4cf10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc365e09b10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc365dc8350>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc365dfeb50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc365dbc390>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc365d72c50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc365d31fd0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc365d313d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc365cf0950>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc365c5cc10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc365c1e450>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc365bd2c50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc365b93490>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc365bc6c90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc362d934d0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load-632</th>\n",
       "      <th>load-634</th>\n",
       "      <th>load-645</th>\n",
       "      <th>load-646</th>\n",
       "      <th>load-652</th>\n",
       "      <th>load-671</th>\n",
       "      <th>load-675</th>\n",
       "      <th>load-692</th>\n",
       "      <th>load-611</th>\n",
       "      <th>row average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>vmag-650</td>\n",
       "      <td>-0.020046</td>\n",
       "      <td>-0.132160</td>\n",
       "      <td>-0.021454</td>\n",
       "      <td>-0.021495</td>\n",
       "      <td>-0.019223</td>\n",
       "      <td>-0.137006</td>\n",
       "      <td>-0.110304</td>\n",
       "      <td>-0.024238</td>\n",
       "      <td>-0.023217</td>\n",
       "      <td>-0.056572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-646</td>\n",
       "      <td>-0.086474</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.174776</td>\n",
       "      <td>-0.298769</td>\n",
       "      <td>-0.067853</td>\n",
       "      <td>-0.547298</td>\n",
       "      <td>-0.412960</td>\n",
       "      <td>-0.084970</td>\n",
       "      <td>-0.085142</td>\n",
       "      <td>-0.220738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-645</td>\n",
       "      <td>-0.088140</td>\n",
       "      <td>-0.233107</td>\n",
       "      <td>-0.178247</td>\n",
       "      <td>-0.228672</td>\n",
       "      <td>-0.069011</td>\n",
       "      <td>-0.558910</td>\n",
       "      <td>-0.421875</td>\n",
       "      <td>-0.086483</td>\n",
       "      <td>-0.086819</td>\n",
       "      <td>-0.216807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-632</td>\n",
       "      <td>-0.090864</td>\n",
       "      <td>-0.241835</td>\n",
       "      <td>-0.086768</td>\n",
       "      <td>-0.103492</td>\n",
       "      <td>-0.071260</td>\n",
       "      <td>-0.579590</td>\n",
       "      <td>-0.437670</td>\n",
       "      <td>-0.089086</td>\n",
       "      <td>-0.089764</td>\n",
       "      <td>-0.198925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-633</td>\n",
       "      <td>-0.087539</td>\n",
       "      <td>-0.351729</td>\n",
       "      <td>-0.083343</td>\n",
       "      <td>-0.099481</td>\n",
       "      <td>-0.069388</td>\n",
       "      <td>-0.557443</td>\n",
       "      <td>-0.421417</td>\n",
       "      <td>-0.085484</td>\n",
       "      <td>-0.085808</td>\n",
       "      <td>-0.204626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-634</td>\n",
       "      <td>-0.038337</td>\n",
       "      <td>-0.264779</td>\n",
       "      <td>-0.040705</td>\n",
       "      <td>-0.041729</td>\n",
       "      <td>-0.031290</td>\n",
       "      <td>-0.253145</td>\n",
       "      <td>-0.190968</td>\n",
       "      <td>-0.039854</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>-0.104544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-611</td>\n",
       "      <td>-0.059673</td>\n",
       "      <td>-0.159657</td>\n",
       "      <td>-0.060138</td>\n",
       "      <td>-0.066237</td>\n",
       "      <td>-0.110490</td>\n",
       "      <td>-0.682213</td>\n",
       "      <td>-0.512931</td>\n",
       "      <td>-0.104191</td>\n",
       "      <td>-0.181470</td>\n",
       "      <td>-0.215222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-684</td>\n",
       "      <td>-0.059961</td>\n",
       "      <td>-0.160856</td>\n",
       "      <td>-0.060472</td>\n",
       "      <td>-0.066622</td>\n",
       "      <td>-0.111234</td>\n",
       "      <td>-0.686586</td>\n",
       "      <td>-0.516017</td>\n",
       "      <td>-0.104635</td>\n",
       "      <td>-0.144018</td>\n",
       "      <td>-0.212267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-671</td>\n",
       "      <td>-0.060145</td>\n",
       "      <td>-0.162090</td>\n",
       "      <td>-0.060937</td>\n",
       "      <td>-0.067011</td>\n",
       "      <td>-0.083057</td>\n",
       "      <td>-0.691941</td>\n",
       "      <td>-0.519826</td>\n",
       "      <td>-0.105176</td>\n",
       "      <td>-0.106685</td>\n",
       "      <td>-0.206319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-692</td>\n",
       "      <td>-0.060137</td>\n",
       "      <td>-0.162069</td>\n",
       "      <td>-0.060930</td>\n",
       "      <td>-0.067001</td>\n",
       "      <td>-0.083047</td>\n",
       "      <td>-0.691848</td>\n",
       "      <td>-0.519997</td>\n",
       "      <td>-0.105211</td>\n",
       "      <td>-0.106673</td>\n",
       "      <td>-0.206324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-675</td>\n",
       "      <td>-0.056085</td>\n",
       "      <td>-0.152016</td>\n",
       "      <td>-0.057545</td>\n",
       "      <td>-0.062143</td>\n",
       "      <td>-0.077964</td>\n",
       "      <td>-0.647404</td>\n",
       "      <td>-0.598233</td>\n",
       "      <td>-0.098894</td>\n",
       "      <td>-0.100393</td>\n",
       "      <td>-0.205631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-652</td>\n",
       "      <td>-0.059816</td>\n",
       "      <td>-0.159748</td>\n",
       "      <td>-0.059785</td>\n",
       "      <td>-0.066187</td>\n",
       "      <td>-0.176738</td>\n",
       "      <td>-0.679954</td>\n",
       "      <td>-0.511062</td>\n",
       "      <td>-0.103743</td>\n",
       "      <td>-0.142542</td>\n",
       "      <td>-0.217731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-680</td>\n",
       "      <td>-0.060145</td>\n",
       "      <td>-0.162090</td>\n",
       "      <td>-0.060937</td>\n",
       "      <td>-0.067011</td>\n",
       "      <td>-0.083057</td>\n",
       "      <td>-0.691941</td>\n",
       "      <td>-0.519826</td>\n",
       "      <td>-0.105176</td>\n",
       "      <td>-0.106685</td>\n",
       "      <td>-0.206319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>column average</td>\n",
       "      <td>-0.063643</td>\n",
       "      <td>-0.197733</td>\n",
       "      <td>-0.077388</td>\n",
       "      <td>-0.096604</td>\n",
       "      <td>-0.081047</td>\n",
       "      <td>-0.569637</td>\n",
       "      <td>-0.437930</td>\n",
       "      <td>-0.087473</td>\n",
       "      <td>-0.099946</td>\n",
       "      <td>-0.190156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                load-632  load-634  load-645  load-646  load-652  load-671  \\\n",
       "vmag-650       -0.020046 -0.132160 -0.021454 -0.021495 -0.019223 -0.137006   \n",
       "vmag-646       -0.086474 -0.228395 -0.174776 -0.298769 -0.067853 -0.547298   \n",
       "vmag-645       -0.088140 -0.233107 -0.178247 -0.228672 -0.069011 -0.558910   \n",
       "vmag-632       -0.090864 -0.241835 -0.086768 -0.103492 -0.071260 -0.579590   \n",
       "vmag-633       -0.087539 -0.351729 -0.083343 -0.099481 -0.069388 -0.557443   \n",
       "vmag-634       -0.038337 -0.264779 -0.040705 -0.041729 -0.031290 -0.253145   \n",
       "vmag-611       -0.059673 -0.159657 -0.060138 -0.066237 -0.110490 -0.682213   \n",
       "vmag-684       -0.059961 -0.160856 -0.060472 -0.066622 -0.111234 -0.686586   \n",
       "vmag-671       -0.060145 -0.162090 -0.060937 -0.067011 -0.083057 -0.691941   \n",
       "vmag-692       -0.060137 -0.162069 -0.060930 -0.067001 -0.083047 -0.691848   \n",
       "vmag-675       -0.056085 -0.152016 -0.057545 -0.062143 -0.077964 -0.647404   \n",
       "vmag-652       -0.059816 -0.159748 -0.059785 -0.066187 -0.176738 -0.679954   \n",
       "vmag-680       -0.060145 -0.162090 -0.060937 -0.067011 -0.083057 -0.691941   \n",
       "column average -0.063643 -0.197733 -0.077388 -0.096604 -0.081047 -0.569637   \n",
       "\n",
       "                load-675  load-692  load-611  row average  \n",
       "vmag-650       -0.110304 -0.024238 -0.023217    -0.056572  \n",
       "vmag-646       -0.412960 -0.084970 -0.085142    -0.220738  \n",
       "vmag-645       -0.421875 -0.086483 -0.086819    -0.216807  \n",
       "vmag-632       -0.437670 -0.089086 -0.089764    -0.198925  \n",
       "vmag-633       -0.421417 -0.085484 -0.085808    -0.204626  \n",
       "vmag-634       -0.190968 -0.039854 -0.040087    -0.104544  \n",
       "vmag-611       -0.512931 -0.104191 -0.181470    -0.215222  \n",
       "vmag-684       -0.516017 -0.104635 -0.144018    -0.212267  \n",
       "vmag-671       -0.519826 -0.105176 -0.106685    -0.206319  \n",
       "vmag-692       -0.519997 -0.105211 -0.106673    -0.206324  \n",
       "vmag-675       -0.598233 -0.098894 -0.100393    -0.205631  \n",
       "vmag-652       -0.511062 -0.103743 -0.142542    -0.217731  \n",
       "vmag-680       -0.519826 -0.105176 -0.106685    -0.206319  \n",
       "column average -0.437930 -0.087473 -0.099946    -0.190156  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = labels.join(features).corr()\n",
    "\n",
    "# only loads for columns\n",
    "cols = [c for i, c in enumerate(corr_matrix.columns) if corr_matrix.keys().str.contains(\"^load\", regex=True)[i]]\n",
    "reduced_corr_matrix = corr_matrix[cols]\n",
    "reduced_corr_matrix[\"row average\"] = pd.Series(reduced_corr_matrix.mean(axis=1))\n",
    "# only voltages for rows\n",
    "rows = reduced_corr_matrix.index[reduced_corr_matrix.index.str.contains(\"load\")]\n",
    "reduced_corr_matrix.drop(rows, inplace=True)\n",
    "reduced_corr_matrix = reduced_corr_matrix.append(pd.Series(reduced_corr_matrix.mean(), name=\"column average\"))\n",
    "\n",
    "display(reduced_corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine number of samples to get reasonable scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model parameters/hyperparameters\n",
    "\n",
    "'''\n",
    "dnn hyperparameters are chosen from sandbox testing. On average the model attempts to converge \n",
    "(with other parameters it sometimes gives up early).\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regression_model = RandomForestRegressor(n_estimators=100, max_depth=None)\n",
    "regression_model_name = \"rf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add on extra descriptor to saved file (ex: -testing_maxae)? no\n",
      "\n",
      "\n",
      "Run:  0\n",
      "n_samples for k fold cross validation:  10\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.35708\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_r2</th>\n",
       "      <th>rf_test_rmse</th>\n",
       "      <th>rf_test_mae</th>\n",
       "      <th>rf_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.076372</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>-4.041733</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.003487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.068832</td>\n",
       "      <td>0.022342</td>\n",
       "      <td>-7.113384</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.003933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.077792</td>\n",
       "      <td>0.042646</td>\n",
       "      <td>-3.925563</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.014644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.066168</td>\n",
       "      <td>0.049398</td>\n",
       "      <td>-351.636270</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.003881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.039302</td>\n",
       "      <td>-299.289965</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.005254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.070331</td>\n",
       "      <td>0.036616</td>\n",
       "      <td>-133.201383</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.006240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>176.487856</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.004745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rf_fit_time  rf_score_time  rf_test_r2  rf_test_rmse  rf_test_mae  \\\n",
       "0        0.076372       0.029394   -4.041733      0.000864     0.000527   \n",
       "1        0.068832       0.022342   -7.113384      0.002125     0.001661   \n",
       "2        0.077792       0.042646   -3.925563      0.004851     0.003869   \n",
       "3        0.066168       0.049398 -351.636270      0.001694     0.001358   \n",
       "4        0.062488       0.039302 -299.289965      0.002690     0.002407   \n",
       "mean     0.070331       0.036616 -133.201383      0.002445     0.001965   \n",
       "std      0.006581       0.010757  176.487856      0.001501     0.001260   \n",
       "\n",
       "      rf_test_maxae  \n",
       "0          0.003487  \n",
       "1          0.003933  \n",
       "2          0.014644  \n",
       "3          0.003881  \n",
       "4          0.005254  \n",
       "mean       0.006240  \n",
       "std        0.004745  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "n_training_samples:  8\n",
      "n_validation_samples:  2\n",
      "training score:  0.847037369199652\n",
      "validation score:  0.03497912405730065\n",
      "rmse:  0.0045496561408353885\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.025027\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "      <th>linear_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>-74.537961</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.013064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>-806.548384</td>\n",
       "      <td>0.016163</td>\n",
       "      <td>0.014120</td>\n",
       "      <td>0.028565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>-812.947495</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>0.042586</td>\n",
       "      <td>0.118949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>-152498.428753</td>\n",
       "      <td>0.038038</td>\n",
       "      <td>0.028280</td>\n",
       "      <td>0.118378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>-168.631679</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.008874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>-30872.218855</td>\n",
       "      <td>0.022943</td>\n",
       "      <td>0.017953</td>\n",
       "      <td>0.057566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>67991.997109</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>0.017411</td>\n",
       "      <td>0.056255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.001094           0.001143      -74.537961          0.003692   \n",
       "1            0.001250           0.003202     -806.548384          0.016163   \n",
       "2            0.000737           0.001080     -812.947495          0.054003   \n",
       "3            0.000690           0.001082  -152498.428753          0.038038   \n",
       "4            0.000616           0.000964     -168.631679          0.002818   \n",
       "mean         0.000877           0.001494   -30872.218855          0.022943   \n",
       "std          0.000278           0.000957    67991.997109          0.022440   \n",
       "\n",
       "      linear_test_mae  linear_test_maxae  \n",
       "0            0.002461           0.013064  \n",
       "1            0.014120           0.028565  \n",
       "2            0.042586           0.118949  \n",
       "3            0.028280           0.118378  \n",
       "4            0.002316           0.008874  \n",
       "mean         0.017953           0.057566  \n",
       "std          0.017411           0.056255  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  1.0\n",
      "validation score:  -114.33448775167417\n",
      "rmse:  0.03313077679674021\n",
      "\n",
      "\n",
      "Run:  1\n",
      "n_samples for k fold cross validation:  100\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.47783\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_r2</th>\n",
       "      <th>rf_test_rmse</th>\n",
       "      <th>rf_test_mae</th>\n",
       "      <th>rf_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.120773</td>\n",
       "      <td>0.028136</td>\n",
       "      <td>0.472382</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.013422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.123469</td>\n",
       "      <td>0.027487</td>\n",
       "      <td>0.589175</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.013021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.121908</td>\n",
       "      <td>0.045683</td>\n",
       "      <td>0.529600</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.017450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.116894</td>\n",
       "      <td>0.036991</td>\n",
       "      <td>0.061218</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.014129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.129726</td>\n",
       "      <td>0.027276</td>\n",
       "      <td>0.279653</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.017330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.122554</td>\n",
       "      <td>0.033115</td>\n",
       "      <td>0.386406</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.015070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.008117</td>\n",
       "      <td>0.215729</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rf_fit_time  rf_score_time  rf_test_r2  rf_test_rmse  rf_test_mae  \\\n",
       "0        0.120773       0.028136    0.472382      0.002621     0.001982   \n",
       "1        0.123469       0.027487    0.589175      0.002998     0.002180   \n",
       "2        0.121908       0.045683    0.529600      0.002980     0.002109   \n",
       "3        0.116894       0.036991    0.061218      0.002996     0.002238   \n",
       "4        0.129726       0.027276    0.279653      0.003455     0.002519   \n",
       "mean     0.122554       0.033115    0.386406      0.003010     0.002205   \n",
       "std      0.004688       0.008117    0.215729      0.000296     0.000200   \n",
       "\n",
       "      rf_test_maxae  \n",
       "0          0.013422  \n",
       "1          0.013021  \n",
       "2          0.017450  \n",
       "3          0.014129  \n",
       "4          0.017330  \n",
       "mean       0.015070  \n",
       "std        0.002155  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "n_training_samples:  80\n",
      "n_validation_samples:  20\n",
      "training score:  0.9308661430629533\n",
      "validation score:  0.5058536006809089\n",
      "rmse:  0.002447156942380102\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.056885\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "      <th>linear_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.589988</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.013640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.707613</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.016597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.646234</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.018252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.420303</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.013344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.487703</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.021570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.570368</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.016681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.116544</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.003419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.001121           0.001352        0.589988          0.002245   \n",
       "1            0.001029           0.001383        0.707613          0.002483   \n",
       "2            0.001023           0.001161        0.646234          0.002633   \n",
       "3            0.001078           0.001370        0.420303          0.002387   \n",
       "4            0.000729           0.001451        0.487703          0.002979   \n",
       "mean         0.000996           0.001343        0.570368          0.002545   \n",
       "std          0.000155           0.000109        0.116544          0.000281   \n",
       "\n",
       "      linear_test_mae  linear_test_maxae  \n",
       "0            0.001520           0.013640  \n",
       "1            0.001648           0.016597  \n",
       "2            0.001891           0.018252  \n",
       "3            0.001667           0.013344  \n",
       "4            0.001918           0.021570  \n",
       "mean         0.001729           0.016681  \n",
       "std          0.000171           0.003419  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.716213326159638\n",
      "validation score:  0.6237232245259071\n",
      "rmse:  0.002134492596662164\n",
      "\n",
      "\n",
      "SUMMARY\n",
      "\n",
      " |                   |              10 |        100 |\n",
      "|:------------------|----------------:|-----------:|\n",
      "| rf_fit_time       |      0.0703306  | 0.122554   |\n",
      "| rf_score_time     |      0.0366165  | 0.0331146  |\n",
      "| rf_test_r2        |   -133.201      | 0.386406   |\n",
      "| rf_test_rmse      |      0.00244477 | 0.00301007 |\n",
      "| rf_test_mae       |      0.00196458 | 0.00220548 |\n",
      "| rf_test_maxae     |      0.00623979 | 0.0150702  |\n",
      "| linear_fit_time   |      0.00087738 | 0.00099597 |\n",
      "| linear_score_time |      0.00149422 | 0.00134325 |\n",
      "| linear_test_r2    | -30872.2        | 0.570368   |\n",
      "| linear_test_rmse  |      0.0229427  | 0.00254548 |\n",
      "| linear_test_mae   |      0.0179526  | 0.0017288  |\n",
      "| linear_test_maxae |      0.0575661  | 0.0166805  |\n"
     ]
    }
   ],
   "source": [
    "train_models_on_given_sample_size(regression_model, features, labels, n_samples_array=[100, 1000, 10000, 100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try different feature preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add on extra descriptor to saved file (ex: -testing_maxae)? -normalised_inputs\n",
      "\n",
      "\n",
      "Run:  0\n",
      "n_samples for k fold cross validation:  100000\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 475.7\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_r2</th>\n",
       "      <th>rf_test_rmse</th>\n",
       "      <th>rf_test_mae</th>\n",
       "      <th>rf_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>153.875281</td>\n",
       "      <td>5.932143</td>\n",
       "      <td>0.637177</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.027139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>152.561436</td>\n",
       "      <td>6.294808</td>\n",
       "      <td>0.639960</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.029437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>149.776759</td>\n",
       "      <td>5.658828</td>\n",
       "      <td>0.633469</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.026920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>150.460783</td>\n",
       "      <td>5.819415</td>\n",
       "      <td>0.643095</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.031620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>153.287055</td>\n",
       "      <td>6.390744</td>\n",
       "      <td>0.635263</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.031242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>151.992263</td>\n",
       "      <td>6.019188</td>\n",
       "      <td>0.637793</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.029272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.788861</td>\n",
       "      <td>0.312796</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.002208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rf_fit_time  rf_score_time  rf_test_r2  rf_test_rmse  rf_test_mae  \\\n",
       "0      153.875281       5.932143    0.637177      0.002433     0.001560   \n",
       "1      152.561436       6.294808    0.639960      0.002437     0.001557   \n",
       "2      149.776759       5.658828    0.633469      0.002458     0.001568   \n",
       "3      150.460783       5.819415    0.643095      0.002425     0.001546   \n",
       "4      153.287055       6.390744    0.635263      0.002453     0.001573   \n",
       "mean   151.992263       6.019188    0.637793      0.002441     0.001561   \n",
       "std      1.788861       0.312796    0.003817      0.000014     0.000011   \n",
       "\n",
       "      rf_test_maxae  \n",
       "0          0.027139  \n",
       "1          0.029437  \n",
       "2          0.026920  \n",
       "3          0.031620  \n",
       "4          0.031242  \n",
       "mean       0.029272  \n",
       "std        0.002208  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "n_training_samples:  80000\n",
      "n_validation_samples:  20000\n",
      "training score:  0.9002041849787135\n",
      "validation score:  0.28117266994230283\n",
      "rmse:  0.003427523667950598\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 3.1393\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "      <th>linear_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.577047</td>\n",
       "      <td>0.200674</td>\n",
       "      <td>0.658344</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.026092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.115414</td>\n",
       "      <td>0.211838</td>\n",
       "      <td>0.664823</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.026766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.111729</td>\n",
       "      <td>0.215991</td>\n",
       "      <td>0.661817</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.026110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.190370</td>\n",
       "      <td>0.188705</td>\n",
       "      <td>0.659786</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.026804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.134244</td>\n",
       "      <td>0.207136</td>\n",
       "      <td>0.664758</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.028172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.225761</td>\n",
       "      <td>0.204869</td>\n",
       "      <td>0.661906</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.026789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.198878</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.577047           0.200674        0.658344          0.002419   \n",
       "1            0.115414           0.211838        0.664823          0.002425   \n",
       "2            0.111729           0.215991        0.661817          0.002423   \n",
       "3            0.190370           0.188705        0.659786          0.002436   \n",
       "4            0.134244           0.207136        0.664758          0.002412   \n",
       "mean         0.225761           0.204869        0.661906          0.002423   \n",
       "std          0.198878           0.010680        0.002908          0.000009   \n",
       "\n",
       "      linear_test_mae  linear_test_maxae  \n",
       "0            0.001668           0.026092  \n",
       "1            0.001662           0.026766  \n",
       "2            0.001669           0.026110  \n",
       "3            0.001679           0.026804  \n",
       "4            0.001663           0.028172  \n",
       "mean         0.001668           0.026789  \n",
       "std          0.000007           0.000845  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.6631622616863727\n",
      "validation score:  0.6603767378935336\n",
      "rmse:  0.002422863041469911\n",
      "\n",
      "\n",
      "SUMMARY\n",
      "\n",
      " |                   |       100000 |\n",
      "|:------------------|-------------:|\n",
      "| rf_fit_time       | 151.992      |\n",
      "| rf_score_time     |   6.01919    |\n",
      "| rf_test_r2        |   0.637793   |\n",
      "| rf_test_rmse      |   0.00244126 |\n",
      "| rf_test_mae       |   0.00156085 |\n",
      "| rf_test_maxae     |   0.0292717  |\n",
      "| linear_fit_time   |   0.225761   |\n",
      "| linear_score_time |   0.204869   |\n",
      "| linear_test_r2    |   0.661906   |\n",
      "| linear_test_rmse  |   0.00242279 |\n",
      "| linear_test_mae   |   0.00166827 |\n",
      "| linear_test_maxae |   0.0267888  |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# test normalizing labels\n",
    "estimators = [(\"normalise\", Normalizer()),\n",
    "              ('regression', regression_model)]\n",
    "preprocessed_model = Pipeline(estimators)\n",
    "train_models_on_given_sample_size(preprocessed_model, features, labels, n_samples_array=[100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores with outliers removed by 1-sigma filter: \n",
      "r2 score: 0.4404498935663021\n",
      "rmse score: 0.003034414566557147\n",
      "mae score: 0.0021592306465658987\n",
      "maxae score: 0.035390213912141255\n",
      "\n",
      "\n",
      "Scores with all data (incl. outliers): \n",
      "r2 score: 0.6081998730762346\n",
      "rmse score: 0.0025391462103004363\n",
      "mae score: 0.0017673716999786135\n",
      "maxae score: 0.027288566908512002\n",
      "\n",
      "\n",
      "Scores with outliers removed by 2-sigma filter: \n",
      "r2 score: 0.5925082825055584\n",
      "rmse score: 0.0025894934456937415\n",
      "mae score: 0.0018033819467131692\n",
      "maxae score: 0.03320194821203448\n",
      "\n",
      "\n",
      "Scores with all data (incl. outliers): \n",
      "r2 score: 0.610869572762153\n",
      "rmse score: 0.00253048063774992\n",
      "mae score: 0.0017622837122290849\n",
      "maxae score: 0.02927787708931051\n",
      "\n",
      "\n",
      "Scores with outliers removed by 3-sigma filter: \n",
      "r2 score: 0.6164294160372116\n",
      "rmse score: 0.0025123380160403997\n",
      "mae score: 0.001746826357674079\n",
      "maxae score: 0.030153409116718932\n",
      "\n",
      "\n",
      "Scores with all data (incl. outliers): \n",
      "r2 score: 0.6115149513901053\n",
      "rmse score: 0.002528381346988403\n",
      "mae score: 0.0017568386856197083\n",
      "maxae score: 0.03159176440636857\n",
      "\n",
      "\n",
      "Scores with outliers removed by 4-sigma filter: \n",
      "r2 score: 0.6175159883119533\n",
      "rmse score: 0.002508777038023244\n",
      "mae score: 0.0017428954539859967\n",
      "maxae score: 0.030179614116119247\n",
      "\n",
      "\n",
      "Scores with all data (incl. outliers): \n",
      "r2 score: 0.6115996800150866\n",
      "rmse score: 0.0025281056118504745\n",
      "mae score: 0.0017562971945968868\n",
      "maxae score: 0.03096774043314543\n",
      "\n",
      "\n",
      "Scores with outliers removed by 5-sigma filter: \n",
      "r2 score: 0.6174213385182905\n",
      "rmse score: 0.0025090874307891384\n",
      "mae score: 0.0017437805133288754\n",
      "maxae score: 0.02922835862930573\n",
      "\n",
      "\n",
      "Scores with all data (incl. outliers): \n",
      "r2 score: 0.6113852914221456\n",
      "rmse score: 0.002528803245458144\n",
      "mae score: 0.0017584102241693942\n",
      "maxae score: 0.028532719258111516\n"
     ]
    }
   ],
   "source": [
    "# test outlier removal\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "def find_outliers(df, m=3):\n",
    "    \"\"\"\n",
    "    Thanks https://stackoverflow.com/questions/21448225/getting-indices-of-true-values-in-a-boolean-list\n",
    "    \"\"\"\n",
    "    from itertools import compress\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    outliers = []\n",
    "    for col in df:\n",
    "        data = df[col]\n",
    "        positions = abs(data - np.mean(data)) > m * np.std(df[col])\n",
    "        outliers.append(list(compress(range(len(positions.values)), positions.values)))\n",
    "    \n",
    "    flat_list = np.unique([item for sublist in outliers for item in sublist])\n",
    "    return flat_list\n",
    "\n",
    "def test_find_outliers():\n",
    "    import pandas as pd\n",
    "    y_train = pd.DataFrame([[1,2,3,4,5],\n",
    "                            [2,3,4,5,6],\n",
    "                            [3,4,5,6,7]])\n",
    "    return list(find_outliers(y_train, m=1)) == [0, 2] and list(find_outliers(y_train, m=2)) == []\n",
    "\n",
    "if not test_find_outliers():\n",
    "    assert(False)\n",
    "\n",
    "X_train, y_train, X_test, y_test, _, _ = set_data_size(features, labels, 100000, 80000)\n",
    "\n",
    "for sigma in [1,2,3,4,5]:\n",
    "    # find outliers in labels (voltages). If there is an outlier at any node remove the sample from the data set \n",
    "    outliers = find_outliers(pd.DataFrame(y_train), m=sigma)\n",
    "\n",
    "    outlier_free_X_train = np.array([e for i, e in enumerate(X_train) if i not in outliers])\n",
    "    outlier_free_y_train = np.array([e for i, e in enumerate(y_train) if i not in outliers])\n",
    "\n",
    "    estimators = [('regression', regression_model)]\n",
    "    preprocessed_model = Pipeline(estimators)\n",
    "    preprocessed_model.fit(outlier_free_X_train, outlier_free_y_train)\n",
    "    print(\"\\n\\nScores with outliers removed by {}-sigma filter: \".format(sigma))\n",
    "    print(\"r2 score: {}\".format(preprocessed_model.score(X_test, y_test)))\n",
    "    print(\"rmse score: {}\".format(rmse(preprocessed_model.predict(X_test), y_test)))\n",
    "    print(\"mae score: {}\".format(mae(preprocessed_model.predict(X_test), y_test)))\n",
    "    print(\"maxae score: {}\".format(maxae(preprocessed_model.predict(X_test), y_test)))\n",
    "    \n",
    "    samples_to_use = np.random.randint(0, np.array(X_train).shape[0], outlier_free_X_train.shape[0])\n",
    "    X_train_same_number_samples_as_outlier_free = pd.DataFrame(X_train).iloc[samples_to_use].values\n",
    "    y_train_same_number_samples_as_outlier_free = pd.DataFrame(y_train).iloc[samples_to_use].values\n",
    "\n",
    "    estimators = [('regression', regression_model)]\n",
    "    preprocessed_model = Pipeline(estimators)\n",
    "    preprocessed_model.fit(X_train_same_number_samples_as_outlier_free, y_train_same_number_samples_as_outlier_free)\n",
    "    print(\"\\n\\nScores with all data (incl. outliers): \".format(sigma))\n",
    "    print(\"r2 score: {}\".format(preprocessed_model.score(X_test, y_test)))\n",
    "    print(\"rmse score: {}\".format(rmse(preprocessed_model.predict(X_test), y_test)))\n",
    "    print(\"mae score: {}\".format(mae(preprocessed_model.predict(X_test), y_test)))\n",
    "    print(\"maxae score: {}\".format(maxae(preprocessed_model.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.9104\n",
       "                \n",
       "                    &plusmn; 0.0853\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.5800\n",
       "                \n",
       "                    &plusmn; 0.0346\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.74%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1351\n",
       "                \n",
       "                    &plusmn; 0.0108\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0541\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0539\n",
       "                \n",
       "                    &plusmn; 0.0046\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0511\n",
       "                \n",
       "                    &plusmn; 0.0022\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x8\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.37%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0501\n",
       "                \n",
       "                    &plusmn; 0.0028\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0459\n",
       "                \n",
       "                    &plusmn; 0.0044\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x7\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.64%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0430\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Run:  0\n",
      "n_samples for k fold cross validation:  100000\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 168.36\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_r2</th>\n",
       "      <th>rf_test_rmse</th>\n",
       "      <th>rf_test_mae</th>\n",
       "      <th>rf_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>51.063625</td>\n",
       "      <td>6.047257</td>\n",
       "      <td>0.738921</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.026894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50.108573</td>\n",
       "      <td>6.139742</td>\n",
       "      <td>0.735965</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.031112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>48.687012</td>\n",
       "      <td>6.387817</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.028867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>48.196170</td>\n",
       "      <td>5.913771</td>\n",
       "      <td>0.731674</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>49.951375</td>\n",
       "      <td>6.684309</td>\n",
       "      <td>0.739743</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.031498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>49.601351</td>\n",
       "      <td>6.234579</td>\n",
       "      <td>0.736134</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.029557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.154186</td>\n",
       "      <td>0.305262</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rf_fit_time  rf_score_time  rf_test_r2  rf_test_rmse  rf_test_mae  \\\n",
       "0       51.063625       6.047257    0.738921      0.002102     0.001278   \n",
       "1       50.108573       6.139742    0.735965      0.002116     0.001286   \n",
       "2       48.687012       6.387817    0.734366      0.002119     0.001283   \n",
       "3       48.196170       5.913771    0.731674      0.002127     0.001292   \n",
       "4       49.951375       6.684309    0.739743      0.002106     0.001279   \n",
       "mean    49.601351       6.234579    0.736134      0.002114     0.001284   \n",
       "std      1.154186       0.305262    0.003311      0.000010     0.000005   \n",
       "\n",
       "      rf_test_maxae  \n",
       "0          0.026894  \n",
       "1          0.031112  \n",
       "2          0.028867  \n",
       "3          0.029412  \n",
       "4          0.031498  \n",
       "mean       0.029557  \n",
       "std        0.001856  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "n_training_samples:  80000\n",
      "n_validation_samples:  20000\n",
      "training score:  0.9283508115354299\n",
      "validation score:  0.48855192981536966\n",
      "rmse:  0.002948983260264578\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 1.4309\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "      <th>linear_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.236396</td>\n",
       "      <td>0.212268</td>\n",
       "      <td>0.663619</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.026283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.230044</td>\n",
       "      <td>0.207291</td>\n",
       "      <td>0.657281</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.025273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.201597</td>\n",
       "      <td>0.664431</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.028306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.148471</td>\n",
       "      <td>0.200430</td>\n",
       "      <td>0.663284</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.028224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.123347</td>\n",
       "      <td>0.205913</td>\n",
       "      <td>0.667226</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.025534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.178032</td>\n",
       "      <td>0.205500</td>\n",
       "      <td>0.663168</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.026724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.051621</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.236396           0.212268        0.663619          0.002419   \n",
       "1            0.230044           0.207291        0.657281          0.002441   \n",
       "2            0.151900           0.201597        0.664431          0.002426   \n",
       "3            0.148471           0.200430        0.663284          0.002419   \n",
       "4            0.123347           0.205913        0.667226          0.002418   \n",
       "mean         0.178032           0.205500        0.663168          0.002425   \n",
       "std          0.051621           0.004747        0.003638          0.000010   \n",
       "\n",
       "      linear_test_mae  linear_test_maxae  \n",
       "0            0.001664           0.026283  \n",
       "1            0.001682           0.025273  \n",
       "2            0.001665           0.028306  \n",
       "3            0.001667           0.028224  \n",
       "4            0.001666           0.025534  \n",
       "mean         0.001669           0.026724  \n",
       "std          0.000008           0.001455  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.6625430352822904\n",
      "validation score:  0.662842151625444\n",
      "rmse:  0.002429935349548591\n",
      "\n",
      "\n",
      "SUMMARY\n",
      "\n",
      " |                   |      100000 |\n",
      "|:------------------|------------:|\n",
      "| rf_fit_time       | 49.6014     |\n",
      "| rf_score_time     |  6.23458    |\n",
      "| rf_test_r2        |  0.736134   |\n",
      "| rf_test_rmse      |  0.00211407 |\n",
      "| rf_test_mae       |  0.00128355 |\n",
      "| rf_test_maxae     |  0.0295565  |\n",
      "| linear_fit_time   |  0.178032   |\n",
      "| linear_score_time |  0.2055     |\n",
      "| linear_test_r2    |  0.663168   |\n",
      "| linear_test_rmse  |  0.00242486 |\n",
      "| linear_test_mae   |  0.00166866 |\n",
      "| linear_test_maxae |  0.0267242  |\n",
      "\n",
      "\n",
      "Run:  0\n",
      "n_samples for k fold cross validation:  100000\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 209.3\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_r2</th>\n",
       "      <th>rf_test_rmse</th>\n",
       "      <th>rf_test_mae</th>\n",
       "      <th>rf_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>61.719341</td>\n",
       "      <td>6.512179</td>\n",
       "      <td>0.770796</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.028566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>61.645916</td>\n",
       "      <td>6.416672</td>\n",
       "      <td>0.773884</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.027680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60.917179</td>\n",
       "      <td>5.948511</td>\n",
       "      <td>0.780709</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.025491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>61.611201</td>\n",
       "      <td>5.819875</td>\n",
       "      <td>0.779860</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.027651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>61.559282</td>\n",
       "      <td>5.919811</td>\n",
       "      <td>0.774046</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.025318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>61.490584</td>\n",
       "      <td>6.123409</td>\n",
       "      <td>0.775859</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.026941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.325775</td>\n",
       "      <td>0.316749</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.001451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rf_fit_time  rf_score_time  rf_test_r2  rf_test_rmse  rf_test_mae  \\\n",
       "0       61.719341       6.512179    0.770796      0.001970     0.001191   \n",
       "1       61.645916       6.416672    0.773884      0.001962     0.001187   \n",
       "2       60.917179       5.948511    0.780709      0.001923     0.001162   \n",
       "3       61.611201       5.819875    0.779860      0.001936     0.001175   \n",
       "4       61.559282       5.919811    0.774046      0.001954     0.001186   \n",
       "mean    61.490584       6.123409    0.775859      0.001949     0.001180   \n",
       "std      0.325775       0.316749    0.004253      0.000019     0.000012   \n",
       "\n",
       "      rf_test_maxae  \n",
       "0          0.028566  \n",
       "1          0.027680  \n",
       "2          0.025491  \n",
       "3          0.027651  \n",
       "4          0.025318  \n",
       "mean       0.026941  \n",
       "std        0.001451  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "n_training_samples:  80000\n",
      "n_validation_samples:  20000\n",
      "training score:  0.9390700370099386\n",
      "validation score:  0.563631123993027\n",
      "rmse:  0.002716336335245981\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 1.2891\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "      <th>linear_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.207929</td>\n",
       "      <td>0.210054</td>\n",
       "      <td>0.659628</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.028236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.194711</td>\n",
       "      <td>0.204710</td>\n",
       "      <td>0.663907</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.026751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.119295</td>\n",
       "      <td>0.211266</td>\n",
       "      <td>0.660463</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.024289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.107027</td>\n",
       "      <td>0.206197</td>\n",
       "      <td>0.662773</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.028298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.111432</td>\n",
       "      <td>0.207285</td>\n",
       "      <td>0.659625</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.026201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.148079</td>\n",
       "      <td>0.207902</td>\n",
       "      <td>0.661279</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.026755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.049024</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.207929           0.210054        0.659628          0.002436   \n",
       "1            0.194711           0.204710        0.663907          0.002424   \n",
       "2            0.119295           0.211266        0.660463          0.002425   \n",
       "3            0.107027           0.206197        0.662773          0.002426   \n",
       "4            0.111432           0.207285        0.659625          0.002426   \n",
       "mean         0.148079           0.207902        0.661279          0.002427   \n",
       "std          0.049024           0.002712        0.001954          0.000005   \n",
       "\n",
       "      linear_test_mae  linear_test_maxae  \n",
       "0            0.001681           0.028236  \n",
       "1            0.001670           0.026751  \n",
       "2            0.001671           0.024289  \n",
       "3            0.001675           0.028298  \n",
       "4            0.001679           0.026201  \n",
       "mean         0.001675           0.026755  \n",
       "std          0.000005           0.001656  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.6627849261846617\n",
      "validation score:  0.6618038909268418\n",
      "rmse:  0.0024268269847817934\n",
      "\n",
      "\n",
      "SUMMARY\n",
      "\n",
      " |                   |      100000 |\n",
      "|:------------------|------------:|\n",
      "| rf_fit_time       | 61.4906     |\n",
      "| rf_score_time     |  6.12341    |\n",
      "| rf_test_r2        |  0.775859   |\n",
      "| rf_test_rmse      |  0.00194902 |\n",
      "| rf_test_mae       |  0.00118029 |\n",
      "| rf_test_maxae     |  0.0269413  |\n",
      "| linear_fit_time   |  0.148079   |\n",
      "| linear_score_time |  0.207902   |\n",
      "| linear_test_r2    |  0.661279   |\n",
      "| linear_test_rmse  |  0.00242734 |\n",
      "| linear_test_mae   |  0.00167524 |\n",
      "| linear_test_maxae |  0.026755   |\n",
      "\n",
      "\n",
      "Run:  0\n",
      "n_samples for k fold cross validation:  100000\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 239.81\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_r2</th>\n",
       "      <th>rf_test_rmse</th>\n",
       "      <th>rf_test_mae</th>\n",
       "      <th>rf_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>75.286373</td>\n",
       "      <td>5.816095</td>\n",
       "      <td>0.795658</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.029986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>75.041183</td>\n",
       "      <td>5.626776</td>\n",
       "      <td>0.789985</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.025581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>74.031703</td>\n",
       "      <td>5.832996</td>\n",
       "      <td>0.796502</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.031028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>73.847305</td>\n",
       "      <td>5.887408</td>\n",
       "      <td>0.790026</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.026617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>73.455949</td>\n",
       "      <td>5.423605</td>\n",
       "      <td>0.795711</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.025112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>74.332503</td>\n",
       "      <td>5.717376</td>\n",
       "      <td>0.793577</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.027665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.791571</td>\n",
       "      <td>0.191399</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.002676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rf_fit_time  rf_score_time  rf_test_r2  rf_test_rmse  rf_test_mae  \\\n",
       "0       75.286373       5.816095    0.795658      0.001875     0.001129   \n",
       "1       75.041183       5.626776    0.789985      0.001899     0.001144   \n",
       "2       74.031703       5.832996    0.796502      0.001869     0.001118   \n",
       "3       73.847305       5.887408    0.790026      0.001885     0.001130   \n",
       "4       73.455949       5.423605    0.795711      0.001887     0.001139   \n",
       "mean    74.332503       5.717376    0.793577      0.001883     0.001132   \n",
       "std      0.791571       0.191399    0.003277      0.000012     0.000010   \n",
       "\n",
       "      rf_test_maxae  \n",
       "0          0.029986  \n",
       "1          0.025581  \n",
       "2          0.031028  \n",
       "3          0.026617  \n",
       "4          0.025112  \n",
       "mean       0.027665  \n",
       "std        0.002676  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "n_training_samples:  80000\n",
      "n_validation_samples:  20000\n",
      "training score:  0.9425513715741146\n",
      "validation score:  0.5939933934652444\n",
      "rmse:  0.002646767560040764\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 1.0998\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "      <th>linear_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.170956</td>\n",
       "      <td>0.192108</td>\n",
       "      <td>0.664739</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.026163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.199448</td>\n",
       "      <td>0.201695</td>\n",
       "      <td>0.660968</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.025543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.109709</td>\n",
       "      <td>0.186168</td>\n",
       "      <td>0.661821</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.028335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.131276</td>\n",
       "      <td>0.168493</td>\n",
       "      <td>0.657886</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.024635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.095788</td>\n",
       "      <td>0.188255</td>\n",
       "      <td>0.664276</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.028208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.141436</td>\n",
       "      <td>0.187344</td>\n",
       "      <td>0.661938</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.026577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.012106</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.170956           0.192108        0.664739          0.002415   \n",
       "1            0.199448           0.201695        0.660968          0.002431   \n",
       "2            0.109709           0.186168        0.661821          0.002428   \n",
       "3            0.131276           0.168493        0.657886          0.002427   \n",
       "4            0.095788           0.188255        0.664276          0.002440   \n",
       "mean         0.141436           0.187344        0.661938          0.002428   \n",
       "std          0.043100           0.012106        0.002770          0.000009   \n",
       "\n",
       "      linear_test_mae  linear_test_maxae  \n",
       "0            0.001662           0.026163  \n",
       "1            0.001675           0.025543  \n",
       "2            0.001664           0.028335  \n",
       "3            0.001668           0.024635  \n",
       "4            0.001682           0.028208  \n",
       "mean         0.001670           0.026577  \n",
       "std          0.000008           0.001640  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.6626393070674431\n",
      "validation score:  0.6625000066573127\n",
      "rmse:  0.002426639344680641\n",
      "\n",
      "\n",
      "SUMMARY\n",
      "\n",
      " |                   |      100000 |\n",
      "|:------------------|------------:|\n",
      "| rf_fit_time       | 74.3325     |\n",
      "| rf_score_time     |  5.71738    |\n",
      "| rf_test_r2        |  0.793577   |\n",
      "| rf_test_rmse      |  0.00188306 |\n",
      "| rf_test_mae       |  0.00113203 |\n",
      "| rf_test_maxae     |  0.0276649  |\n",
      "| linear_fit_time   |  0.141436   |\n",
      "| linear_score_time |  0.187344   |\n",
      "| linear_test_r2    |  0.661938   |\n",
      "| linear_test_rmse  |  0.0024283  |\n",
      "| linear_test_mae   |  0.00167015 |\n",
      "| linear_test_maxae |  0.0265768  |\n",
      "\n",
      "\n",
      "Run:  0\n",
      "n_samples for k fold cross validation:  100000\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "RF REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 286.9\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_fit_time</th>\n",
       "      <th>rf_score_time</th>\n",
       "      <th>rf_test_r2</th>\n",
       "      <th>rf_test_rmse</th>\n",
       "      <th>rf_test_mae</th>\n",
       "      <th>rf_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>88.960391</td>\n",
       "      <td>5.830247</td>\n",
       "      <td>0.802590</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.030552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>89.575397</td>\n",
       "      <td>5.473330</td>\n",
       "      <td>0.795402</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.024348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>88.778250</td>\n",
       "      <td>5.642744</td>\n",
       "      <td>0.790149</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.026848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>88.403215</td>\n",
       "      <td>5.862692</td>\n",
       "      <td>0.801521</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.025046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>91.488596</td>\n",
       "      <td>5.787717</td>\n",
       "      <td>0.798559</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.029795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>89.441170</td>\n",
       "      <td>5.719346</td>\n",
       "      <td>0.797644</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.027318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.220444</td>\n",
       "      <td>0.161178</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rf_fit_time  rf_score_time  rf_test_r2  rf_test_rmse  rf_test_mae  \\\n",
       "0       88.960391       5.830247    0.802590      0.001849     0.001113   \n",
       "1       89.575397       5.473330    0.795402      0.001869     0.001122   \n",
       "2       88.778250       5.642744    0.790149      0.001904     0.001143   \n",
       "3       88.403215       5.862692    0.801521      0.001849     0.001110   \n",
       "4       91.488596       5.787717    0.798559      0.001878     0.001130   \n",
       "mean    89.441170       5.719346    0.797644      0.001870     0.001123   \n",
       "std      1.220444       0.161178    0.005038      0.000023     0.000013   \n",
       "\n",
       "      rf_test_maxae  \n",
       "0          0.030552  \n",
       "1          0.024348  \n",
       "2          0.026848  \n",
       "3          0.025046  \n",
       "4          0.029795  \n",
       "mean       0.027318  \n",
       "std        0.002775  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "n_training_samples:  80000\n",
      "n_validation_samples:  20000\n",
      "training score:  0.9437478908058095\n",
      "validation score:  0.6077307611020948\n",
      "rmse:  0.0026049150606530496\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 1.1832\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "      <th>linear_test_maxae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.188396</td>\n",
       "      <td>0.216302</td>\n",
       "      <td>0.670750</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.028117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.197415</td>\n",
       "      <td>0.192640</td>\n",
       "      <td>0.661665</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.024642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.119720</td>\n",
       "      <td>0.179484</td>\n",
       "      <td>0.656980</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.026181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.118516</td>\n",
       "      <td>0.203470</td>\n",
       "      <td>0.664518</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.025327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.113289</td>\n",
       "      <td>0.179219</td>\n",
       "      <td>0.664921</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.028320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.147467</td>\n",
       "      <td>0.194223</td>\n",
       "      <td>0.663767</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.026517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.041672</td>\n",
       "      <td>0.015952</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.188396           0.216302        0.670750          0.002398   \n",
       "1            0.197415           0.192640        0.661665          0.002420   \n",
       "2            0.119720           0.179484        0.656980          0.002450   \n",
       "3            0.118516           0.203470        0.664518          0.002420   \n",
       "4            0.113289           0.179219        0.664921          0.002433   \n",
       "mean         0.147467           0.194223        0.663767          0.002424   \n",
       "std          0.041672           0.015952        0.005028          0.000019   \n",
       "\n",
       "      linear_test_mae  linear_test_maxae  \n",
       "0            0.001650           0.028117  \n",
       "1            0.001665           0.024642  \n",
       "2            0.001688           0.026181  \n",
       "3            0.001671           0.025327  \n",
       "4            0.001678           0.028320  \n",
       "mean         0.001671           0.026517  \n",
       "std          0.000014           0.001648  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.6614925716499267\n",
      "validation score:  0.6671086508811701\n",
      "rmse:  0.002412978792379462\n",
      "\n",
      "\n",
      "SUMMARY\n",
      "\n",
      " |                   |      100000 |\n",
      "|:------------------|------------:|\n",
      "| rf_fit_time       | 89.4412     |\n",
      "| rf_score_time     |  5.71935    |\n",
      "| rf_test_r2        |  0.797644   |\n",
      "| rf_test_rmse      |  0.00186955 |\n",
      "| rf_test_mae       |  0.00112346 |\n",
      "| rf_test_maxae     |  0.0273177  |\n",
      "| linear_fit_time   |  0.147467   |\n",
      "| linear_score_time |  0.194223   |\n",
      "| linear_test_r2    |  0.663767   |\n",
      "| linear_test_rmse  |  0.00242443 |\n",
      "| linear_test_mae   |  0.00167057 |\n",
      "| linear_test_maxae |  0.0265174  |\n"
     ]
    }
   ],
   "source": [
    "# test dimensionality reduction\n",
    "\n",
    "# first determine how many features to drop\n",
    "import eli5\n",
    "X_train, y_train, X_test, y_test, _, _ = set_data_size(features, labels, 1000, 800)\n",
    "regression_model = RandomForestRegressor(n_estimators=100, max_depth=None)\n",
    "regression_model.fit(X_train, y_train)\n",
    "perm = eli5.sklearn.PermutationImportance(regression_model, random_state=1).fit(X_train, y_train)\n",
    "display(eli5.show_weights(perm))\n",
    "\n",
    "\n",
    "# drop features using pca. Centre number of features around perm importance results, which is 3 features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "for n_features in [1,2,3,4,5]:\n",
    "    estimators = [(\"pca\", PCA()),\n",
    "                  ('regression', regression_model)]\n",
    "    preprocessed_model = Pipeline(estimators)\n",
    "    preprocessed_model.set_params(pca__n_components=n_features)\n",
    "    train_models_on_given_sample_size(preprocessed_model, features, labels, n_samples_array=[100000], prompt=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100000\n",
    "if n_samples < 100000:\n",
    "    raise ValueError(\"So you don't accidentally run this on 100 samples again\")\n",
    "\n",
    "n_training_samples = int(n_samples*(80/100))\n",
    "X_train, y_train, X_val, y_val = set_data_size(n_samples, n_training_samples)\n",
    "# remove bad label\n",
    "y_train = y_train.T[1:].T\n",
    "y_val = y_val.T[1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  6.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RF\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_r2</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>66.531391</td>\n",
       "      <td>0.622077</td>\n",
       "      <td>2.545954</td>\n",
       "      <td>0.086762</td>\n",
       "      <td>80</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_estimators': 80, 'max_depth': 29}</td>\n",
       "      <td>0.921858</td>\n",
       "      <td>0.922751</td>\n",
       "      <td>0.922099</td>\n",
       "      <td>0.922236</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>59.921115</td>\n",
       "      <td>0.734938</td>\n",
       "      <td>2.203448</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>72</td>\n",
       "      <td>98</td>\n",
       "      <td>{'n_estimators': 72, 'max_depth': 98}</td>\n",
       "      <td>0.921811</td>\n",
       "      <td>0.921741</td>\n",
       "      <td>0.921164</td>\n",
       "      <td>0.921572</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>52.694661</td>\n",
       "      <td>0.098162</td>\n",
       "      <td>2.040517</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>{'n_estimators': 64, 'max_depth': 33}</td>\n",
       "      <td>0.921495</td>\n",
       "      <td>0.921932</td>\n",
       "      <td>0.921088</td>\n",
       "      <td>0.921505</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>42.708556</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>1.667782</td>\n",
       "      <td>0.055191</td>\n",
       "      <td>52</td>\n",
       "      <td>71</td>\n",
       "      <td>{'n_estimators': 52, 'max_depth': 71}</td>\n",
       "      <td>0.920678</td>\n",
       "      <td>0.921160</td>\n",
       "      <td>0.921027</td>\n",
       "      <td>0.920955</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>49.611883</td>\n",
       "      <td>0.197651</td>\n",
       "      <td>1.920520</td>\n",
       "      <td>0.055440</td>\n",
       "      <td>60</td>\n",
       "      <td>93</td>\n",
       "      <td>{'n_estimators': 60, 'max_depth': 93}</td>\n",
       "      <td>0.920492</td>\n",
       "      <td>0.921506</td>\n",
       "      <td>0.920086</td>\n",
       "      <td>0.920695</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32.702112</td>\n",
       "      <td>0.183965</td>\n",
       "      <td>1.336063</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>{'n_estimators': 40, 'max_depth': 74}</td>\n",
       "      <td>0.918704</td>\n",
       "      <td>0.919897</td>\n",
       "      <td>0.919109</td>\n",
       "      <td>0.919237</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.698034</td>\n",
       "      <td>0.078871</td>\n",
       "      <td>0.903889</td>\n",
       "      <td>0.030214</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>{'n_estimators': 25, 'max_depth': 73}</td>\n",
       "      <td>0.915674</td>\n",
       "      <td>0.917252</td>\n",
       "      <td>0.916619</td>\n",
       "      <td>0.916515</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.139486</td>\n",
       "      <td>0.097723</td>\n",
       "      <td>0.843532</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 66}</td>\n",
       "      <td>0.915774</td>\n",
       "      <td>0.915434</td>\n",
       "      <td>0.915281</td>\n",
       "      <td>0.915496</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.422979</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.468810</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>{'n_estimators': 10, 'max_depth': 48}</td>\n",
       "      <td>0.903202</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>0.903273</td>\n",
       "      <td>0.903725</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>9</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.304425</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.322273</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 4}</td>\n",
       "      <td>0.475762</td>\n",
       "      <td>0.463664</td>\n",
       "      <td>0.459374</td>\n",
       "      <td>0.466267</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>10</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      66.531391      0.622077         2.545954        0.086762   \n",
       "5      59.921115      0.734938         2.203448        0.029155   \n",
       "7      52.694661      0.098162         2.040517        0.075283   \n",
       "9      42.708556      0.272464         1.667782        0.055191   \n",
       "6      49.611883      0.197651         1.920520        0.055440   \n",
       "4      32.702112      0.183965         1.336063        0.059603   \n",
       "1      20.698034      0.078871         0.903889        0.030214   \n",
       "2      19.139486      0.097723         0.843532        0.018133   \n",
       "3       8.422979      0.240346         0.468810        0.022842   \n",
       "8       6.304425      0.014633         0.322273        0.010596   \n",
       "\n",
       "  param_n_estimators param_max_depth                                 params  \\\n",
       "0                 80              29  {'n_estimators': 80, 'max_depth': 29}   \n",
       "5                 72              98  {'n_estimators': 72, 'max_depth': 98}   \n",
       "7                 64              33  {'n_estimators': 64, 'max_depth': 33}   \n",
       "9                 52              71  {'n_estimators': 52, 'max_depth': 71}   \n",
       "6                 60              93  {'n_estimators': 60, 'max_depth': 93}   \n",
       "4                 40              74  {'n_estimators': 40, 'max_depth': 74}   \n",
       "1                 25              73  {'n_estimators': 25, 'max_depth': 73}   \n",
       "2                 23              66  {'n_estimators': 23, 'max_depth': 66}   \n",
       "3                 10              48  {'n_estimators': 10, 'max_depth': 48}   \n",
       "8                 23               4   {'n_estimators': 23, 'max_depth': 4}   \n",
       "\n",
       "   split0_test_r2  split1_test_r2  split2_test_r2  mean_test_r2  std_test_r2  \\\n",
       "0        0.921858        0.922751        0.922099      0.922236     0.000377   \n",
       "5        0.921811        0.921741        0.921164      0.921572     0.000290   \n",
       "7        0.921495        0.921932        0.921088      0.921505     0.000345   \n",
       "9        0.920678        0.921160        0.921027      0.920955     0.000203   \n",
       "6        0.920492        0.921506        0.920086      0.920695     0.000597   \n",
       "4        0.918704        0.919897        0.919109      0.919237     0.000495   \n",
       "1        0.915674        0.917252        0.916619      0.916515     0.000648   \n",
       "2        0.915774        0.915434        0.915281      0.915496     0.000206   \n",
       "3        0.903202        0.904700        0.903273      0.903725     0.000690   \n",
       "8        0.475762        0.463664        0.459374      0.466267     0.006939   \n",
       "\n",
       "   rank_test_r2  split0_test_rmse  split1_test_rmse  split2_test_rmse  \\\n",
       "0             1          0.002894          0.002883          0.002889   \n",
       "5             2          0.002894          0.002901          0.002907   \n",
       "7             3          0.002899          0.002897          0.002909   \n",
       "9             4          0.002914          0.002911          0.002911   \n",
       "6             5          0.002919          0.002905          0.002928   \n",
       "4             6          0.002951          0.002934          0.002942   \n",
       "1             7          0.003008          0.002984          0.002990   \n",
       "2             8          0.003007          0.003020          0.003011   \n",
       "3             9          0.003218          0.003203          0.003221   \n",
       "8            10          0.007396          0.007507          0.007516   \n",
       "\n",
       "   mean_test_rmse  std_test_rmse  rank_test_rmse  \n",
       "0        0.002889       0.000004              10  \n",
       "5        0.002901       0.000005               9  \n",
       "7        0.002902       0.000005               8  \n",
       "9        0.002912       0.000001               7  \n",
       "6        0.002917       0.000009               6  \n",
       "4        0.002942       0.000007               5  \n",
       "1        0.002994       0.000010               4  \n",
       "2        0.003013       0.000005               3  \n",
       "3        0.003214       0.000008               2  \n",
       "8        0.007473       0.000054               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to  ../../pypsa/examples/ieee-13//ieee-13-with-load-gen-uniform-data-100000-samples//results/approximating_with_rf_grid_results-100000_samples-2019-09-13-07-25.csv\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "params = {\"n_estimators\": range(100), \n",
    "          \"max_depth\": [None]+[i for i in range(1, 100)]}\n",
    "grid = RandomizedSearchCV(rf, params, cv=3, n_iter=10, n_jobs=-1, refit=False,\n",
    "                          scoring={\"r2\": make_scorer(r2_score), \"rmse\": make_scorer(rmse), \"mae\": make_scorer(mae)}, \n",
    "                          iid=False, verbose=10)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\\nRF\\n\\n\")\n",
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "display(grid_results.sort_values(by=[\"rank_test_r2\"]))\n",
    "datetimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "filepath = (path_to_powerflow_data + \n",
    "            \"/results/approximating_with_rf_grid_results-{}_samples-{}.csv\".format(n_samples, datetimestamp))\n",
    "print(\"Saving to \", filepath)\n",
    "grid_results.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_r2</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.531391</td>\n",
       "      <td>0.622077</td>\n",
       "      <td>2.545954</td>\n",
       "      <td>0.086762</td>\n",
       "      <td>80</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_estimators': 80, 'max_depth': 29}</td>\n",
       "      <td>0.921858</td>\n",
       "      <td>0.922751</td>\n",
       "      <td>0.922099</td>\n",
       "      <td>0.922236</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>59.921115</td>\n",
       "      <td>0.734938</td>\n",
       "      <td>2.203448</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>72</td>\n",
       "      <td>98</td>\n",
       "      <td>{'n_estimators': 72, 'max_depth': 98}</td>\n",
       "      <td>0.921811</td>\n",
       "      <td>0.921741</td>\n",
       "      <td>0.921164</td>\n",
       "      <td>0.921572</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>52.694661</td>\n",
       "      <td>0.098162</td>\n",
       "      <td>2.040517</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>{'n_estimators': 64, 'max_depth': 33}</td>\n",
       "      <td>0.921495</td>\n",
       "      <td>0.921932</td>\n",
       "      <td>0.921088</td>\n",
       "      <td>0.921505</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>42.708556</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>1.667782</td>\n",
       "      <td>0.055191</td>\n",
       "      <td>52</td>\n",
       "      <td>71</td>\n",
       "      <td>{'n_estimators': 52, 'max_depth': 71}</td>\n",
       "      <td>0.920678</td>\n",
       "      <td>0.921160</td>\n",
       "      <td>0.921027</td>\n",
       "      <td>0.920955</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>49.611883</td>\n",
       "      <td>0.197651</td>\n",
       "      <td>1.920520</td>\n",
       "      <td>0.055440</td>\n",
       "      <td>60</td>\n",
       "      <td>93</td>\n",
       "      <td>{'n_estimators': 60, 'max_depth': 93}</td>\n",
       "      <td>0.920492</td>\n",
       "      <td>0.921506</td>\n",
       "      <td>0.920086</td>\n",
       "      <td>0.920695</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32.702112</td>\n",
       "      <td>0.183965</td>\n",
       "      <td>1.336063</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>{'n_estimators': 40, 'max_depth': 74}</td>\n",
       "      <td>0.918704</td>\n",
       "      <td>0.919897</td>\n",
       "      <td>0.919109</td>\n",
       "      <td>0.919237</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.698034</td>\n",
       "      <td>0.078871</td>\n",
       "      <td>0.903889</td>\n",
       "      <td>0.030214</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>{'n_estimators': 25, 'max_depth': 73}</td>\n",
       "      <td>0.915674</td>\n",
       "      <td>0.917252</td>\n",
       "      <td>0.916619</td>\n",
       "      <td>0.916515</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19.139486</td>\n",
       "      <td>0.097723</td>\n",
       "      <td>0.843532</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 66}</td>\n",
       "      <td>0.915774</td>\n",
       "      <td>0.915434</td>\n",
       "      <td>0.915281</td>\n",
       "      <td>0.915496</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8.422979</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.468810</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>{'n_estimators': 10, 'max_depth': 48}</td>\n",
       "      <td>0.903202</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>0.903273</td>\n",
       "      <td>0.903725</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>9</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6.304425</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.322273</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 4}</td>\n",
       "      <td>0.475762</td>\n",
       "      <td>0.463664</td>\n",
       "      <td>0.459374</td>\n",
       "      <td>0.466267</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>10</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0      66.531391      0.622077         2.545954        0.086762   \n",
       "5           5      59.921115      0.734938         2.203448        0.029155   \n",
       "7           7      52.694661      0.098162         2.040517        0.075283   \n",
       "9           9      42.708556      0.272464         1.667782        0.055191   \n",
       "6           6      49.611883      0.197651         1.920520        0.055440   \n",
       "4           4      32.702112      0.183965         1.336063        0.059603   \n",
       "1           1      20.698034      0.078871         0.903889        0.030214   \n",
       "2           2      19.139486      0.097723         0.843532        0.018133   \n",
       "3           3       8.422979      0.240346         0.468810        0.022842   \n",
       "8           8       6.304425      0.014633         0.322273        0.010596   \n",
       "\n",
       "   param_n_estimators  param_max_depth                                 params  \\\n",
       "0                  80               29  {'n_estimators': 80, 'max_depth': 29}   \n",
       "5                  72               98  {'n_estimators': 72, 'max_depth': 98}   \n",
       "7                  64               33  {'n_estimators': 64, 'max_depth': 33}   \n",
       "9                  52               71  {'n_estimators': 52, 'max_depth': 71}   \n",
       "6                  60               93  {'n_estimators': 60, 'max_depth': 93}   \n",
       "4                  40               74  {'n_estimators': 40, 'max_depth': 74}   \n",
       "1                  25               73  {'n_estimators': 25, 'max_depth': 73}   \n",
       "2                  23               66  {'n_estimators': 23, 'max_depth': 66}   \n",
       "3                  10               48  {'n_estimators': 10, 'max_depth': 48}   \n",
       "8                  23                4   {'n_estimators': 23, 'max_depth': 4}   \n",
       "\n",
       "   split0_test_r2  split1_test_r2  split2_test_r2  mean_test_r2  std_test_r2  \\\n",
       "0        0.921858        0.922751        0.922099      0.922236     0.000377   \n",
       "5        0.921811        0.921741        0.921164      0.921572     0.000290   \n",
       "7        0.921495        0.921932        0.921088      0.921505     0.000345   \n",
       "9        0.920678        0.921160        0.921027      0.920955     0.000203   \n",
       "6        0.920492        0.921506        0.920086      0.920695     0.000597   \n",
       "4        0.918704        0.919897        0.919109      0.919237     0.000495   \n",
       "1        0.915674        0.917252        0.916619      0.916515     0.000648   \n",
       "2        0.915774        0.915434        0.915281      0.915496     0.000206   \n",
       "3        0.903202        0.904700        0.903273      0.903725     0.000690   \n",
       "8        0.475762        0.463664        0.459374      0.466267     0.006939   \n",
       "\n",
       "   rank_test_r2  split0_test_rmse  split1_test_rmse  split2_test_rmse  \\\n",
       "0             1          0.002894          0.002883          0.002889   \n",
       "5             2          0.002894          0.002901          0.002907   \n",
       "7             3          0.002899          0.002897          0.002909   \n",
       "9             4          0.002914          0.002911          0.002911   \n",
       "6             5          0.002919          0.002905          0.002928   \n",
       "4             6          0.002951          0.002934          0.002942   \n",
       "1             7          0.003008          0.002984          0.002990   \n",
       "2             8          0.003007          0.003020          0.003011   \n",
       "3             9          0.003218          0.003203          0.003221   \n",
       "8            10          0.007396          0.007507          0.007516   \n",
       "\n",
       "   mean_test_rmse  std_test_rmse  rank_test_rmse  \n",
       "0        0.002889       0.000004              10  \n",
       "5        0.002901       0.000005               9  \n",
       "7        0.002902       0.000005               8  \n",
       "9        0.002912       0.000001               7  \n",
       "6        0.002917       0.000009               6  \n",
       "4        0.002942       0.000007               5  \n",
       "1        0.002994       0.000010               4  \n",
       "2        0.003013       0.000005               3  \n",
       "3        0.003214       0.000008               2  \n",
       "8        0.007473       0.000054               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for reading values if you closed the notebook\n",
    "imported_results = pd.read_csv(filepath)\n",
    "display(imported_results.sort_values(by=[\"rank_test_r2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
