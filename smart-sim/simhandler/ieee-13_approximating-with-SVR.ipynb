{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: \n",
    "\n",
    "I want to approximate the non-linear data space that makes up a PyPSA simulation. Specifically, I want to approximate a modified IEEE 13 bus topology with a uniform (grid) input. The approximation should be time sensitive.\n",
    "\n",
    "**Objective**:\n",
    "\n",
    "This notebook will only look at [support vector regression](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.htmlhttps://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) (SVR) models. Per [1], the approximation should have a root mean sqaure error < 0.002 to ensure the approximation is not the largest source of error in the simulation. A standard linear regression will be shown for baseline comparison. Since the approximation is time sensitive, a search for the ball park number of samples required for reasonable scores is performed. Once the number of samples to produce reasonable results is found, a grid search can be ran to determine optimal training parameters.\n",
    "\n",
    "**Hypothesis**: \n",
    "\n",
    "Previously, linear regression models outperformed artificial neural networks when tested on simple, small radial networks [2]. Since the modified IEEE 13 bus network contains two transformers whos behaviour can become non-linear if their power limit is exceeded (which is allowed in power flow [3]), I suspect there are two possible scenarios:\n",
    "\n",
    "1. Transformer limit not exceeded: Linear regression outperforms RF model\n",
    "2. Transformer limit exceeded: RF outperforms linear regressor because a RF model can capture non-linearity \n",
    "\n",
    "As for the number of samples required, historically 1e5-1e6 samples produces K-fold cross validation scores with low variance if the feature-label correlation is reasonable.\n",
    "\n",
    "**Experimental Procedure**:\n",
    "\n",
    "1. Determine the number of samples required to return reasonable scores with SVR K-fold cross validation. Reasonable scores is defined as:\n",
    "  * R2 > 0.8\n",
    "  * RMSE < 0.002\n",
    "  * K-fold R2 variance one degree of magnitude less than R2\n",
    "2. Using approximately that number of samples, run grid search to determine optimal parameters/hyperparameters\n",
    "\n",
    "**Results**:\n",
    "\n",
    "The model was unable to predict the first label. This is expected because the node represented by the label is a slack bus and therefore its voltage is always 1. The results for the other labels were averaged\n",
    "\n",
    "* 1e4 samples (mean R2: 0.88, std dev: 0.002)\n",
    "* 1e3 samples (mean R2: 0.87, std dev: 0.014)\n",
    "* 1e2 samples (mean R2: 0.79, std dev: 0.076)\n",
    "* 1e1 samples (mean R2: -15, std dev: 19)\n",
    "\n",
    "If the slack bus is removed the results improve by roughly 9%\n",
    "\n",
    "* 1e4 samples (mean R2: 0.96, std dev: 0.002)\n",
    "* 1e3 samples (mean R2: 0.95, std dev: 0.009)\n",
    "* 1e2 samples (mean R2: 0.87, std dev: 0.069)\n",
    "* 1e1 samples (mean R2: -16, std dev: 20)\n",
    "\n",
    "From 1e3 to 1e4 samples there is not a significant improvement in mean R2 (1%), but there is in the std dev (). From 1e2 to 1e3 it is more apparent (9%). Running a grid search with 1e3 samples produced the following results:\n",
    "\n",
    "1. Mean R2: ? std dev: ?\n",
    "2. Mean R2: ? std dev: ?\n",
    "3. .\n",
    "4. .\n",
    "\n",
    "Tried training the model on 1e5 samples for over 5 hours. Cancelled.\n",
    "\n",
    "**Discussion**:\n",
    "\n",
    "One approach to reduce the cost of simulation-based research is to copy the underlying model and evaluate the approximation [1][4].\n",
    "\n",
    "It takes roughly 7 hours to create 1e5 samples (by running PyPSA sim) on Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz\n",
    "\n",
    "\n",
    "**Bibliography**\n",
    "\n",
    "[1] https://github.com/mbardwell/masters\n",
    "\n",
    "[2] Enhancing Power Flow Simulations Using Function Mapping. Michael Bardwell ; Petr Musilek. 2019 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)\n",
    "\n",
    "[3] https://groups.google.com/forum/#!searchin/pypsa/mikey%7Csort:date/pypsa/FqfC_UR85k0/vBc7HYP_EQAJ\n",
    "\n",
    "[4] ieee-13_timing-pfsim-vs-evaluating-models.ipynb\n",
    "\n",
    "\n",
    "Table of Contents:\n",
    "* Source data\n",
    "* Analyse data\n",
    "* Setup grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypsa\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger = logging.getLogger(\"pypsa\")\n",
    "logger.setLevel(\"WARNING\")\n",
    "%matplotlib inline\n",
    "\n",
    "import copy\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import pypsa\n",
    "from n_dimensional_datasets import *\n",
    "from plotter import *\n",
    "\n",
    "from IPython.display import display # for better Pandas printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalise_column_names(df, name):\n",
    "        new_columns = []\n",
    "        for column in df.columns:\n",
    "            new_columns.append(name +  \"-\" + str(column))\n",
    "        df.columns = new_columns\n",
    "        return pd.DataFrame(df)\n",
    "\n",
    "def collect_data(path_to_powerflow_data, data):\n",
    "    '''\n",
    "    Assumes folder tree has\n",
    "    path_to_powerflow_data/\n",
    "    -->datafiles\n",
    "    -->results/\n",
    "    '''\n",
    "    data[\"loads\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"loads-p_set.csv\"), \"load\")\n",
    "    data[\"vmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"vmags.csv\"), \"vmag\")\n",
    "    data[\"vangs\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"vangs.csv\"), \"vang\")\n",
    "    data[\"qmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"qmags.csv\"), \"qmag\")\n",
    "    data[\"linemags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"linemags.csv\"), \"linemag\")\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "def set_uniform_sample_size(path_to_powerflow_data, data_to_change, n_samples, seed=None):\n",
    "    '''\n",
    "    Modifies common .csv files in PyPSA folders with uniformly sampled data \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_to_powerflow_data: string\n",
    "        ex: \"/home/user/Documents/powerflow_data/\"\n",
    "    data_to_change: list of strings.\n",
    "        ex: [\"loads-p_set\", \"generators-p_max_pu\", \"snapshots\"] \n",
    "    n_samples: int\n",
    "    \n",
    "    seed=None: int\n",
    "    '''\n",
    "\n",
    "    data = {}\n",
    "    for datatype in data_to_change:\n",
    "        data[datatype] = pd.read_csv(path_to_powerflow_data + datatype + \".csv\")\n",
    "\n",
    "    def increase_data(dataframe, n_samples, seed=None):\n",
    "        addon = {}\n",
    "        new_df_list = []\n",
    "        for idx, column in enumerate(dataframe):\n",
    "          \n",
    "            if dataframe[column].dtype == np.float64 or dataframe[column].dtype == np.int64:\n",
    "                ## special cases\n",
    "                if datatype == \"generators-p_max_pu\":\n",
    "                    # add a ridiculous amount of generation so the is always enough power and sim doesn't fail\n",
    "                    addon[column] = np.random.RandomState(seed=seed).uniform(low=100, high=200, size=n_samples)\n",
    "                elif datatype == \"snapshots\":\n",
    "                    addon[column] = np.ones(n_samples)\n",
    "                else:\n",
    "                    addon[column] = np.random.RandomState(seed=seed).uniform(low=0, high=0.5, size=n_samples)\n",
    "            elif dataframe[column].dtype == object:\n",
    "                # assuming object is datetime column\n",
    "                latest_datetime = pd.to_datetime(dataframe[column][0])\n",
    "                addon[column] = []\n",
    "                for sample in range(n_samples):\n",
    "                    addon[column].append(latest_datetime + pd.Timedelta(hours=(1+sample)))\n",
    "            else:\n",
    "                raise TypeError(\"dataframe[column] type: {} should be object or float64/int64\".format(\n",
    "                    type(dataframe[column].dtype)))\n",
    "        addon_dataframe = pd.DataFrame(addon)\n",
    "        return dataframe.head(1).append(addon_dataframe)\n",
    "\n",
    "    for datatype in data:\n",
    "        data[datatype] = increase_data(data[datatype], n_samples-1, seed) # -1 is for original sample, which stays\n",
    "        data[datatype].to_csv(path_to_powerflow_data + datatype + \".csv\", index=False)\n",
    "        print(\"Datatype {} stored\".format(datatype))\n",
    "\n",
    "def create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None):\n",
    "    import os\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "    import pypsa\n",
    "\n",
    "    if not os.path.isdir(path_to_powerflow_data):\n",
    "        src = Path(path_to_powerflow_data).parents[0] / \"ieee-13-with-load-gen/\" # original modified IEEE model\n",
    "        shutil.copytree(src, path_to_powerflow_data)\n",
    "\n",
    "    set_uniform_sample_size(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "\n",
    "    network = pypsa.Network(import_name=path_to_powerflow_data)\n",
    "    network.pf()\n",
    "\n",
    "    save_path = path_to_powerflow_data + \"results/\"\n",
    "    network.buses_t.v_mag_pu.to_csv(save_path + \"vmags.csv\")\n",
    "    network.buses_t.v_ang.to_csv(save_path + \"vangs.csv\")\n",
    "    network.buses_t.q.to_csv(save_path + \"qmags.csv\")\n",
    "    network.lines_t.p0.to_csv(save_path + \"linemags.csv\")\n",
    "    \n",
    "def backup_samples(src, dest):\n",
    "    '''\n",
    "    thanks https://www.pythoncentral.io/how-to-recursively-copy-a-directory-folder-in-python/\n",
    "    '''\n",
    "    import os\n",
    "    import errno\n",
    "    import shutil\n",
    "    \n",
    "    try:\n",
    "        if os.path.isdir(dest):\n",
    "            shutil.rmtree(dest)\n",
    "        shutil.copytree(src, dest)\n",
    "        print(\"Backup to {} successful\".format(dest))\n",
    "    except OSError as e:\n",
    "        # If the error was caused because the source wasn't a directory\n",
    "        if e.errno == errno.ENOTDIR:\n",
    "            shutil.copy(src, dest)\n",
    "        else:\n",
    "            print('Directory not copied. Error: %s' % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER INPUT\n",
    "sample_size = 100000 # this is the max number of samples available\n",
    "\n",
    "data_to_change = [\"loads-p_set\", \"snapshots\", \"loads-q_set\"]\n",
    "\n",
    "path_to_powerflow_example = \"../../pypsa/examples/ieee-13/\"\n",
    "path_to_powerflow_data = (path_to_powerflow_example +\n",
    "                          \"/ieee-13-with-load-gen-uniform-data-\"\n",
    "                          + str(sample_size) +\n",
    "                          \"-samples/\")\n",
    "path_to_powerflow_results = path_to_powerflow_data + \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Uncomment to generate load samples for modified IEEE-13 network\n",
    "# if sample_size > 10000:\n",
    "#     user = input(\"Are you sure [y/n]? This could erase hours worth of data\")\n",
    "#     if user == \"y\":\n",
    "#         backup_samples(path_to_powerflow_results, path_to_powerflow_data + \"results-backup/\")\n",
    "#         create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "# else:\n",
    "#     create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "\n",
    "data = {\"loads\": [], \"vmags\": [], \"vangs\": [], \"qmags\": [], \"linemags\": []}\n",
    "collect_data(path_to_powerflow_data, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[\"loads\"].drop(\"load-name\", axis=1)\n",
    "labels = data[\"vmags\"].drop([\"vmag-name\", \"vmag-Substation\"], axis=1) #loc[:,[\"vmag-632\", \"vmag-671\", \"vmag-675\"]]\n",
    "features_and_labels = features.join(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9a760cd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9bc89f10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9bc496d0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9bbfaed0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9bbb6710>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9bbe5f10>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9bba3750>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9bb53f50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9bb5bb10>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9a760ed0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9b116090>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9b068710>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9b099f10>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9b05a750>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9b00ef50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9afcf790>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9af82f90>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9af8eb50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9af50510>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9aebd810>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9ae7a210>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9ae2cf90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9ae5fc10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9ae1ffd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f8c9add3c50>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load-632</th>\n",
       "      <th>load-634</th>\n",
       "      <th>load-645</th>\n",
       "      <th>load-646</th>\n",
       "      <th>load-652</th>\n",
       "      <th>load-671</th>\n",
       "      <th>load-675</th>\n",
       "      <th>load-692</th>\n",
       "      <th>load-611</th>\n",
       "      <th>row average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>vmag-650</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>-0.002953</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-0.001955</td>\n",
       "      <td>-0.007134</td>\n",
       "      <td>-0.001353</td>\n",
       "      <td>-0.004306</td>\n",
       "      <td>-0.001971</td>\n",
       "      <td>-0.002970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-646</td>\n",
       "      <td>-0.196512</td>\n",
       "      <td>-0.200144</td>\n",
       "      <td>-0.487273</td>\n",
       "      <td>-0.671172</td>\n",
       "      <td>-0.211606</td>\n",
       "      <td>-0.204674</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.208235</td>\n",
       "      <td>-0.211118</td>\n",
       "      <td>-0.287779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-645</td>\n",
       "      <td>-0.219407</td>\n",
       "      <td>-0.223990</td>\n",
       "      <td>-0.546822</td>\n",
       "      <td>-0.558979</td>\n",
       "      <td>-0.235927</td>\n",
       "      <td>-0.229190</td>\n",
       "      <td>-0.223332</td>\n",
       "      <td>-0.233060</td>\n",
       "      <td>-0.236599</td>\n",
       "      <td>-0.300812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-632</td>\n",
       "      <td>-0.316812</td>\n",
       "      <td>-0.320804</td>\n",
       "      <td>-0.319882</td>\n",
       "      <td>-0.333944</td>\n",
       "      <td>-0.339195</td>\n",
       "      <td>-0.329811</td>\n",
       "      <td>-0.324215</td>\n",
       "      <td>-0.334387</td>\n",
       "      <td>-0.339914</td>\n",
       "      <td>-0.328774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-633</td>\n",
       "      <td>-0.286406</td>\n",
       "      <td>-0.512513</td>\n",
       "      <td>-0.289868</td>\n",
       "      <td>-0.302645</td>\n",
       "      <td>-0.307178</td>\n",
       "      <td>-0.298881</td>\n",
       "      <td>-0.292050</td>\n",
       "      <td>-0.303695</td>\n",
       "      <td>-0.307554</td>\n",
       "      <td>-0.322310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-634</td>\n",
       "      <td>-0.286326</td>\n",
       "      <td>-0.512387</td>\n",
       "      <td>-0.289801</td>\n",
       "      <td>-0.302548</td>\n",
       "      <td>-0.307111</td>\n",
       "      <td>-0.298800</td>\n",
       "      <td>-0.291940</td>\n",
       "      <td>-0.303616</td>\n",
       "      <td>-0.307463</td>\n",
       "      <td>-0.322221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-611</td>\n",
       "      <td>-0.157880</td>\n",
       "      <td>-0.158084</td>\n",
       "      <td>-0.155850</td>\n",
       "      <td>-0.168281</td>\n",
       "      <td>-0.463138</td>\n",
       "      <td>-0.316864</td>\n",
       "      <td>-0.313902</td>\n",
       "      <td>-0.320260</td>\n",
       "      <td>-0.600170</td>\n",
       "      <td>-0.294936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-684</td>\n",
       "      <td>-0.170285</td>\n",
       "      <td>-0.171447</td>\n",
       "      <td>-0.168631</td>\n",
       "      <td>-0.182151</td>\n",
       "      <td>-0.502244</td>\n",
       "      <td>-0.343257</td>\n",
       "      <td>-0.340429</td>\n",
       "      <td>-0.346904</td>\n",
       "      <td>-0.501052</td>\n",
       "      <td>-0.302933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-671</td>\n",
       "      <td>-0.196724</td>\n",
       "      <td>-0.199334</td>\n",
       "      <td>-0.196651</td>\n",
       "      <td>-0.210183</td>\n",
       "      <td>-0.410146</td>\n",
       "      <td>-0.399117</td>\n",
       "      <td>-0.395772</td>\n",
       "      <td>-0.403272</td>\n",
       "      <td>-0.410221</td>\n",
       "      <td>-0.313491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-692</td>\n",
       "      <td>-0.196689</td>\n",
       "      <td>-0.199299</td>\n",
       "      <td>-0.196616</td>\n",
       "      <td>-0.210148</td>\n",
       "      <td>-0.410075</td>\n",
       "      <td>-0.399049</td>\n",
       "      <td>-0.395916</td>\n",
       "      <td>-0.403413</td>\n",
       "      <td>-0.410151</td>\n",
       "      <td>-0.313484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-675</td>\n",
       "      <td>-0.187323</td>\n",
       "      <td>-0.189802</td>\n",
       "      <td>-0.187164</td>\n",
       "      <td>-0.200840</td>\n",
       "      <td>-0.391617</td>\n",
       "      <td>-0.380550</td>\n",
       "      <td>-0.479096</td>\n",
       "      <td>-0.385147</td>\n",
       "      <td>-0.391644</td>\n",
       "      <td>-0.310354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-652</td>\n",
       "      <td>-0.140446</td>\n",
       "      <td>-0.141170</td>\n",
       "      <td>-0.137119</td>\n",
       "      <td>-0.151906</td>\n",
       "      <td>-0.698675</td>\n",
       "      <td>-0.281787</td>\n",
       "      <td>-0.280290</td>\n",
       "      <td>-0.284874</td>\n",
       "      <td>-0.411965</td>\n",
       "      <td>-0.280915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-680</td>\n",
       "      <td>-0.196724</td>\n",
       "      <td>-0.199334</td>\n",
       "      <td>-0.196651</td>\n",
       "      <td>-0.210183</td>\n",
       "      <td>-0.410146</td>\n",
       "      <td>-0.399117</td>\n",
       "      <td>-0.395772</td>\n",
       "      <td>-0.403272</td>\n",
       "      <td>-0.410221</td>\n",
       "      <td>-0.313491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>column average</td>\n",
       "      <td>-0.196921</td>\n",
       "      <td>-0.232835</td>\n",
       "      <td>-0.244252</td>\n",
       "      <td>-0.269466</td>\n",
       "      <td>-0.360693</td>\n",
       "      <td>-0.299095</td>\n",
       "      <td>-0.302565</td>\n",
       "      <td>-0.302649</td>\n",
       "      <td>-0.349234</td>\n",
       "      <td>-0.284190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                load-632  load-634  load-645  load-646  load-652  load-671  \\\n",
       "vmag-650       -0.008439  0.001458 -0.002953 -0.000081 -0.001955 -0.007134   \n",
       "vmag-646       -0.196512 -0.200144 -0.487273 -0.671172 -0.211606 -0.204674   \n",
       "vmag-645       -0.219407 -0.223990 -0.546822 -0.558979 -0.235927 -0.229190   \n",
       "vmag-632       -0.316812 -0.320804 -0.319882 -0.333944 -0.339195 -0.329811   \n",
       "vmag-633       -0.286406 -0.512513 -0.289868 -0.302645 -0.307178 -0.298881   \n",
       "vmag-634       -0.286326 -0.512387 -0.289801 -0.302548 -0.307111 -0.298800   \n",
       "vmag-611       -0.157880 -0.158084 -0.155850 -0.168281 -0.463138 -0.316864   \n",
       "vmag-684       -0.170285 -0.171447 -0.168631 -0.182151 -0.502244 -0.343257   \n",
       "vmag-671       -0.196724 -0.199334 -0.196651 -0.210183 -0.410146 -0.399117   \n",
       "vmag-692       -0.196689 -0.199299 -0.196616 -0.210148 -0.410075 -0.399049   \n",
       "vmag-675       -0.187323 -0.189802 -0.187164 -0.200840 -0.391617 -0.380550   \n",
       "vmag-652       -0.140446 -0.141170 -0.137119 -0.151906 -0.698675 -0.281787   \n",
       "vmag-680       -0.196724 -0.199334 -0.196651 -0.210183 -0.410146 -0.399117   \n",
       "column average -0.196921 -0.232835 -0.244252 -0.269466 -0.360693 -0.299095   \n",
       "\n",
       "                load-675  load-692  load-611  row average  \n",
       "vmag-650       -0.001353 -0.004306 -0.001971    -0.002970  \n",
       "vmag-646       -0.199273 -0.208235 -0.211118    -0.287779  \n",
       "vmag-645       -0.223332 -0.233060 -0.236599    -0.300812  \n",
       "vmag-632       -0.324215 -0.334387 -0.339914    -0.328774  \n",
       "vmag-633       -0.292050 -0.303695 -0.307554    -0.322310  \n",
       "vmag-634       -0.291940 -0.303616 -0.307463    -0.322221  \n",
       "vmag-611       -0.313902 -0.320260 -0.600170    -0.294936  \n",
       "vmag-684       -0.340429 -0.346904 -0.501052    -0.302933  \n",
       "vmag-671       -0.395772 -0.403272 -0.410221    -0.313491  \n",
       "vmag-692       -0.395916 -0.403413 -0.410151    -0.313484  \n",
       "vmag-675       -0.479096 -0.385147 -0.391644    -0.310354  \n",
       "vmag-652       -0.280290 -0.284874 -0.411965    -0.280915  \n",
       "vmag-680       -0.395772 -0.403272 -0.410221    -0.313491  \n",
       "column average -0.302565 -0.302649 -0.349234    -0.284190  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = labels.join(features).corr()\n",
    "\n",
    "# only loads for columns\n",
    "cols = [c for i, c in enumerate(corr_matrix.columns) if corr_matrix.keys().str.contains(\"^load\", regex=True)[i]]\n",
    "reduced_corr_matrix = corr_matrix[cols]\n",
    "reduced_corr_matrix[\"row average\"] = pd.Series(reduced_corr_matrix.mean(axis=1))\n",
    "# only voltages for rows\n",
    "rows = reduced_corr_matrix.index[reduced_corr_matrix.index.str.contains(\"load\")]\n",
    "reduced_corr_matrix.drop(rows, inplace=True)\n",
    "reduced_corr_matrix = reduced_corr_matrix.append(pd.Series(reduced_corr_matrix.mean(), name=\"column average\"))\n",
    "\n",
    "display(reduced_corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from scoring import rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def set_data_size(n_samples, n_training_samples):\n",
    "    X_train, X_val, y_train, y_val, test_idx, train_idx = train_test_split(features,\n",
    "                                                                           labels,\n",
    "                                                                           range(features.shape[0]),\n",
    "                                                                           train_size=n_training_samples,\n",
    "                                                                           test_size=n_samples-n_training_samples,\n",
    "                                                                           random_state=None)\n",
    "    X_train = X_train.values\n",
    "    y_train = y_train.values\n",
    "    X_val = X_val.values\n",
    "    y_val = y_val.values\n",
    "\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine number of samples to get reasonable scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model parameters/hyperparameters\n",
    "\n",
    "'''\n",
    "dnn hyperparameters are chosen from sandbox testing. On average the model attempts to converge \n",
    "(with other parameters it sometimes gives up early).\n",
    "'''\n",
    "svr = SVR(gamma='scale', C=1.0, epsilon=0.0002, kernel='rbf')\n",
    "\n",
    "linear = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Run:  0\n",
      "n_training_samples:  80\n",
      "n_validation_samples:  20\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "SVR\n",
      "\n",
      "\n",
      "cross validation training time 0.33906\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time_label_0</th>\n",
       "      <th>score_time_label_0</th>\n",
       "      <th>test_score_label_0</th>\n",
       "      <th>fit_time_label_1</th>\n",
       "      <th>score_time_label_1</th>\n",
       "      <th>test_score_label_1</th>\n",
       "      <th>fit_time_label_2</th>\n",
       "      <th>score_time_label_2</th>\n",
       "      <th>test_score_label_2</th>\n",
       "      <th>fit_time_label_3</th>\n",
       "      <th>...</th>\n",
       "      <th>test_score_label_9</th>\n",
       "      <th>fit_time_label_10</th>\n",
       "      <th>score_time_label_10</th>\n",
       "      <th>test_score_label_10</th>\n",
       "      <th>fit_time_label_11</th>\n",
       "      <th>score_time_label_11</th>\n",
       "      <th>test_score_label_11</th>\n",
       "      <th>fit_time_label_12</th>\n",
       "      <th>score_time_label_12</th>\n",
       "      <th>test_score_label_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>-0.404138</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.881090</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.902811</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767919</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.766022</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.771251</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.767909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.030785</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>-0.138660</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.940861</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.941230</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937353</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.937015</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.937355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>-0.061851</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.918889</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.931277</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925586</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.920585</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.918964</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.925600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>-0.172559</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.929882</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.926467</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895069</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.894911</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.856707</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.895062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>-0.006380</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.770056</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.776781</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802709</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.794008</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.847214</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.802676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time_label_0  score_time_label_0  test_score_label_0  fit_time_label_1  \\\n",
       "0          0.001367            0.000628           -0.404138          0.000908   \n",
       "1          0.030785            0.000973           -0.138660          0.000912   \n",
       "2          0.001328            0.000656           -0.061851          0.000711   \n",
       "3          0.001519            0.000801           -0.172559          0.000712   \n",
       "4          0.000540            0.000441           -0.006380          0.000839   \n",
       "\n",
       "   score_time_label_1  test_score_label_1  fit_time_label_2  \\\n",
       "0            0.000521            0.881090          0.000912   \n",
       "1            0.000502            0.940861          0.000780   \n",
       "2            0.000480            0.918889          0.000669   \n",
       "3            0.000491            0.929882          0.000565   \n",
       "4            0.000594            0.770056          0.000559   \n",
       "\n",
       "   score_time_label_2  test_score_label_2  fit_time_label_3  ...  \\\n",
       "0            0.000601            0.902811          0.000664  ...   \n",
       "1            0.000466            0.941230          0.000708  ...   \n",
       "2            0.000434            0.931277          0.000601  ...   \n",
       "3            0.000415            0.926467          0.000574  ...   \n",
       "4            0.000442            0.776781          0.000539  ...   \n",
       "\n",
       "   test_score_label_9  fit_time_label_10  score_time_label_10  \\\n",
       "0            0.767919           0.000629             0.000437   \n",
       "1            0.937353           0.000651             0.000432   \n",
       "2            0.925586           0.000611             0.000425   \n",
       "3            0.895069           0.000569             0.000430   \n",
       "4            0.802709           0.000594             0.000412   \n",
       "\n",
       "   test_score_label_10  fit_time_label_11  score_time_label_11  \\\n",
       "0             0.766022           0.000663             0.000442   \n",
       "1             0.936000           0.000741             0.000477   \n",
       "2             0.920585           0.000711             0.000489   \n",
       "3             0.894911           0.000623             0.000433   \n",
       "4             0.794008           0.000604             0.000433   \n",
       "\n",
       "   test_score_label_11  fit_time_label_12  score_time_label_12  \\\n",
       "0             0.771251           0.000659             0.000434   \n",
       "1             0.937015           0.000650             0.000463   \n",
       "2             0.918964           0.000597             0.000409   \n",
       "3             0.856707           0.023688             0.000560   \n",
       "4             0.847214           0.000777             0.000524   \n",
       "\n",
       "   test_score_label_12  \n",
       "0             0.767909  \n",
       "1             0.937355  \n",
       "2             0.925600  \n",
       "3             0.895062  \n",
       "4             0.802676  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "label:  0\n",
      "training score:  -398891.1983399248\n",
      "validation score:  -368276.3536812776\n",
      "rmse:  0.05546627698395137\n",
      "label:  1\n",
      "training score:  0.5736464958564393\n",
      "validation score:  0.21199693282003174\n",
      "rmse:  0.007551526085124966\n",
      "label:  2\n",
      "training score:  0.2948369491754753\n",
      "validation score:  -0.5077203291707015\n",
      "rmse:  0.009020238977857383\n",
      "label:  3\n",
      "training score:  -7.859667987796241\n",
      "validation score:  -14.365136360019951\n",
      "rmse:  0.01892231492999851\n",
      "label:  4\n",
      "training score:  -4.298954723704377\n",
      "validation score:  -6.0733882511091\n",
      "rmse:  0.015525147125494984\n",
      "label:  5\n",
      "training score:  -4.253317115079584\n",
      "validation score:  -6.023302260185082\n",
      "rmse:  0.015468948687056944\n",
      "label:  6\n",
      "training score:  0.25464384942409357\n",
      "validation score:  -0.7923164901690274\n",
      "rmse:  0.014022642096046896\n",
      "label:  7\n",
      "training score:  0.6054600142662074\n",
      "validation score:  -0.13975106261606962\n",
      "rmse:  0.01019671004289791\n",
      "label:  8\n",
      "training score:  0.9984774240967816\n",
      "validation score:  0.7484365993282376\n",
      "rmse:  0.003966805698581141\n",
      "label:  9\n",
      "training score:  0.9984763405391334\n",
      "validation score:  0.7480176151248412\n",
      "rmse:  0.00397056810646142\n",
      "label:  10\n",
      "training score:  0.9631820132345752\n",
      "validation score:  0.5828815371314042\n",
      "rmse:  0.005119020085081781\n",
      "label:  11\n",
      "training score:  -0.3548501120890517\n",
      "validation score:  -1.355230031028229\n",
      "rmse:  0.018992550595235275\n",
      "label:  12\n",
      "training score:  0.9984774240967815\n",
      "validation score:  0.7484365993282367\n",
      "rmse:  0.0039668056985811585\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.012639\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.860111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.906727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.895310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.882817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.845123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   linear_fit_time  linear_score_time  linear_test_score\n",
       "0         0.001755           0.000474           0.860111\n",
       "1         0.001018           0.000420           0.906727\n",
       "2         0.000563           0.000378           0.895310\n",
       "3         0.000551           0.000375           0.882817\n",
       "4         0.000560           0.000400           0.845123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.9137280358009785\n",
      "validation score:  0.8674069049458768\n",
      "rmse:  0.001646198179553289\n",
      "\n",
      "\n",
      "Run:  1\n",
      "n_training_samples:  800\n",
      "n_validation_samples:  200\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "SVR\n",
      "\n",
      "\n",
      "cross validation training time 6.8781\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time_label_0</th>\n",
       "      <th>score_time_label_0</th>\n",
       "      <th>test_score_label_0</th>\n",
       "      <th>fit_time_label_1</th>\n",
       "      <th>score_time_label_1</th>\n",
       "      <th>test_score_label_1</th>\n",
       "      <th>fit_time_label_2</th>\n",
       "      <th>score_time_label_2</th>\n",
       "      <th>test_score_label_2</th>\n",
       "      <th>fit_time_label_3</th>\n",
       "      <th>...</th>\n",
       "      <th>test_score_label_9</th>\n",
       "      <th>fit_time_label_10</th>\n",
       "      <th>score_time_label_10</th>\n",
       "      <th>test_score_label_10</th>\n",
       "      <th>fit_time_label_11</th>\n",
       "      <th>score_time_label_11</th>\n",
       "      <th>test_score_label_11</th>\n",
       "      <th>fit_time_label_12</th>\n",
       "      <th>score_time_label_12</th>\n",
       "      <th>test_score_label_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>-0.041337</td>\n",
       "      <td>0.224496</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>0.961345</td>\n",
       "      <td>0.174110</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.958765</td>\n",
       "      <td>0.098003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956391</td>\n",
       "      <td>0.187610</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.957396</td>\n",
       "      <td>0.230689</td>\n",
       "      <td>0.016093</td>\n",
       "      <td>0.955812</td>\n",
       "      <td>0.167104</td>\n",
       "      <td>0.012935</td>\n",
       "      <td>0.956311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>-0.161251</td>\n",
       "      <td>0.120450</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>0.960614</td>\n",
       "      <td>0.105753</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.959537</td>\n",
       "      <td>0.180407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961784</td>\n",
       "      <td>0.237476</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>0.962050</td>\n",
       "      <td>0.166790</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.962031</td>\n",
       "      <td>0.201628</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.962187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>-0.023947</td>\n",
       "      <td>0.147391</td>\n",
       "      <td>0.039989</td>\n",
       "      <td>0.942821</td>\n",
       "      <td>0.127923</td>\n",
       "      <td>0.028219</td>\n",
       "      <td>0.941702</td>\n",
       "      <td>0.140484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944901</td>\n",
       "      <td>0.296333</td>\n",
       "      <td>0.029478</td>\n",
       "      <td>0.947705</td>\n",
       "      <td>0.225302</td>\n",
       "      <td>0.049461</td>\n",
       "      <td>0.947311</td>\n",
       "      <td>0.153859</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.945782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>-0.152011</td>\n",
       "      <td>0.223858</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.962616</td>\n",
       "      <td>0.166143</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.962554</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963718</td>\n",
       "      <td>0.232661</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.964819</td>\n",
       "      <td>0.134406</td>\n",
       "      <td>0.044381</td>\n",
       "      <td>0.961410</td>\n",
       "      <td>0.157701</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.963396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>-0.011250</td>\n",
       "      <td>0.151633</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.950752</td>\n",
       "      <td>0.127154</td>\n",
       "      <td>0.013142</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.064667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945887</td>\n",
       "      <td>0.138421</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>0.948549</td>\n",
       "      <td>0.176385</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.944803</td>\n",
       "      <td>0.124232</td>\n",
       "      <td>0.024353</td>\n",
       "      <td>0.946977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time_label_0  score_time_label_0  test_score_label_0  fit_time_label_1  \\\n",
       "0          0.001030            0.000656           -0.041337          0.224496   \n",
       "1          0.000714            0.000559           -0.161251          0.120450   \n",
       "2          0.001593            0.000464           -0.023947          0.147391   \n",
       "3          0.000955            0.000689           -0.152011          0.223858   \n",
       "4          0.000805            0.000441           -0.011250          0.151633   \n",
       "\n",
       "   score_time_label_1  test_score_label_1  fit_time_label_2  \\\n",
       "0            0.004013            0.961345          0.174110   \n",
       "1            0.009422            0.960614          0.105753   \n",
       "2            0.039989            0.942821          0.127923   \n",
       "3            0.003908            0.962616          0.166143   \n",
       "4            0.004563            0.950752          0.127154   \n",
       "\n",
       "   score_time_label_2  test_score_label_2  fit_time_label_3  ...  \\\n",
       "0            0.004127            0.958765          0.098003  ...   \n",
       "1            0.003833            0.959537          0.180407  ...   \n",
       "2            0.028219            0.941702          0.140484  ...   \n",
       "3            0.017381            0.962554          0.121875  ...   \n",
       "4            0.013142            0.948683          0.064667  ...   \n",
       "\n",
       "   test_score_label_9  fit_time_label_10  score_time_label_10  \\\n",
       "0            0.956391           0.187610             0.004374   \n",
       "1            0.961784           0.237476             0.004564   \n",
       "2            0.944901           0.296333             0.029478   \n",
       "3            0.963718           0.232661             0.013601   \n",
       "4            0.945887           0.138421             0.008377   \n",
       "\n",
       "   test_score_label_10  fit_time_label_11  score_time_label_11  \\\n",
       "0             0.957396           0.230689             0.016093   \n",
       "1             0.962050           0.166790             0.004499   \n",
       "2             0.947705           0.225302             0.049461   \n",
       "3             0.964819           0.134406             0.044381   \n",
       "4             0.948549           0.176385             0.005634   \n",
       "\n",
       "   test_score_label_11  fit_time_label_12  score_time_label_12  \\\n",
       "0             0.955812           0.167104             0.012935   \n",
       "1             0.962031           0.201628             0.005284   \n",
       "2             0.947311           0.153859             0.004582   \n",
       "3             0.961410           0.157701             0.005725   \n",
       "4             0.944803           0.124232             0.024353   \n",
       "\n",
       "   test_score_label_12  \n",
       "0             0.956311  \n",
       "1             0.962187  \n",
       "2             0.945782  \n",
       "3             0.963396  \n",
       "4             0.946977  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "label:  0\n",
      "training score:  -404598.9390780738\n",
      "validation score:  -414598.1517789576\n",
      "rmse:  0.05410832875613987\n",
      "label:  1\n",
      "training score:  0.41665275733875473\n",
      "validation score:  0.34057648821372266\n",
      "rmse:  0.008793927420683278\n",
      "label:  2\n",
      "training score:  0.03057768184307008\n",
      "validation score:  -0.06533633217975354\n",
      "rmse:  0.009897571728430197\n",
      "label:  3\n",
      "training score:  -7.540752585911884\n",
      "validation score:  -7.862868910864115\n",
      "rmse:  0.019444544043972015\n",
      "label:  4\n",
      "training score:  -4.070310623558734\n",
      "validation score:  -4.326539462361496\n",
      "rmse:  0.016547564785426013\n",
      "label:  5\n",
      "training score:  -4.039441078929949\n",
      "validation score:  -4.290228174341879\n",
      "rmse:  0.01649477922679165\n",
      "label:  6\n",
      "training score:  0.3445295159026497\n",
      "validation score:  0.27008820626569174\n",
      "rmse:  0.011205536007669513\n",
      "label:  7\n",
      "training score:  0.6606542480072028\n",
      "validation score:  0.5995833597282114\n",
      "rmse:  0.00762957691840547\n",
      "label:  8\n",
      "training score:  0.9987645986340599\n",
      "validation score:  0.9537835232829734\n",
      "rmse:  0.002254259208172381\n",
      "label:  9\n",
      "training score:  0.9987618864010832\n",
      "validation score:  0.9538270738899316\n",
      "rmse:  0.0022536539240751554\n",
      "label:  10\n",
      "training score:  0.9665276953329598\n",
      "validation score:  0.9285787071014735\n",
      "rmse:  0.0029572001994204685\n",
      "label:  11\n",
      "training score:  -0.1314331523575023\n",
      "validation score:  -0.3139679762578147\n",
      "rmse:  0.016630529664628545\n",
      "label:  12\n",
      "training score:  0.9987645986340599\n",
      "validation score:  0.9537835232829734\n",
      "rmse:  0.0022542592081723815\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.064565\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.906108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.903111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.904385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.903627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.899888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   linear_fit_time  linear_score_time  linear_test_score\n",
       "0         0.002637           0.000549           0.906108\n",
       "1         0.002035           0.000550           0.903111\n",
       "2         0.001780           0.000544           0.904385\n",
       "3         0.001600           0.000489           0.903627\n",
       "4         0.001248           0.000495           0.899888"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.9077665845281383\n",
      "validation score:  0.9048806366132508\n",
      "rmse:  0.0013710857936568197\n",
      "\n",
      "\n",
      "Run:  2\n",
      "n_training_samples:  8000\n",
      "n_validation_samples:  2000\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "SVR\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svr_xval_scores = []\n",
    "linear_xval_scores = []\n",
    "for i, n_samples in enumerate([100, 1000, 10000, 100000]):\n",
    "    current_iteration = i\n",
    "\n",
    "    n_training_samples = int(n_samples*(80/100))\n",
    "    X_train, y_train, X_val, y_val = set_data_size(n_samples, n_training_samples)\n",
    "\n",
    "    print(\"\\n\\nRun: \", current_iteration)\n",
    "    print(\"n_training_samples: \", n_training_samples)\n",
    "    print(\"n_validation_samples: \", n_samples-n_training_samples)\n",
    "    print(\"n_features: \", X_train.shape[1])\n",
    "    print(\"n_labels: \", y_train.shape[1])\n",
    "\n",
    "    ## svr - can only predict one label at a time\n",
    "    print(\"\\n\\nSVR\\n\\n\")\n",
    "    \n",
    "    time_start = time.time()\n",
    "    svr_models = []\n",
    "    for label in range(y_train.shape[1]):\n",
    "        svr_y_train = y_train.T[label].T\n",
    "        svr_xval_scores = pd.DataFrame(cross_validate(svr, \n",
    "                                                      X_train, \n",
    "                                                      svr_y_train, \n",
    "                                                      cv=5, \n",
    "                                                      n_jobs=-1, \n",
    "                                                      scoring=make_scorer(r2_score)))\n",
    "        svr_xval_scores.columns = [col + \"_label_\" + str(label) for col in svr_xval_scores.columns]\n",
    "        if label == 0:\n",
    "            svr_results = svr_xval_scores\n",
    "        else:\n",
    "            svr_results = svr_results.join(svr_xval_scores)\n",
    "        \n",
    "        svr_models.append(svr.fit(X_train, svr_y_train))\n",
    "\n",
    "    time_svr = time.time()\n",
    "    print(\"cross validation training time {:.5}\".format(time_svr-time_start))\n",
    "    print(\"cross validation training scores: \")\n",
    "    display(svr_results)\n",
    "\n",
    "    print(\"non-cross validation model scores for reference:\")\n",
    "    for label in range(y_train.shape[1]):\n",
    "        print(\"label: \", label)\n",
    "        print(\"training score: \", r2_score(y_train.T[label].T, svr.predict(X_train)))\n",
    "        print(\"validation score: \", r2_score(y_val.T[label].T, svr.predict(X_val)))\n",
    "        print(\"rmse: \", rmse(y_val.T[label].T, svr.predict(X_val)))\n",
    "\n",
    "    ## linear regression\n",
    "    print(\"\\n\\nLINEAR REGRESSION\\n\\n\")\n",
    "    time_start = time.time()\n",
    "    linear_xval_scores.append(cross_validate(linear,\n",
    "                                             X_train,\n",
    "                                             y_train,\n",
    "                                             cv=5,\n",
    "                                             n_jobs=-1,\n",
    "                                             scoring=make_scorer(r2_score)))\n",
    "\n",
    "    time_linear = time.time()\n",
    "    print(\"cross validation training time {:.5}\".format(time_linear-time_start))\n",
    "    print(\"cross validation training scores: \")\n",
    "    linear_results = pd.DataFrame(linear_xval_scores[current_iteration])\n",
    "    linear_results.columns = [\"linear_\"+col for col in linear_results.columns]\n",
    "    display(linear_results)\n",
    "\n",
    "    linear.fit(X_train, y_train)\n",
    "    print(\"non-cross validation model scores for reference:\")\n",
    "    print(\"training score: \", r2_score(y_train, linear.predict(X_train)))\n",
    "    print(\"validation score: \", r2_score(y_val, linear.predict(X_val)))\n",
    "    print(\"rmse: \", rmse(linear.predict(X_val), y_val))\n",
    "\n",
    "    ## model statistics\n",
    "    datetimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "    results_to_save = linear_results.join(svr_results).round(3)\n",
    "    results_to_save.to_csv(path_to_powerflow_data + \n",
    "                           \"/results/approximating_with_svr_results-{}_samples-{}.csv\".format(n_samples, \n",
    "                                                                                             datetimestamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing results for calculating mean/std\n",
    "\n",
    "This is different than the RF/DNN notebooks because there are more numbers to crunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.88242 std: 0.0019049 for labels from 0 to 12\n",
      "mean: 0.87425 std: 0.013803 for labels from 0 to 12\n",
      "mean: 0.7944 std: 0.075523 for labels from 0 to 12\n",
      "mean: -14.923 std: 18.887 for labels from 0 to 12\n",
      "mean: 0.95605 std: 0.0019939 for labels from 1 to 12\n",
      "mean: 0.95358 std: 0.0088948 for labels from 1 to 12\n",
      "mean: 0.87367 std: 0.069082 for labels from 1 to 12\n",
      "mean: -15.676 std: 19.772 for labels from 1 to 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_score</th>\n",
       "      <th>fit_time_label_0</th>\n",
       "      <th>score_time_label_0</th>\n",
       "      <th>test_score_label_0</th>\n",
       "      <th>fit_time_label_1</th>\n",
       "      <th>score_time_label_1</th>\n",
       "      <th>test_score_label_1</th>\n",
       "      <th>...</th>\n",
       "      <th>test_score_label_9</th>\n",
       "      <th>fit_time_label_10</th>\n",
       "      <th>score_time_label_10</th>\n",
       "      <th>test_score_label_10</th>\n",
       "      <th>fit_time_label_11</th>\n",
       "      <th>score_time_label_11</th>\n",
       "      <th>test_score_label_11</th>\n",
       "      <th>fit_time_label_12</th>\n",
       "      <th>score_time_label_12</th>\n",
       "      <th>test_score_label_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>162.387</td>\n",
       "      <td>1.073</td>\n",
       "      <td>0.961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960</td>\n",
       "      <td>68.145</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.961</td>\n",
       "      <td>67.372</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.964</td>\n",
       "      <td>70.088</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>159.017</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957</td>\n",
       "      <td>68.869</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.959</td>\n",
       "      <td>65.471</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.963</td>\n",
       "      <td>67.659</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>163.874</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956</td>\n",
       "      <td>68.181</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.957</td>\n",
       "      <td>67.798</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.961</td>\n",
       "      <td>69.363</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>163.062</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956</td>\n",
       "      <td>68.627</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.957</td>\n",
       "      <td>67.603</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.961</td>\n",
       "      <td>68.765</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>96.826</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958</td>\n",
       "      <td>67.617</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.959</td>\n",
       "      <td>67.553</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.963</td>\n",
       "      <td>68.641</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  linear_fit_time  linear_score_time  linear_test_score  \\\n",
       "0           0            0.010              0.001              0.905   \n",
       "1           1            0.010              0.001              0.906   \n",
       "2           2            0.016              0.002              0.906   \n",
       "3           3            0.009              0.001              0.905   \n",
       "4           4            0.006              0.001              0.905   \n",
       "\n",
       "   fit_time_label_0  score_time_label_0  test_score_label_0  fit_time_label_1  \\\n",
       "0             0.004               0.001              -0.000           162.387   \n",
       "1             0.003               0.001              -0.001           159.017   \n",
       "2             0.003               0.001              -0.002           163.874   \n",
       "3             0.003               0.001              -0.001           163.062   \n",
       "4             0.002               0.001              -0.002            96.826   \n",
       "\n",
       "   score_time_label_1  test_score_label_1  ...  test_score_label_9  \\\n",
       "0               1.073               0.961  ...               0.960   \n",
       "1               0.999               0.956  ...               0.957   \n",
       "2               0.829               0.962  ...               0.956   \n",
       "3               0.941               0.957  ...               0.956   \n",
       "4               0.651               0.959  ...               0.958   \n",
       "\n",
       "   fit_time_label_10  score_time_label_10  test_score_label_10  \\\n",
       "0             68.145                0.441                0.961   \n",
       "1             68.869                0.444                0.959   \n",
       "2             68.181                0.431                0.957   \n",
       "3             68.627                0.449                0.957   \n",
       "4             67.617                0.483                0.959   \n",
       "\n",
       "   fit_time_label_11  score_time_label_11  test_score_label_11  \\\n",
       "0             67.372                0.433                0.964   \n",
       "1             65.471                0.436                0.963   \n",
       "2             67.798                0.445                0.961   \n",
       "3             67.603                0.449                0.961   \n",
       "4             67.553                0.454                0.963   \n",
       "\n",
       "   fit_time_label_12  score_time_label_12  test_score_label_12  \n",
       "0             70.088                0.460                0.959  \n",
       "1             67.659                0.419                0.957  \n",
       "2             69.363                0.530                0.956  \n",
       "3             68.765                0.535                0.956  \n",
       "4             68.641                0.433                0.958  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_score</th>\n",
       "      <th>fit_time_label_0</th>\n",
       "      <th>score_time_label_0</th>\n",
       "      <th>test_score_label_0</th>\n",
       "      <th>fit_time_label_1</th>\n",
       "      <th>score_time_label_1</th>\n",
       "      <th>test_score_label_1</th>\n",
       "      <th>...</th>\n",
       "      <th>test_score_label_9</th>\n",
       "      <th>fit_time_label_10</th>\n",
       "      <th>score_time_label_10</th>\n",
       "      <th>test_score_label_10</th>\n",
       "      <th>fit_time_label_11</th>\n",
       "      <th>score_time_label_11</th>\n",
       "      <th>test_score_label_11</th>\n",
       "      <th>fit_time_label_12</th>\n",
       "      <th>score_time_label_12</th>\n",
       "      <th>test_score_label_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  linear_fit_time  linear_score_time  linear_test_score  \\\n",
       "0           0            0.003              0.001              0.906   \n",
       "1           1            0.002              0.001              0.903   \n",
       "2           2            0.002              0.001              0.904   \n",
       "3           3            0.002              0.000              0.904   \n",
       "4           4            0.001              0.000              0.900   \n",
       "\n",
       "   fit_time_label_0  score_time_label_0  test_score_label_0  fit_time_label_1  \\\n",
       "0             0.001               0.001              -0.041             0.224   \n",
       "1             0.001               0.001              -0.161             0.120   \n",
       "2             0.002               0.000              -0.024             0.147   \n",
       "3             0.001               0.001              -0.152             0.224   \n",
       "4             0.001               0.000              -0.011             0.152   \n",
       "\n",
       "   score_time_label_1  test_score_label_1  ...  test_score_label_9  \\\n",
       "0               0.004               0.961  ...               0.956   \n",
       "1               0.009               0.961  ...               0.962   \n",
       "2               0.040               0.943  ...               0.945   \n",
       "3               0.004               0.963  ...               0.964   \n",
       "4               0.005               0.951  ...               0.946   \n",
       "\n",
       "   fit_time_label_10  score_time_label_10  test_score_label_10  \\\n",
       "0              0.188                0.004                0.957   \n",
       "1              0.237                0.005                0.962   \n",
       "2              0.296                0.029                0.948   \n",
       "3              0.233                0.014                0.965   \n",
       "4              0.138                0.008                0.949   \n",
       "\n",
       "   fit_time_label_11  score_time_label_11  test_score_label_11  \\\n",
       "0              0.231                0.016                0.956   \n",
       "1              0.167                0.004                0.962   \n",
       "2              0.225                0.049                0.947   \n",
       "3              0.134                0.044                0.961   \n",
       "4              0.176                0.006                0.945   \n",
       "\n",
       "   fit_time_label_12  score_time_label_12  test_score_label_12  \n",
       "0              0.167                0.013                0.956  \n",
       "1              0.202                0.005                0.962  \n",
       "2              0.154                0.005                0.946  \n",
       "3              0.158                0.006                0.963  \n",
       "4              0.124                0.024                0.947  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mean_and_std(results_dataframe, label_min):\n",
    "    scores = imported_results.loc[:,[\"test_score_label_\" + str(i) for i in range(label_min,13)]]\n",
    "    means = scores.mean()\n",
    "    stds = scores.std()\n",
    "    the_mean = np.mean(means)\n",
    "    the_std = np.mean(stds)\n",
    "    print(\"mean: {:.5} std: {:.5} for labels from {} to 12\".format(the_mean, the_std, label_min))\n",
    "\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-10000_samples-2019-09-12-00-21.csv\")\n",
    "imported_results_hold1 = imported_results\n",
    "mean_and_std(imported_results, 0)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-1000_samples-2019-09-11-23-22.csv\")\n",
    "imported_results_hold2 = imported_results\n",
    "mean_and_std(imported_results, 0)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-100_samples-2019-09-11-23-22.csv\")\n",
    "mean_and_std(imported_results, 0)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-10_samples-2019-09-11-23-20.csv\")\n",
    "mean_and_std(imported_results, 0)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-10000_samples-2019-09-12-00-21.csv\")\n",
    "mean_and_std(imported_results, 1)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-1000_samples-2019-09-11-23-22.csv\")\n",
    "mean_and_std(imported_results, 1)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-100_samples-2019-09-11-23-22.csv\")\n",
    "mean_and_std(imported_results, 1)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-10_samples-2019-09-11-23-20.csv\")\n",
    "mean_and_std(imported_results, 1)\n",
    "\n",
    "display(imported_results_hold1)\n",
    "display(imported_results_hold2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "if n_samples < 10000:\n",
    "    raise ValueError(\"So you don't accidentally run this on 100 samples again\")\n",
    "n_training_samples = int(n_samples*(80/100))\n",
    "X_train, y_train, X_val, y_val = set_data_size(n_samples, n_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 10.6min\n"
     ]
    }
   ],
   "source": [
    "svr = SVR()\n",
    "params = {\"gamma\": [\"auto\", \"scale\"], \n",
    "          \"C\": [i*5/1000 for i in range(0,1000)], # min: 0, max: 5\n",
    "          \"epsilon\": [i*2/1000000 for i in range(1,1000)], # min: 2e-6, max: 2e-3\n",
    "          \"kernel\": [\"rbf\", \"poly\", \"sigmoid\", \"linear\"],\n",
    "          \"tol\": [1e-3] # min: 1e-6, max: 1e-3\n",
    "         }\n",
    "\n",
    "\n",
    "for label in range(1, y_train.shape[1]):\n",
    "    svr_y_train = y_train.T[label].T\n",
    "\n",
    "    grid = RandomizedSearchCV(svr, params, cv=5, n_iter=30, n_jobs=-1, refit=False,\n",
    "                      scoring={\"r2\": make_scorer(r2_score), \"rmse\": make_scorer(rmse)}, iid=False, verbose=10)\n",
    "\n",
    "    grid.fit(X_train, svr_y_train)\n",
    "\n",
    "    print(\"\\n\\nSVR\\n\\n\")\n",
    "    grid_results = pd.DataFrame(grid.cv_results_)\n",
    "    display(grid_results.sort_values(by=[\"rank_test_r2\"]))\n",
    "    datetimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "    filepath = (path_to_powerflow_data + \n",
    "                \"/results/approximating_with_svr_grid_results-{}_samples-{}_label-{}.csv\".format(\n",
    "                    n_samples, datetimestamp, label))\n",
    "    print(\"Saving to \", filepath)\n",
    "    grid_results.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_epsilon</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_r2</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>split3_test_r2</th>\n",
       "      <th>split4_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>split3_test_rmse</th>\n",
       "      <th>split4_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.00641</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>3.230</td>\n",
       "      <td>{'tol': 0.00641, 'kernel': 'rbf', 'gamma': 'au...</td>\n",
       "      <td>0.300632</td>\n",
       "      <td>0.321616</td>\n",
       "      <td>0.320192</td>\n",
       "      <td>0.323132</td>\n",
       "      <td>0.325418</td>\n",
       "      <td>0.318198</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>0.008841</td>\n",
       "      <td>0.008676</td>\n",
       "      <td>0.008804</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.00824</td>\n",
       "      <td>poly</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>4.630</td>\n",
       "      <td>{'tol': 0.00824, 'kernel': 'poly', 'gamma': 's...</td>\n",
       "      <td>0.092631</td>\n",
       "      <td>0.283887</td>\n",
       "      <td>0.244285</td>\n",
       "      <td>0.276795</td>\n",
       "      <td>0.296674</td>\n",
       "      <td>0.238855</td>\n",
       "      <td>0.075128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010286</td>\n",
       "      <td>0.009083</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>poly</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.065</td>\n",
       "      <td>{'tol': 0.0014, 'kernel': 'poly', 'gamma': 'sc...</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.014644</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>-0.012070</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.00255</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>3.310</td>\n",
       "      <td>{'tol': 0.00255, 'kernel': 'sigmoid', 'gamma':...</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.014644</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>-0.012070</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.013998</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>3.900</td>\n",
       "      <td>{'tol': 9e-05, 'kernel': 'sigmoid', 'gamma': '...</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.014644</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>-0.012070</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.015116</td>\n",
       "      <td>0.00645</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>3.740</td>\n",
       "      <td>{'tol': 0.00645, 'kernel': 'rbf', 'gamma': 'sc...</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.014644</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>-0.012070</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.00577</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.570</td>\n",
       "      <td>{'tol': 0.00577, 'kernel': 'sigmoid', 'gamma':...</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.014644</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>-0.012070</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.00539</td>\n",
       "      <td>poly</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>3.990</td>\n",
       "      <td>{'tol': 0.00539, 'kernel': 'poly', 'gamma': 'a...</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.014644</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>-0.012070</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.00650</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.080</td>\n",
       "      <td>{'tol': 0.0065, 'kernel': 'sigmoid', 'gamma': ...</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.014644</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>-0.012070</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>9</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00682</td>\n",
       "      <td>poly</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.1702</td>\n",
       "      <td>3.685</td>\n",
       "      <td>{'tol': 0.00682, 'kernel': 'poly', 'gamma': 'a...</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.014644</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>-0.012070</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6           6       0.004027      0.003173         0.001795        0.000185   \n",
       "4           4       0.002008      0.000317         0.008344        0.008668   \n",
       "1           1       0.001963      0.000263         0.001557        0.000138   \n",
       "0           0       0.003453      0.001175         0.003422        0.003401   \n",
       "2           2       0.002120      0.000141         0.008455        0.013998   \n",
       "7           7       0.002677      0.001642         0.011723        0.015116   \n",
       "8           8       0.004473      0.004843         0.001540        0.000016   \n",
       "9           9       0.005063      0.006830         0.004357        0.004945   \n",
       "5           5       0.002014      0.000119         0.001459        0.000043   \n",
       "3           3       0.001501      0.000087         0.001492        0.000031   \n",
       "\n",
       "   param_tol param_kernel param_gamma  param_epsilon  param_C  \\\n",
       "6    0.00641          rbf        auto         0.0282    3.230   \n",
       "4    0.00824         poly       scale         0.0242    4.630   \n",
       "1    0.00140         poly       scale         0.0940    0.065   \n",
       "0    0.00255      sigmoid       scale         0.1110    3.310   \n",
       "2    0.00009      sigmoid       scale         0.0562    3.900   \n",
       "7    0.00645          rbf       scale         0.0504    3.740   \n",
       "8    0.00577      sigmoid       scale         0.1376    0.570   \n",
       "9    0.00539         poly        auto         0.0604    3.990   \n",
       "5    0.00650      sigmoid       scale         0.0926    0.080   \n",
       "3    0.00682         poly        auto         0.1702    3.685   \n",
       "\n",
       "                                              params  split0_test_r2  \\\n",
       "6  {'tol': 0.00641, 'kernel': 'rbf', 'gamma': 'au...        0.300632   \n",
       "4  {'tol': 0.00824, 'kernel': 'poly', 'gamma': 's...        0.092631   \n",
       "1  {'tol': 0.0014, 'kernel': 'poly', 'gamma': 'sc...       -0.000622   \n",
       "0  {'tol': 0.00255, 'kernel': 'sigmoid', 'gamma':...       -0.000622   \n",
       "2  {'tol': 9e-05, 'kernel': 'sigmoid', 'gamma': '...       -0.000622   \n",
       "7  {'tol': 0.00645, 'kernel': 'rbf', 'gamma': 'sc...       -0.000622   \n",
       "8  {'tol': 0.00577, 'kernel': 'sigmoid', 'gamma':...       -0.000622   \n",
       "9  {'tol': 0.00539, 'kernel': 'poly', 'gamma': 'a...       -0.000622   \n",
       "5  {'tol': 0.0065, 'kernel': 'sigmoid', 'gamma': ...       -0.000622   \n",
       "3  {'tol': 0.00682, 'kernel': 'poly', 'gamma': 'a...       -0.000622   \n",
       "\n",
       "   split1_test_r2  split2_test_r2  split3_test_r2  split4_test_r2  \\\n",
       "6        0.321616        0.320192        0.323132        0.325418   \n",
       "4        0.283887        0.244285        0.276795        0.296674   \n",
       "1       -0.016433       -0.009225       -0.014644       -0.019426   \n",
       "0       -0.016433       -0.009225       -0.014644       -0.019426   \n",
       "2       -0.016433       -0.009225       -0.014644       -0.019426   \n",
       "7       -0.016433       -0.009225       -0.014644       -0.019426   \n",
       "8       -0.016433       -0.009225       -0.014644       -0.019426   \n",
       "9       -0.016433       -0.009225       -0.014644       -0.019426   \n",
       "5       -0.016433       -0.009225       -0.014644       -0.019426   \n",
       "3       -0.016433       -0.009225       -0.014644       -0.019426   \n",
       "\n",
       "   mean_test_r2  std_test_r2  rank_test_r2  split0_test_rmse  \\\n",
       "6      0.318198     0.008952             1          0.009030   \n",
       "4      0.238855     0.075128             2          0.010286   \n",
       "1     -0.012070     0.006617             3          0.010801   \n",
       "0     -0.012070     0.006617             4          0.010801   \n",
       "2     -0.012070     0.006617             4          0.010801   \n",
       "7     -0.012070     0.006617             4          0.010801   \n",
       "8     -0.012070     0.006617             4          0.010801   \n",
       "9     -0.012070     0.006617             4          0.010801   \n",
       "5     -0.012070     0.006617             9          0.010801   \n",
       "3     -0.012070     0.006617            10          0.010801   \n",
       "\n",
       "   split1_test_rmse  split2_test_rmse  split3_test_rmse  split4_test_rmse  \\\n",
       "6          0.008841          0.008676          0.008804          0.008927   \n",
       "4          0.009083          0.009148          0.009100          0.009115   \n",
       "1          0.010821          0.010571          0.010779          0.010974   \n",
       "0          0.010821          0.010571          0.010779          0.010974   \n",
       "2          0.010821          0.010571          0.010779          0.010974   \n",
       "7          0.010821          0.010571          0.010779          0.010974   \n",
       "8          0.010821          0.010571          0.010779          0.010974   \n",
       "9          0.010821          0.010571          0.010779          0.010974   \n",
       "5          0.010821          0.010571          0.010779          0.010974   \n",
       "3          0.010821          0.010571          0.010779          0.010974   \n",
       "\n",
       "   mean_test_rmse  std_test_rmse  rank_test_rmse  \n",
       "6        0.008856       0.000119              10  \n",
       "4        0.009346       0.000470               9  \n",
       "1        0.010789       0.000129               8  \n",
       "0        0.010789       0.000129               2  \n",
       "2        0.010789       0.000129               2  \n",
       "7        0.010789       0.000129               2  \n",
       "8        0.010789       0.000129               2  \n",
       "9        0.010789       0.000129               2  \n",
       "5        0.010789       0.000129               2  \n",
       "3        0.010789       0.000129               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for reading values if you closed the notebook\n",
    "# filepath = (path_to_powerflow_data +\n",
    "#            \"/results/approximating_with_svr_grid_results-10000_samples-2019-09-12-21-08_label-12.csv\")\n",
    "imported_results = pd.read_csv(filepath)\n",
    "display(imported_results.sort_values(by=[\"rank_test_r2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
