{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: \n",
    "\n",
    "I want to approximate the non-linear data space that makes up a PyPSA simulation. Specifically, I want to approximate a modified IEEE 13 bus topology with a uniform (grid) input. The approximation should be time sensitive.\n",
    "\n",
    "**Objective**:\n",
    "\n",
    "This notebook will only look at [support vector regression](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.htmlhttps://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) (SVR) models. Per [1], the approximation should have a root mean sqaure error < 0.002 to ensure the approximation is not the largest source of error in the simulation. A standard linear regression will be shown for baseline comparison. Since the approximation is time sensitive, a search for the ball park number of samples required for reasonable scores is performed. Once the number of samples to produce reasonable results is found, a grid search can be ran to determine optimal training parameters.\n",
    "\n",
    "**Hypothesis**: \n",
    "\n",
    "Previously, linear regression models outperformed artificial neural networks when tested on simple, small radial networks [2]. Since the modified IEEE 13 bus network contains two transformers whos behaviour can become non-linear if their power limit is exceeded (which is allowed in power flow [3]), I suspect there are two possible scenarios:\n",
    "\n",
    "1. Transformer limit not exceeded: Linear regression outperforms RF model\n",
    "2. Transformer limit exceeded: RF outperforms linear regressor because a RF model can capture non-linearity \n",
    "\n",
    "As for the number of samples required, historically 1e5-1e6 samples produces K-fold cross validation scores with low variance if the feature-label correlation is reasonable.\n",
    "\n",
    "**Experimental Procedure**:\n",
    "\n",
    "1. Determine the number of samples required to return reasonable scores with SVR K-fold cross validation. Reasonable scores is defined as:\n",
    "  * R2 > 0.8\n",
    "  * RMSE < 0.002\n",
    "  * K-fold R2 variance one degree of magnitude less than R2\n",
    "2. Using approximately that number of samples, run grid search to determine optimal parameters/hyperparameters\n",
    "\n",
    "**Results**:\n",
    "\n",
    "The model was unable to predict the first label. This is expected because the node represented by the label is a slack bus and therefore its voltage is always 1. The results for the other labels were averaged\n",
    "\n",
    "* 1e4 samples (mean R2: 0.88, std dev: 0.002)\n",
    "* 1e3 samples (mean R2: 0.87, std dev: 0.014)\n",
    "* 1e2 samples (mean R2: 0.79, std dev: 0.076)\n",
    "* 1e1 samples (mean R2: -15, std dev: 19)\n",
    "\n",
    "If the slack bus is removed the results improve by roughly 9%\n",
    "\n",
    "* 1e4 samples (mean R2: 0.96, std dev: 0.002)\n",
    "* 1e3 samples (mean R2: 0.95, std dev: 0.009)\n",
    "* 1e2 samples (mean R2: 0.87, std dev: 0.069)\n",
    "* 1e1 samples (mean R2: -16, std dev: 20)\n",
    "\n",
    "From 1e3 to 1e4 samples there is not a significant improvement in mean R2 (1%), but there is in the std dev (). From 1e2 to 1e3 it is more apparent (9%). Running a grid search with 1e3 samples produced the following results:\n",
    "\n",
    "1. Mean R2: ? std dev: ?\n",
    "2. Mean R2: ? std dev: ?\n",
    "3. .\n",
    "4. .\n",
    "\n",
    "Tried training the model on 1e5 samples for over 5 hours. Cancelled.\n",
    "\n",
    "**Discussion**:\n",
    "\n",
    "One approach to reduce the cost of simulation-based research is to copy the underlying model and evaluate the approximation [1][4].\n",
    "\n",
    "It takes roughly 7 hours to create 1e5 samples (by running PyPSA sim) on Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz\n",
    "\n",
    "\n",
    "**Bibliography**\n",
    "\n",
    "[1] https://github.com/mbardwell/masters\n",
    "\n",
    "[2] Enhancing Power Flow Simulations Using Function Mapping. Michael Bardwell ; Petr Musilek. 2019 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)\n",
    "\n",
    "[3] https://groups.google.com/forum/#!searchin/pypsa/mikey%7Csort:date/pypsa/FqfC_UR85k0/vBc7HYP_EQAJ\n",
    "\n",
    "[4] ieee-13_timing-pfsim-vs-evaluating-models.ipynb\n",
    "\n",
    "\n",
    "Table of Contents:\n",
    "* Source data\n",
    "* Analyse data\n",
    "* Setup grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypsa\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger = logging.getLogger(\"pypsa\")\n",
    "logger.setLevel(\"WARNING\")\n",
    "%matplotlib inline\n",
    "\n",
    "import copy\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import pypsa\n",
    "from n_dimensional_datasets import *\n",
    "from plotter import *\n",
    "\n",
    "from IPython.display import display # for better Pandas printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalise_column_names(df, name):\n",
    "        new_columns = []\n",
    "        for column in df.columns:\n",
    "            new_columns.append(name +  \"-\" + str(column))\n",
    "        df.columns = new_columns\n",
    "        return pd.DataFrame(df)\n",
    "\n",
    "def collect_data(path_to_powerflow_data, data):\n",
    "    '''\n",
    "    Assumes folder tree has\n",
    "    path_to_powerflow_data/\n",
    "    -->datafiles\n",
    "    -->results/\n",
    "    '''\n",
    "    data[\"loads\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"loads-p_set.csv\"), \"load\")\n",
    "    data[\"vmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"vmags.csv\"), \"vmag\")\n",
    "    data[\"vangs\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"vangs.csv\"), \"vang\")\n",
    "    data[\"qmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"qmags.csv\"), \"qmag\")\n",
    "    data[\"linemags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"results/\" + \"linemags.csv\"), \"linemag\")\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "def set_uniform_sample_size(path_to_powerflow_data, data_to_change, n_samples, seed=None):\n",
    "    '''\n",
    "    Modifies common .csv files in PyPSA folders with uniformly sampled data \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_to_powerflow_data: string\n",
    "        ex: \"/home/user/Documents/powerflow_data/\"\n",
    "    data_to_change: list of strings.\n",
    "        ex: [\"loads-p_set\", \"generators-p_max_pu\", \"snapshots\"] \n",
    "    n_samples: int\n",
    "    \n",
    "    seed=None: int\n",
    "    '''\n",
    "\n",
    "    data = {}\n",
    "    for datatype in data_to_change:\n",
    "        data[datatype] = pd.read_csv(path_to_powerflow_data + datatype + \".csv\")\n",
    "\n",
    "    def increase_data(dataframe, n_samples, seed=None):\n",
    "        addon = {}\n",
    "        new_df_list = []\n",
    "        for idx, column in enumerate(dataframe):\n",
    "          \n",
    "            if dataframe[column].dtype == np.float64 or dataframe[column].dtype == np.int64:\n",
    "                ## special cases\n",
    "                if datatype == \"generators-p_max_pu\":\n",
    "                    # add a ridiculous amount of generation so the is always enough power and sim doesn't fail\n",
    "                    addon[column] = np.random.RandomState(seed=seed).uniform(low=100, high=200, size=n_samples)\n",
    "                elif datatype == \"snapshots\":\n",
    "                    addon[column] = np.ones(n_samples)\n",
    "                else:\n",
    "                    addon[column] = np.random.RandomState(seed=seed).uniform(low=0, high=0.5, size=n_samples)\n",
    "            elif dataframe[column].dtype == object:\n",
    "                # assuming object is datetime column\n",
    "                latest_datetime = pd.to_datetime(dataframe[column][0])\n",
    "                addon[column] = []\n",
    "                for sample in range(n_samples):\n",
    "                    addon[column].append(latest_datetime + pd.Timedelta(hours=(1+sample)))\n",
    "            else:\n",
    "                raise TypeError(\"dataframe[column] type: {} should be object or float64/int64\".format(\n",
    "                    type(dataframe[column].dtype)))\n",
    "        addon_dataframe = pd.DataFrame(addon)\n",
    "        return dataframe.head(1).append(addon_dataframe)\n",
    "\n",
    "    for datatype in data:\n",
    "        data[datatype] = increase_data(data[datatype], n_samples-1, seed) # -1 is for original sample, which stays\n",
    "        data[datatype].to_csv(path_to_powerflow_data + datatype + \".csv\", index=False)\n",
    "        print(\"Datatype {} stored\".format(datatype))\n",
    "\n",
    "def create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None):\n",
    "    import os\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "    import pypsa\n",
    "\n",
    "    if not os.path.isdir(path_to_powerflow_data):\n",
    "        src = Path(path_to_powerflow_data).parents[0] / \"ieee-13-with-load-gen/\" # original modified IEEE model\n",
    "        shutil.copytree(src, path_to_powerflow_data)\n",
    "\n",
    "    set_uniform_sample_size(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "\n",
    "    network = pypsa.Network(import_name=path_to_powerflow_data)\n",
    "    network.pf()\n",
    "\n",
    "    save_path = path_to_powerflow_data + \"results/\"\n",
    "    network.buses_t.v_mag_pu.to_csv(save_path + \"vmags.csv\")\n",
    "    network.buses_t.v_ang.to_csv(save_path + \"vangs.csv\")\n",
    "    network.buses_t.q.to_csv(save_path + \"qmags.csv\")\n",
    "    network.lines_t.p0.to_csv(save_path + \"linemags.csv\")\n",
    "    \n",
    "def backup_samples(src, dest):\n",
    "    '''\n",
    "    thanks https://www.pythoncentral.io/how-to-recursively-copy-a-directory-folder-in-python/\n",
    "    '''\n",
    "    import os\n",
    "    import errno\n",
    "    import shutil\n",
    "    \n",
    "    try:\n",
    "        if os.path.isdir(dest):\n",
    "            shutil.rmtree(dest)\n",
    "        shutil.copytree(src, dest)\n",
    "        print(\"Backup to {} successful\".format(dest))\n",
    "    except OSError as e:\n",
    "        # If the error was caused because the source wasn't a directory\n",
    "        if e.errno == errno.ENOTDIR:\n",
    "            shutil.copy(src, dest)\n",
    "        else:\n",
    "            print('Directory not copied. Error: %s' % e)\n",
    "            \n",
    "def add_mean_and_std_rows(dataframe):\n",
    "    mean = dataframe.mean()\n",
    "    std = dataframe.std()\n",
    "    dataframe.loc[\"mean\"] = mean\n",
    "    dataframe.loc[\"std\"] = std\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER INPUT\n",
    "sample_size = 100000 # this is the max number of samples available\n",
    "\n",
    "data_to_change = [\"loads-p_set\", \"snapshots\", \"loads-q_set\"]\n",
    "\n",
    "path_to_powerflow_example = \"../../pypsa/examples/ieee-13/\"\n",
    "path_to_powerflow_data = (path_to_powerflow_example +\n",
    "                          \"/ieee-13-with-load-gen-uniform-data-\"\n",
    "                          + str(sample_size) +\n",
    "                          \"-samples/\")\n",
    "path_to_powerflow_results = path_to_powerflow_data + \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Uncomment to generate load samples for modified IEEE-13 network\n",
    "# if sample_size > 10000:\n",
    "#     user = input(\"Are you sure [y/n]? This could erase hours worth of data\")\n",
    "#     if user == \"y\":\n",
    "#         backup_samples(path_to_powerflow_results, path_to_powerflow_data + \"results-backup/\")\n",
    "#         create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "# else:\n",
    "#     create_samples_and_run_network(path_to_powerflow_data, data_to_change, sample_size, seed=None)\n",
    "\n",
    "data = {\"loads\": [], \"vmags\": [], \"vangs\": [], \"qmags\": [], \"linemags\": []}\n",
    "collect_data(path_to_powerflow_data, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[\"loads\"].drop(\"load-name\", axis=1)\n",
    "labels = data[\"vmags\"].drop([\"vmag-name\", \"vmag-Substation\"], axis=1) #loc[:,[\"vmag-632\", \"vmag-671\", \"vmag-675\"]]\n",
    "features_and_labels = features.join(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fc104930190>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc1082eaf90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc1082a1d90>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc1082d5650>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc108288950>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc100a5dbd0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc108256410>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc10820bc10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc108214750>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fc108054fd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107ff6f10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107f27d10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107ee7510>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc107f1ad10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107eda550>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107e8fd50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107e4f590>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc107e5c0d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107e0fa50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107d7add0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107d3a610>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc107cf1e10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107cb2650>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107c64e50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc107c26690>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load-632</th>\n",
       "      <th>load-634</th>\n",
       "      <th>load-645</th>\n",
       "      <th>load-646</th>\n",
       "      <th>load-652</th>\n",
       "      <th>load-671</th>\n",
       "      <th>load-675</th>\n",
       "      <th>load-692</th>\n",
       "      <th>load-611</th>\n",
       "      <th>row average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>vmag-650</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>-0.002953</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-0.001955</td>\n",
       "      <td>-0.007134</td>\n",
       "      <td>-0.001353</td>\n",
       "      <td>-0.004306</td>\n",
       "      <td>-0.001971</td>\n",
       "      <td>-0.002970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-646</td>\n",
       "      <td>-0.196512</td>\n",
       "      <td>-0.200144</td>\n",
       "      <td>-0.487273</td>\n",
       "      <td>-0.671172</td>\n",
       "      <td>-0.211606</td>\n",
       "      <td>-0.204674</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.208235</td>\n",
       "      <td>-0.211118</td>\n",
       "      <td>-0.287779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-645</td>\n",
       "      <td>-0.219407</td>\n",
       "      <td>-0.223990</td>\n",
       "      <td>-0.546822</td>\n",
       "      <td>-0.558979</td>\n",
       "      <td>-0.235927</td>\n",
       "      <td>-0.229190</td>\n",
       "      <td>-0.223332</td>\n",
       "      <td>-0.233060</td>\n",
       "      <td>-0.236599</td>\n",
       "      <td>-0.300812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-632</td>\n",
       "      <td>-0.316812</td>\n",
       "      <td>-0.320804</td>\n",
       "      <td>-0.319882</td>\n",
       "      <td>-0.333944</td>\n",
       "      <td>-0.339195</td>\n",
       "      <td>-0.329811</td>\n",
       "      <td>-0.324215</td>\n",
       "      <td>-0.334387</td>\n",
       "      <td>-0.339914</td>\n",
       "      <td>-0.328774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-633</td>\n",
       "      <td>-0.286406</td>\n",
       "      <td>-0.512513</td>\n",
       "      <td>-0.289868</td>\n",
       "      <td>-0.302645</td>\n",
       "      <td>-0.307178</td>\n",
       "      <td>-0.298881</td>\n",
       "      <td>-0.292050</td>\n",
       "      <td>-0.303695</td>\n",
       "      <td>-0.307554</td>\n",
       "      <td>-0.322310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-634</td>\n",
       "      <td>-0.286326</td>\n",
       "      <td>-0.512387</td>\n",
       "      <td>-0.289801</td>\n",
       "      <td>-0.302548</td>\n",
       "      <td>-0.307111</td>\n",
       "      <td>-0.298800</td>\n",
       "      <td>-0.291940</td>\n",
       "      <td>-0.303616</td>\n",
       "      <td>-0.307463</td>\n",
       "      <td>-0.322221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-611</td>\n",
       "      <td>-0.157880</td>\n",
       "      <td>-0.158084</td>\n",
       "      <td>-0.155850</td>\n",
       "      <td>-0.168281</td>\n",
       "      <td>-0.463138</td>\n",
       "      <td>-0.316864</td>\n",
       "      <td>-0.313902</td>\n",
       "      <td>-0.320260</td>\n",
       "      <td>-0.600170</td>\n",
       "      <td>-0.294936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-684</td>\n",
       "      <td>-0.170285</td>\n",
       "      <td>-0.171447</td>\n",
       "      <td>-0.168631</td>\n",
       "      <td>-0.182151</td>\n",
       "      <td>-0.502244</td>\n",
       "      <td>-0.343257</td>\n",
       "      <td>-0.340429</td>\n",
       "      <td>-0.346904</td>\n",
       "      <td>-0.501052</td>\n",
       "      <td>-0.302933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-671</td>\n",
       "      <td>-0.196724</td>\n",
       "      <td>-0.199334</td>\n",
       "      <td>-0.196651</td>\n",
       "      <td>-0.210183</td>\n",
       "      <td>-0.410146</td>\n",
       "      <td>-0.399117</td>\n",
       "      <td>-0.395772</td>\n",
       "      <td>-0.403272</td>\n",
       "      <td>-0.410221</td>\n",
       "      <td>-0.313491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-692</td>\n",
       "      <td>-0.196689</td>\n",
       "      <td>-0.199299</td>\n",
       "      <td>-0.196616</td>\n",
       "      <td>-0.210148</td>\n",
       "      <td>-0.410075</td>\n",
       "      <td>-0.399049</td>\n",
       "      <td>-0.395916</td>\n",
       "      <td>-0.403413</td>\n",
       "      <td>-0.410151</td>\n",
       "      <td>-0.313484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-675</td>\n",
       "      <td>-0.187323</td>\n",
       "      <td>-0.189802</td>\n",
       "      <td>-0.187164</td>\n",
       "      <td>-0.200840</td>\n",
       "      <td>-0.391617</td>\n",
       "      <td>-0.380550</td>\n",
       "      <td>-0.479096</td>\n",
       "      <td>-0.385147</td>\n",
       "      <td>-0.391644</td>\n",
       "      <td>-0.310354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-652</td>\n",
       "      <td>-0.140446</td>\n",
       "      <td>-0.141170</td>\n",
       "      <td>-0.137119</td>\n",
       "      <td>-0.151906</td>\n",
       "      <td>-0.698675</td>\n",
       "      <td>-0.281787</td>\n",
       "      <td>-0.280290</td>\n",
       "      <td>-0.284874</td>\n",
       "      <td>-0.411965</td>\n",
       "      <td>-0.280915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vmag-680</td>\n",
       "      <td>-0.196724</td>\n",
       "      <td>-0.199334</td>\n",
       "      <td>-0.196651</td>\n",
       "      <td>-0.210183</td>\n",
       "      <td>-0.410146</td>\n",
       "      <td>-0.399117</td>\n",
       "      <td>-0.395772</td>\n",
       "      <td>-0.403272</td>\n",
       "      <td>-0.410221</td>\n",
       "      <td>-0.313491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>column average</td>\n",
       "      <td>-0.196921</td>\n",
       "      <td>-0.232835</td>\n",
       "      <td>-0.244252</td>\n",
       "      <td>-0.269466</td>\n",
       "      <td>-0.360693</td>\n",
       "      <td>-0.299095</td>\n",
       "      <td>-0.302565</td>\n",
       "      <td>-0.302649</td>\n",
       "      <td>-0.349234</td>\n",
       "      <td>-0.284190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                load-632  load-634  load-645  load-646  load-652  load-671  \\\n",
       "vmag-650       -0.008439  0.001458 -0.002953 -0.000081 -0.001955 -0.007134   \n",
       "vmag-646       -0.196512 -0.200144 -0.487273 -0.671172 -0.211606 -0.204674   \n",
       "vmag-645       -0.219407 -0.223990 -0.546822 -0.558979 -0.235927 -0.229190   \n",
       "vmag-632       -0.316812 -0.320804 -0.319882 -0.333944 -0.339195 -0.329811   \n",
       "vmag-633       -0.286406 -0.512513 -0.289868 -0.302645 -0.307178 -0.298881   \n",
       "vmag-634       -0.286326 -0.512387 -0.289801 -0.302548 -0.307111 -0.298800   \n",
       "vmag-611       -0.157880 -0.158084 -0.155850 -0.168281 -0.463138 -0.316864   \n",
       "vmag-684       -0.170285 -0.171447 -0.168631 -0.182151 -0.502244 -0.343257   \n",
       "vmag-671       -0.196724 -0.199334 -0.196651 -0.210183 -0.410146 -0.399117   \n",
       "vmag-692       -0.196689 -0.199299 -0.196616 -0.210148 -0.410075 -0.399049   \n",
       "vmag-675       -0.187323 -0.189802 -0.187164 -0.200840 -0.391617 -0.380550   \n",
       "vmag-652       -0.140446 -0.141170 -0.137119 -0.151906 -0.698675 -0.281787   \n",
       "vmag-680       -0.196724 -0.199334 -0.196651 -0.210183 -0.410146 -0.399117   \n",
       "column average -0.196921 -0.232835 -0.244252 -0.269466 -0.360693 -0.299095   \n",
       "\n",
       "                load-675  load-692  load-611  row average  \n",
       "vmag-650       -0.001353 -0.004306 -0.001971    -0.002970  \n",
       "vmag-646       -0.199273 -0.208235 -0.211118    -0.287779  \n",
       "vmag-645       -0.223332 -0.233060 -0.236599    -0.300812  \n",
       "vmag-632       -0.324215 -0.334387 -0.339914    -0.328774  \n",
       "vmag-633       -0.292050 -0.303695 -0.307554    -0.322310  \n",
       "vmag-634       -0.291940 -0.303616 -0.307463    -0.322221  \n",
       "vmag-611       -0.313902 -0.320260 -0.600170    -0.294936  \n",
       "vmag-684       -0.340429 -0.346904 -0.501052    -0.302933  \n",
       "vmag-671       -0.395772 -0.403272 -0.410221    -0.313491  \n",
       "vmag-692       -0.395916 -0.403413 -0.410151    -0.313484  \n",
       "vmag-675       -0.479096 -0.385147 -0.391644    -0.310354  \n",
       "vmag-652       -0.280290 -0.284874 -0.411965    -0.280915  \n",
       "vmag-680       -0.395772 -0.403272 -0.410221    -0.313491  \n",
       "column average -0.302565 -0.302649 -0.349234    -0.284190  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = labels.join(features).corr()\n",
    "\n",
    "# only loads for columns\n",
    "cols = [c for i, c in enumerate(corr_matrix.columns) if corr_matrix.keys().str.contains(\"^load\", regex=True)[i]]\n",
    "reduced_corr_matrix = corr_matrix[cols]\n",
    "reduced_corr_matrix[\"row average\"] = pd.Series(reduced_corr_matrix.mean(axis=1))\n",
    "# only voltages for rows\n",
    "rows = reduced_corr_matrix.index[reduced_corr_matrix.index.str.contains(\"load\")]\n",
    "reduced_corr_matrix.drop(rows, inplace=True)\n",
    "reduced_corr_matrix = reduced_corr_matrix.append(pd.Series(reduced_corr_matrix.mean(), name=\"column average\"))\n",
    "\n",
    "display(reduced_corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from scoring import rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def set_data_size(n_samples, n_training_samples):\n",
    "    X_train, X_val, y_train, y_val, test_idx, train_idx = train_test_split(features,\n",
    "                                                                           labels,\n",
    "                                                                           range(features.shape[0]),\n",
    "                                                                           train_size=n_training_samples,\n",
    "                                                                           test_size=n_samples-n_training_samples,\n",
    "                                                                           random_state=None)\n",
    "    X_train = X_train.values\n",
    "    y_train = y_train.values\n",
    "    X_val = X_val.values\n",
    "    y_val = y_val.values\n",
    "\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine number of samples to get reasonable scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model parameters/hyperparameters\n",
    "\n",
    "'''\n",
    "dnn hyperparameters are chosen from sandbox testing. On average the model attempts to converge \n",
    "(with other parameters it sometimes gives up early).\n",
    "'''\n",
    "svr = SVR(gamma='scale', C=1.0, epsilon=0.0002, kernel='rbf')\n",
    "\n",
    "linear = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Run:  0\n",
      "n_training_samples:  80\n",
      "n_validation_samples:  20\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "SVR\n",
      "\n",
      "\n",
      "cross validation training time 1.2083\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svr_fit_time_label_0</th>\n",
       "      <th>svr_score_time_label_0</th>\n",
       "      <th>svr_test_r2_label_0</th>\n",
       "      <th>svr_test_rmse_label_0</th>\n",
       "      <th>svr_test_mae_label_0</th>\n",
       "      <th>svr_fit_time_label_1</th>\n",
       "      <th>svr_score_time_label_1</th>\n",
       "      <th>svr_test_r2_label_1</th>\n",
       "      <th>svr_test_rmse_label_1</th>\n",
       "      <th>svr_test_mae_label_1</th>\n",
       "      <th>...</th>\n",
       "      <th>svr_fit_time_label_11</th>\n",
       "      <th>svr_score_time_label_11</th>\n",
       "      <th>svr_test_r2_label_11</th>\n",
       "      <th>svr_test_rmse_label_11</th>\n",
       "      <th>svr_test_mae_label_11</th>\n",
       "      <th>svr_fit_time_label_12</th>\n",
       "      <th>svr_score_time_label_12</th>\n",
       "      <th>svr_test_r2_label_12</th>\n",
       "      <th>svr_test_rmse_label_12</th>\n",
       "      <th>svr_test_mae_label_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>-0.070754</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.725519</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.749972</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.686592</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>-0.026519</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.873864</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.868880</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.854295</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.002487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>-0.254505</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.835298</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.792538</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.803615</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.003534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.003594</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.916946</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.914202</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.899234</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.002822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>-0.661189</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.764335</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.847434</td>\n",
       "      <td>0.007346</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.824470</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.003561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>-0.203312</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.823192</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.834605</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.813641</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.003120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.274311</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.078276</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.064435</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.079590</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      svr_fit_time_label_0  svr_score_time_label_0  svr_test_r2_label_0  \\\n",
       "0                 0.000857                0.001216            -0.070754   \n",
       "1                 0.000838                0.001157            -0.026519   \n",
       "2                 0.000565                0.001207            -0.254505   \n",
       "3                 0.000524                0.001130            -0.003594   \n",
       "4                 0.000570                0.001015            -0.661189   \n",
       "mean              0.000671                0.001145            -0.203312   \n",
       "std               0.000162                0.000081             0.274311   \n",
       "\n",
       "      svr_test_rmse_label_0  svr_test_mae_label_0  svr_fit_time_label_1  \\\n",
       "0                  0.000093              0.000070              0.000906   \n",
       "1                  0.000084              0.000073              0.000788   \n",
       "2                  0.000100              0.000079              0.000712   \n",
       "3                  0.000088              0.000070              0.000921   \n",
       "4                  0.000068              0.000056              0.000709   \n",
       "mean               0.000087              0.000070              0.000807   \n",
       "std                0.000012              0.000009              0.000102   \n",
       "\n",
       "      svr_score_time_label_1  svr_test_r2_label_1  svr_test_rmse_label_1  \\\n",
       "0                   0.001138             0.725519               0.004807   \n",
       "1                   0.001062             0.873864               0.003466   \n",
       "2                   0.001111             0.835298               0.004174   \n",
       "3                   0.001093             0.916946               0.003069   \n",
       "4                   0.001056             0.764335               0.005187   \n",
       "mean                0.001092             0.823192               0.004141   \n",
       "std                 0.000034             0.078276               0.000886   \n",
       "\n",
       "      svr_test_mae_label_1  ...  svr_fit_time_label_11  \\\n",
       "0                 0.003456  ...               0.000826   \n",
       "1                 0.002804  ...               0.003335   \n",
       "2                 0.003398  ...               0.000855   \n",
       "3                 0.002359  ...               0.000765   \n",
       "4                 0.003728  ...               0.000862   \n",
       "mean              0.003149  ...               0.001329   \n",
       "std               0.000556  ...               0.001122   \n",
       "\n",
       "      svr_score_time_label_11  svr_test_r2_label_11  svr_test_rmse_label_11  \\\n",
       "0                    0.001148              0.749972                0.004888   \n",
       "1                    0.001309              0.868880                0.004480   \n",
       "2                    0.001151              0.792538                0.007642   \n",
       "3                    0.001123              0.914202                0.005237   \n",
       "4                    0.001236              0.847434                0.007346   \n",
       "mean                 0.001193              0.834605                0.005919   \n",
       "std                  0.000078              0.064435                0.001467   \n",
       "\n",
       "      svr_test_mae_label_11  svr_fit_time_label_12  svr_score_time_label_12  \\\n",
       "0                  0.003785               0.001030                 0.001698   \n",
       "1                  0.004124               0.003355                 0.001770   \n",
       "2                  0.005740               0.001029                 0.001853   \n",
       "3                  0.003627               0.000759                 0.001273   \n",
       "4                  0.005306               0.001312                 0.001403   \n",
       "mean               0.004516               0.001497                 0.001599   \n",
       "std                0.000949               0.001057                 0.000249   \n",
       "\n",
       "      svr_test_r2_label_12  svr_test_rmse_label_12  svr_test_mae_label_12  \n",
       "0                 0.686592                0.003968               0.003194  \n",
       "1                 0.854295                0.002981               0.002487  \n",
       "2                 0.803615                0.004598               0.003534  \n",
       "3                 0.899234                0.003777               0.002822  \n",
       "4                 0.824470                0.005387               0.003561  \n",
       "mean              0.813641                0.004142               0.003120  \n",
       "std               0.079590                0.000904               0.000464  \n",
       "\n",
       "[7 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "label:  0\n",
      "training score:  -405175.1157755053\n",
      "validation score:  -452955.5851603119\n",
      "rmse:  0.05441855980311887\n",
      "label:  1\n",
      "training score:  0.4138143894934786\n",
      "validation score:  0.6008956470339313\n",
      "rmse:  0.007792955396202384\n",
      "label:  2\n",
      "training score:  0.08104679208297072\n",
      "validation score:  0.2997401786933088\n",
      "rmse:  0.009048557066661852\n",
      "label:  3\n",
      "training score:  -8.299408269172135\n",
      "validation score:  -5.088419892025565\n",
      "rmse:  0.019293956406146524\n",
      "label:  4\n",
      "training score:  -4.561801734886986\n",
      "validation score:  -2.654685557035367\n",
      "rmse:  0.016006511525650476\n",
      "label:  5\n",
      "training score:  -4.529157846112978\n",
      "validation score:  -2.636018245980058\n",
      "rmse:  0.01594999955233893\n",
      "label:  6\n",
      "training score:  0.3463968418696538\n",
      "validation score:  0.5654887130041037\n",
      "rmse:  0.01098062493251547\n",
      "label:  7\n",
      "training score:  0.6522920410024485\n",
      "validation score:  0.7226476376974607\n",
      "rmse:  0.008237736397344255\n",
      "label:  8\n",
      "training score:  0.998848625655069\n",
      "validation score:  0.9074650503279446\n",
      "rmse:  0.003994952856689379\n",
      "label:  9\n",
      "training score:  0.9988509299506613\n",
      "validation score:  0.9074266822757481\n",
      "rmse:  0.003996599489811942\n",
      "label:  10\n",
      "training score:  0.9630467493619027\n",
      "validation score:  0.871880106969128\n",
      "rmse:  0.004932281035590233\n",
      "label:  11\n",
      "training score:  -0.11759957280888855\n",
      "validation score:  0.2595710298568772\n",
      "rmse:  0.01720293671583539\n",
      "label:  12\n",
      "training score:  0.998848625655069\n",
      "validation score:  0.9074650503279446\n",
      "rmse:  0.003994952856689379\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.023854\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.887021</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.001038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.868170</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.001193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.892865</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.863797</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.794419</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.000831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.861254</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.001085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.039321</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.010338           0.001400        0.887021          0.001360   \n",
       "1            0.008770           0.001488        0.868170          0.001446   \n",
       "2            0.000743           0.001277        0.892865          0.001621   \n",
       "3            0.001001           0.001257        0.863797          0.001600   \n",
       "4            0.000698           0.000962        0.794419          0.001180   \n",
       "mean         0.004310           0.001277        0.861254          0.001441   \n",
       "std          0.004821           0.000199        0.039321          0.000182   \n",
       "\n",
       "      linear_test_mae  \n",
       "0            0.001038  \n",
       "1            0.001193  \n",
       "2            0.001189  \n",
       "3            0.001176  \n",
       "4            0.000831  \n",
       "mean         0.001085  \n",
       "std          0.000156  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.9126665954697695\n",
      "validation score:  0.8987932814837764\n",
      "rmse:  0.0014147555230062368\n",
      "\n",
      "\n",
      "Run:  1\n",
      "n_training_samples:  800\n",
      "n_validation_samples:  200\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "SVR\n",
      "\n",
      "\n",
      "cross validation training time 4.9363\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svr_fit_time_label_0</th>\n",
       "      <th>svr_score_time_label_0</th>\n",
       "      <th>svr_test_r2_label_0</th>\n",
       "      <th>svr_test_rmse_label_0</th>\n",
       "      <th>svr_test_mae_label_0</th>\n",
       "      <th>svr_fit_time_label_1</th>\n",
       "      <th>svr_score_time_label_1</th>\n",
       "      <th>svr_test_r2_label_1</th>\n",
       "      <th>svr_test_rmse_label_1</th>\n",
       "      <th>svr_test_mae_label_1</th>\n",
       "      <th>...</th>\n",
       "      <th>svr_fit_time_label_11</th>\n",
       "      <th>svr_score_time_label_11</th>\n",
       "      <th>svr_test_r2_label_11</th>\n",
       "      <th>svr_test_rmse_label_11</th>\n",
       "      <th>svr_test_mae_label_11</th>\n",
       "      <th>svr_fit_time_label_12</th>\n",
       "      <th>svr_score_time_label_12</th>\n",
       "      <th>svr_test_r2_label_12</th>\n",
       "      <th>svr_test_rmse_label_12</th>\n",
       "      <th>svr_test_mae_label_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.109184</td>\n",
       "      <td>0.016226</td>\n",
       "      <td>0.950383</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092950</td>\n",
       "      <td>0.013116</td>\n",
       "      <td>0.950961</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.079348</td>\n",
       "      <td>0.013942</td>\n",
       "      <td>0.945957</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.001961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>-0.012610</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.081106</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.957941</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105874</td>\n",
       "      <td>0.013567</td>\n",
       "      <td>0.953417</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.065849</td>\n",
       "      <td>0.012806</td>\n",
       "      <td>0.945251</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>-0.080092</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.094849</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>0.957001</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096464</td>\n",
       "      <td>0.013121</td>\n",
       "      <td>0.958581</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.078427</td>\n",
       "      <td>0.012714</td>\n",
       "      <td>0.954933</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.001744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>-0.013122</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.063049</td>\n",
       "      <td>0.012321</td>\n",
       "      <td>0.949957</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>0.952578</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.080854</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>0.946141</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.001896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>-0.022438</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.071282</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.955996</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091927</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>0.951379</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.078922</td>\n",
       "      <td>0.012608</td>\n",
       "      <td>0.949684</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>-0.025653</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.083894</td>\n",
       "      <td>0.013136</td>\n",
       "      <td>0.954256</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096087</td>\n",
       "      <td>0.013128</td>\n",
       "      <td>0.953383</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.076680</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.948393</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.001879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.018445</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.006123</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      svr_fit_time_label_0  svr_score_time_label_0  svr_test_r2_label_0  \\\n",
       "0                 0.000823                0.001165            -0.000004   \n",
       "1                 0.000806                0.001103            -0.012610   \n",
       "2                 0.000674                0.001247            -0.080092   \n",
       "3                 0.000548                0.001131            -0.013122   \n",
       "4                 0.000546                0.001174            -0.022438   \n",
       "mean              0.000679                0.001164            -0.025653   \n",
       "std               0.000134                0.000054             0.031460   \n",
       "\n",
       "      svr_test_rmse_label_0  svr_test_mae_label_0  svr_fit_time_label_1  \\\n",
       "0                  0.000082              0.000065              0.109184   \n",
       "1                  0.000088              0.000073              0.081106   \n",
       "2                  0.000094              0.000076              0.094849   \n",
       "3                  0.000086              0.000070              0.063049   \n",
       "4                  0.000088              0.000069              0.071282   \n",
       "mean               0.000088              0.000071              0.083894   \n",
       "std                0.000005              0.000004              0.018445   \n",
       "\n",
       "      svr_score_time_label_1  svr_test_r2_label_1  svr_test_rmse_label_1  \\\n",
       "0                   0.016226             0.950383               0.002315   \n",
       "1                   0.012866             0.957941               0.002291   \n",
       "2                   0.012330             0.957001               0.002071   \n",
       "3                   0.012321             0.949957               0.002239   \n",
       "4                   0.011936             0.955996               0.002317   \n",
       "mean                0.013136             0.954256               0.002246   \n",
       "std                 0.001759             0.003795               0.000103   \n",
       "\n",
       "      svr_test_mae_label_1  ...  svr_fit_time_label_11  \\\n",
       "0                 0.001801  ...               0.092950   \n",
       "1                 0.001752  ...               0.105874   \n",
       "2                 0.001631  ...               0.096464   \n",
       "3                 0.001808  ...               0.093220   \n",
       "4                 0.001851  ...               0.091927   \n",
       "mean              0.001768  ...               0.096087   \n",
       "std               0.000085  ...               0.005729   \n",
       "\n",
       "      svr_score_time_label_11  svr_test_r2_label_11  svr_test_rmse_label_11  \\\n",
       "0                    0.013116              0.950961                0.003491   \n",
       "1                    0.013567              0.953417                0.003205   \n",
       "2                    0.013121              0.958581                0.003002   \n",
       "3                    0.013172              0.952578                0.003159   \n",
       "4                    0.012665              0.951379                0.003383   \n",
       "mean                 0.013128              0.953383                0.003248   \n",
       "std                  0.000320              0.003064                0.000192   \n",
       "\n",
       "      svr_test_mae_label_11  svr_fit_time_label_12  svr_score_time_label_12  \\\n",
       "0                  0.002772               0.079348                 0.013942   \n",
       "1                  0.002505               0.065849                 0.012806   \n",
       "2                  0.002404               0.078427                 0.012714   \n",
       "3                  0.002471               0.080854                 0.012641   \n",
       "4                  0.002601               0.078922                 0.012608   \n",
       "mean               0.002551               0.076680                 0.012942   \n",
       "std                0.000143               0.006123                 0.000564   \n",
       "\n",
       "      svr_test_r2_label_12  svr_test_rmse_label_12  svr_test_mae_label_12  \n",
       "0                 0.945957                0.002459               0.001961  \n",
       "1                 0.945251                0.002411               0.001874  \n",
       "2                 0.954933                0.002164               0.001744  \n",
       "3                 0.946141                0.002382               0.001896  \n",
       "4                 0.949684                0.002388               0.001917  \n",
       "mean              0.948393                0.002361               0.001879  \n",
       "std               0.004041                0.000114               0.000082  \n",
       "\n",
       "[7 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "label:  0\n",
      "training score:  -399282.3767483447\n",
      "validation score:  -382951.4335061642\n",
      "rmse:  0.05342864243653316\n",
      "label:  1\n",
      "training score:  0.3634260911267302\n",
      "validation score:  0.35969327392528494\n",
      "rmse:  0.008280264914777428\n",
      "label:  2\n",
      "training score:  -0.07581320922451851\n",
      "validation score:  -0.047684008994790306\n",
      "rmse:  0.009482818407689332\n",
      "label:  3\n",
      "training score:  -8.563168616271307\n",
      "validation score:  -8.30556376741714\n",
      "rmse:  0.019176874717821667\n",
      "label:  4\n",
      "training score:  -4.729535136097592\n",
      "validation score:  -4.351725244428486\n",
      "rmse:  0.01646841109873197\n",
      "label:  5\n",
      "training score:  -4.690669532697653\n",
      "validation score:  -4.3181608359821\n",
      "rmse:  0.016422356558590003\n",
      "label:  6\n",
      "training score:  0.2773072928078003\n",
      "validation score:  0.25917617568744744\n",
      "rmse:  0.011292747478352442\n",
      "label:  7\n",
      "training score:  0.6141145413935973\n",
      "validation score:  0.5900027519633404\n",
      "rmse:  0.007721538029294059\n",
      "label:  8\n",
      "training score:  0.998617377751722\n",
      "validation score:  0.9586831355468817\n",
      "rmse:  0.0020709646490519487\n",
      "label:  9\n",
      "training score:  0.9986133162719245\n",
      "validation score:  0.9586844774727308\n",
      "rmse:  0.002071266257778681\n",
      "label:  10\n",
      "training score:  0.9612355298183646\n",
      "validation score:  0.925049310594482\n",
      "rmse:  0.002904564348032375\n",
      "label:  11\n",
      "training score:  -0.29226109477144413\n",
      "validation score:  -0.2445593088332696\n",
      "rmse:  0.016703278914381475\n",
      "label:  12\n",
      "training score:  0.998617377751722\n",
      "validation score:  0.9586831355468817\n",
      "rmse:  0.0020709646490519504\n",
      "\n",
      "\n",
      "LINEAR REGRESSION\n",
      "\n",
      "\n",
      "cross validation training time 0.040371\n",
      "cross validation training scores: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_r2</th>\n",
       "      <th>linear_test_rmse</th>\n",
       "      <th>linear_test_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.902568</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.903212</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.901215</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.001116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.902802</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.905953</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.001085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.903150</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      linear_fit_time  linear_score_time  linear_test_r2  linear_test_rmse  \\\n",
       "0            0.004205           0.001579        0.902568          0.001372   \n",
       "1            0.002871           0.002625        0.903212          0.001434   \n",
       "2            0.001262           0.001512        0.901215          0.001466   \n",
       "3            0.001126           0.001463        0.902802          0.001356   \n",
       "4            0.001224           0.001429        0.905953          0.001442   \n",
       "mean         0.002137           0.001721        0.903150          0.001414   \n",
       "std          0.001364           0.000508        0.001737          0.000047   \n",
       "\n",
       "      linear_test_mae  \n",
       "0            0.001059  \n",
       "1            0.001103  \n",
       "2            0.001116  \n",
       "3            0.001033  \n",
       "4            0.001085  \n",
       "mean         0.001079  \n",
       "std          0.000033  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cross validation model scores for reference:\n",
      "training score:  0.905871026771822\n",
      "validation score:  0.9043735413742711\n",
      "rmse:  0.0013589426825525242\n",
      "\n",
      "\n",
      "Run:  2\n",
      "n_training_samples:  8000\n",
      "n_validation_samples:  2000\n",
      "n_features:  9\n",
      "n_labels:  13\n",
      "\n",
      "\n",
      "SVR\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svr_xval_scores = []\n",
    "linear_xval_scores = []\n",
    "for i, n_samples in enumerate([100, 1000, 10000, 100000]):\n",
    "    current_iteration = i\n",
    "\n",
    "    n_training_samples = int(n_samples*(80/100))\n",
    "    X_train, y_train, X_val, y_val = set_data_size(n_samples, n_training_samples)\n",
    "\n",
    "    print(\"\\n\\nRun: \", current_iteration)\n",
    "    print(\"n_training_samples: \", n_training_samples)\n",
    "    print(\"n_validation_samples: \", n_samples-n_training_samples)\n",
    "    print(\"n_features: \", X_train.shape[1])\n",
    "    print(\"n_labels: \", y_train.shape[1])\n",
    "\n",
    "    ## svr - can only predict one label at a time\n",
    "    print(\"\\n\\nSVR\\n\\n\")\n",
    "    \n",
    "    time_start = time.time()\n",
    "    svr_models = []\n",
    "    for label in range(y_train.shape[1]):\n",
    "        svr_y_train = y_train.T[label].T\n",
    "        svr_xval_scores = pd.DataFrame(cross_validate(svr, \n",
    "                                                      X_train, \n",
    "                                                      svr_y_train, \n",
    "                                                      cv=5, \n",
    "                                                      n_jobs=-1, \n",
    "                                                      scoring={\"r2\": make_scorer(r2_score),\n",
    "                                                               \"rmse\": make_scorer(rmse),\n",
    "                                                               \"mae\": make_scorer(mae)}))\n",
    "        svr_xval_scores.columns = [\"svr_\" + col + \"_label_\" + str(label) for col in svr_xval_scores.columns]\n",
    "        if label == 0:\n",
    "            svr_results = svr_xval_scores\n",
    "        else:\n",
    "            svr_results = svr_results.join(svr_xval_scores)\n",
    "        \n",
    "        svr_models.append(svr.fit(X_train, svr_y_train))\n",
    "\n",
    "    time_svr = time.time()\n",
    "    print(\"cross validation training time {:.5}\".format(time_svr-time_start))\n",
    "    print(\"cross validation training scores: \")\n",
    "    svr_results = add_mean_and_std_rows(svr_results)\n",
    "    display(svr_results)\n",
    "\n",
    "    print(\"non-cross validation model scores for reference:\")\n",
    "    for label in range(y_train.shape[1]):\n",
    "        print(\"label: \", label)\n",
    "        print(\"training score: \", r2_score(y_train.T[label].T, svr.predict(X_train)))\n",
    "        print(\"validation score: \", r2_score(y_val.T[label].T, svr.predict(X_val)))\n",
    "        print(\"rmse: \", rmse(y_val.T[label].T, svr.predict(X_val)))\n",
    "\n",
    "    ## linear regression\n",
    "    print(\"\\n\\nLINEAR REGRESSION\\n\\n\")\n",
    "    time_start = time.time()\n",
    "    linear_xval_scores.append(cross_validate(linear,\n",
    "                                             X_train,\n",
    "                                             y_train,\n",
    "                                             cv=5,\n",
    "                                             n_jobs=-1,\n",
    "                                             scoring={\"r2\": make_scorer(r2_score),\n",
    "                                                      \"rmse\": make_scorer(rmse),\n",
    "                                                      \"mae\": make_scorer(mae)}))\n",
    "\n",
    "    time_linear = time.time()\n",
    "    print(\"cross validation training time {:.5}\".format(time_linear-time_start))\n",
    "    print(\"cross validation training scores: \")\n",
    "    linear_results = pd.DataFrame(linear_xval_scores[current_iteration])\n",
    "    linear_results.columns = [\"linear_\"+col for col in linear_results.columns]\n",
    "    linear_results = add_mean_and_std_rows(linear_results)\n",
    "    display(linear_results)\n",
    "\n",
    "    linear.fit(X_train, y_train)\n",
    "    print(\"non-cross validation model scores for reference:\")\n",
    "    print(\"training score: \", r2_score(y_train, linear.predict(X_train)))\n",
    "    print(\"validation score: \", r2_score(y_val, linear.predict(X_val)))\n",
    "    print(\"rmse: \", rmse(linear.predict(X_val), y_val))\n",
    "\n",
    "    ## model statistics\n",
    "    datetimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "    results_to_save = linear_results.join(svr_results).round(3)\n",
    "    results_to_save.to_csv(path_to_powerflow_data + \n",
    "                           \"/results/approximating_with_svr_results-{}_samples-{}.csv\".format(n_samples, \n",
    "                                                                                             datetimestamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing results for calculating mean/std\n",
    "\n",
    "This is different than the RF/DNN notebooks because there are more numbers to crunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.88242 std: 0.0019049 for labels from 0 to 12\n",
      "mean: 0.87425 std: 0.013803 for labels from 0 to 12\n",
      "mean: 0.7944 std: 0.075523 for labels from 0 to 12\n",
      "mean: -14.923 std: 18.887 for labels from 0 to 12\n",
      "mean: 0.95605 std: 0.0019939 for labels from 1 to 12\n",
      "mean: 0.95358 std: 0.0088948 for labels from 1 to 12\n",
      "mean: 0.87367 std: 0.069082 for labels from 1 to 12\n",
      "mean: -15.676 std: 19.772 for labels from 1 to 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_score</th>\n",
       "      <th>fit_time_label_0</th>\n",
       "      <th>score_time_label_0</th>\n",
       "      <th>test_score_label_0</th>\n",
       "      <th>fit_time_label_1</th>\n",
       "      <th>score_time_label_1</th>\n",
       "      <th>test_score_label_1</th>\n",
       "      <th>...</th>\n",
       "      <th>test_score_label_9</th>\n",
       "      <th>fit_time_label_10</th>\n",
       "      <th>score_time_label_10</th>\n",
       "      <th>test_score_label_10</th>\n",
       "      <th>fit_time_label_11</th>\n",
       "      <th>score_time_label_11</th>\n",
       "      <th>test_score_label_11</th>\n",
       "      <th>fit_time_label_12</th>\n",
       "      <th>score_time_label_12</th>\n",
       "      <th>test_score_label_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>162.387</td>\n",
       "      <td>1.073</td>\n",
       "      <td>0.961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960</td>\n",
       "      <td>68.145</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.961</td>\n",
       "      <td>67.372</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.964</td>\n",
       "      <td>70.088</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>159.017</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957</td>\n",
       "      <td>68.869</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.959</td>\n",
       "      <td>65.471</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.963</td>\n",
       "      <td>67.659</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>163.874</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956</td>\n",
       "      <td>68.181</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.957</td>\n",
       "      <td>67.798</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.961</td>\n",
       "      <td>69.363</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>163.062</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956</td>\n",
       "      <td>68.627</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.957</td>\n",
       "      <td>67.603</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.961</td>\n",
       "      <td>68.765</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>96.826</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958</td>\n",
       "      <td>67.617</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.959</td>\n",
       "      <td>67.553</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.963</td>\n",
       "      <td>68.641</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  linear_fit_time  linear_score_time  linear_test_score  \\\n",
       "0           0            0.010              0.001              0.905   \n",
       "1           1            0.010              0.001              0.906   \n",
       "2           2            0.016              0.002              0.906   \n",
       "3           3            0.009              0.001              0.905   \n",
       "4           4            0.006              0.001              0.905   \n",
       "\n",
       "   fit_time_label_0  score_time_label_0  test_score_label_0  fit_time_label_1  \\\n",
       "0             0.004               0.001              -0.000           162.387   \n",
       "1             0.003               0.001              -0.001           159.017   \n",
       "2             0.003               0.001              -0.002           163.874   \n",
       "3             0.003               0.001              -0.001           163.062   \n",
       "4             0.002               0.001              -0.002            96.826   \n",
       "\n",
       "   score_time_label_1  test_score_label_1  ...  test_score_label_9  \\\n",
       "0               1.073               0.961  ...               0.960   \n",
       "1               0.999               0.956  ...               0.957   \n",
       "2               0.829               0.962  ...               0.956   \n",
       "3               0.941               0.957  ...               0.956   \n",
       "4               0.651               0.959  ...               0.958   \n",
       "\n",
       "   fit_time_label_10  score_time_label_10  test_score_label_10  \\\n",
       "0             68.145                0.441                0.961   \n",
       "1             68.869                0.444                0.959   \n",
       "2             68.181                0.431                0.957   \n",
       "3             68.627                0.449                0.957   \n",
       "4             67.617                0.483                0.959   \n",
       "\n",
       "   fit_time_label_11  score_time_label_11  test_score_label_11  \\\n",
       "0             67.372                0.433                0.964   \n",
       "1             65.471                0.436                0.963   \n",
       "2             67.798                0.445                0.961   \n",
       "3             67.603                0.449                0.961   \n",
       "4             67.553                0.454                0.963   \n",
       "\n",
       "   fit_time_label_12  score_time_label_12  test_score_label_12  \n",
       "0             70.088                0.460                0.959  \n",
       "1             67.659                0.419                0.957  \n",
       "2             69.363                0.530                0.956  \n",
       "3             68.765                0.535                0.956  \n",
       "4             68.641                0.433                0.958  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>linear_fit_time</th>\n",
       "      <th>linear_score_time</th>\n",
       "      <th>linear_test_score</th>\n",
       "      <th>fit_time_label_0</th>\n",
       "      <th>score_time_label_0</th>\n",
       "      <th>test_score_label_0</th>\n",
       "      <th>fit_time_label_1</th>\n",
       "      <th>score_time_label_1</th>\n",
       "      <th>test_score_label_1</th>\n",
       "      <th>...</th>\n",
       "      <th>test_score_label_9</th>\n",
       "      <th>fit_time_label_10</th>\n",
       "      <th>score_time_label_10</th>\n",
       "      <th>test_score_label_10</th>\n",
       "      <th>fit_time_label_11</th>\n",
       "      <th>score_time_label_11</th>\n",
       "      <th>test_score_label_11</th>\n",
       "      <th>fit_time_label_12</th>\n",
       "      <th>score_time_label_12</th>\n",
       "      <th>test_score_label_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  linear_fit_time  linear_score_time  linear_test_score  \\\n",
       "0           0            0.003              0.001              0.906   \n",
       "1           1            0.002              0.001              0.903   \n",
       "2           2            0.002              0.001              0.904   \n",
       "3           3            0.002              0.000              0.904   \n",
       "4           4            0.001              0.000              0.900   \n",
       "\n",
       "   fit_time_label_0  score_time_label_0  test_score_label_0  fit_time_label_1  \\\n",
       "0             0.001               0.001              -0.041             0.224   \n",
       "1             0.001               0.001              -0.161             0.120   \n",
       "2             0.002               0.000              -0.024             0.147   \n",
       "3             0.001               0.001              -0.152             0.224   \n",
       "4             0.001               0.000              -0.011             0.152   \n",
       "\n",
       "   score_time_label_1  test_score_label_1  ...  test_score_label_9  \\\n",
       "0               0.004               0.961  ...               0.956   \n",
       "1               0.009               0.961  ...               0.962   \n",
       "2               0.040               0.943  ...               0.945   \n",
       "3               0.004               0.963  ...               0.964   \n",
       "4               0.005               0.951  ...               0.946   \n",
       "\n",
       "   fit_time_label_10  score_time_label_10  test_score_label_10  \\\n",
       "0              0.188                0.004                0.957   \n",
       "1              0.237                0.005                0.962   \n",
       "2              0.296                0.029                0.948   \n",
       "3              0.233                0.014                0.965   \n",
       "4              0.138                0.008                0.949   \n",
       "\n",
       "   fit_time_label_11  score_time_label_11  test_score_label_11  \\\n",
       "0              0.231                0.016                0.956   \n",
       "1              0.167                0.004                0.962   \n",
       "2              0.225                0.049                0.947   \n",
       "3              0.134                0.044                0.961   \n",
       "4              0.176                0.006                0.945   \n",
       "\n",
       "   fit_time_label_12  score_time_label_12  test_score_label_12  \n",
       "0              0.167                0.013                0.956  \n",
       "1              0.202                0.005                0.962  \n",
       "2              0.154                0.005                0.946  \n",
       "3              0.158                0.006                0.963  \n",
       "4              0.124                0.024                0.947  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mean_and_std(results_dataframe, label_min):\n",
    "    for score in [\"r2\", \"rmse\", \"mae\"]:\n",
    "        df = [col for col in results_dataframe.columns if all([\"svr\" in col, score + \"_score\" in col])]\n",
    "        print(\"{} mean: {:.5} std: {:.5} for labels from {} to 12\".format(score,\n",
    "                                                                          df.mean().mean(), \n",
    "                                                                          df.std().mean(), \n",
    "                                                                          label_min))\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-10000_samples-2019-09-12-00-21.csv\")\n",
    "imported_results_hold1 = imported_results\n",
    "mean_and_std(imported_results, 0)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-1000_samples-2019-09-11-23-22.csv\")\n",
    "imported_results_hold2 = imported_results\n",
    "mean_and_std(imported_results, 0)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-100_samples-2019-09-11-23-22.csv\")\n",
    "mean_and_std(imported_results, 0)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-10_samples-2019-09-11-23-20.csv\")\n",
    "mean_and_std(imported_results, 0)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-10000_samples-2019-09-12-00-21.csv\")\n",
    "mean_and_std(imported_results, 1)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-1000_samples-2019-09-11-23-22.csv\")\n",
    "mean_and_std(imported_results, 1)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-100_samples-2019-09-11-23-22.csv\")\n",
    "mean_and_std(imported_results, 1)\n",
    "\n",
    "imported_results = pd.read_csv(path_to_powerflow_data + \"results/\" + \n",
    "            \"approximating_with_svr_results-10_samples-2019-09-11-23-20.csv\")\n",
    "mean_and_std(imported_results, 1)\n",
    "\n",
    "display(imported_results_hold1)\n",
    "display(imported_results_hold2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "if n_samples < 10000:\n",
    "    raise ValueError(\"So you don't accidentally run this on 100 samples again\")\n",
    "n_training_samples = int(n_samples*(80/100))\n",
    "X_train, y_train, X_val, y_val = set_data_size(n_samples, n_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.3min\n"
     ]
    }
   ],
   "source": [
    "svr = SVR()\n",
    "params = {\"gamma\": [\"auto\", \"scale\"], \n",
    "          \"C\": [i*5/1000 for i in range(0,1000)], # min: 0, max: 5\n",
    "          \"epsilon\": [i*2/1000000 for i in range(1,1000)], # min: 2e-6, max: 2e-3\n",
    "          \"kernel\": [\"rbf\", \"poly\", \"sigmoid\", \"linear\"],\n",
    "          \"tol\": [1e-3]\n",
    "         }\n",
    "\n",
    "\n",
    "for label in range(1, y_train.shape[1]):\n",
    "    svr_y_train = y_train.T[label].T\n",
    "\n",
    "    grid = RandomizedSearchCV(svr, params, cv=5, n_iter=30, n_jobs=-1, refit=False,\n",
    "                      scoring={\"r2\": make_scorer(r2_score), \"rmse\": make_scorer(rmse)}, iid=False, verbose=10)\n",
    "\n",
    "    grid.fit(X_train, svr_y_train)\n",
    "\n",
    "    print(\"\\n\\nSVR\\n\\n\")\n",
    "    grid_results = pd.DataFrame(grid.cv_results_)\n",
    "    display(grid_results.sort_values(by=[\"rank_test_r2\"]))\n",
    "    datetimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "    filepath = (path_to_powerflow_data + \n",
    "                \"/results/approximating_with_svr_grid_results-{}_samples-{}_label-{}.csv\".format(\n",
    "                    n_samples, datetimestamp, label))\n",
    "    print(\"Saving to \", filepath)\n",
    "    grid_results.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading values if you closed the notebook\n",
    "# filepath = (path_to_powerflow_data +\n",
    "#            \"/results/approximating_with_svr_grid_results-10000_samples-2019-09-12-21-08_label-12.csv\")\n",
    "imported_results = pd.read_csv(filepath)\n",
    "display(imported_results.sort_values(by=[\"rank_test_r2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
