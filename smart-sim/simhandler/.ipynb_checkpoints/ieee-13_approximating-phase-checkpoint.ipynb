{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pypsa\n",
    "from n_dimensional_datasets import *\n",
    "from plotter import *\n",
    "\n",
    "from IPython.display import display # for better Pandas printing \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger = logging.getLogger(\"pypsa\")\n",
    "logger.setLevel(\"WARNING\")\n",
    "%matplotlib inline\n",
    "\n",
    "path_to_powerflow_example = \"../../pypsa/examples/ieee-13/\"\n",
    "path_to_powerflow_data = path_to_powerflow_example + \"/ieee-13-with-load-gen/\"\n",
    "path_to_powerflow_results = path_to_powerflow_data + \"results/\"\n",
    "\n",
    "sys.path.append(path_to_powerflow_example)\n",
    "from ieee13_pf import run\n",
    "\n",
    "from change_powerflow_data import set_sample_size\n",
    "\n",
    "def reject_outliers(data, m=3, return_positions=False):\n",
    "    positions = abs(data - np.mean(data)) < m * np.std(data)\n",
    "    if return_positions:\n",
    "        return positions\n",
    "    return data[positions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_original_samples = 2\n",
    "\n",
    "if n_original_samples < 2:\n",
    "    raise ValueError(\"n_original_samples must be an integer >1\")\n",
    "\n",
    "sample_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalise_column_names(df, name):\n",
    "        new_columns = []\n",
    "        for column in df.columns:\n",
    "            new_columns.append(name +  \"-\" + str(column))\n",
    "        df.columns = new_columns\n",
    "        return pd.DataFrame(df)\n",
    "\n",
    "def collect_data(data):\n",
    "    data[\"loads\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"loads-p_set.csv\"), \"load\")\n",
    "    data[\"vmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_results + \"vmags.csv\"), \"vmag\")\n",
    "    data[\"vangs\"] = personalise_column_names(pd.read_csv(path_to_powerflow_results + \"vangs.csv\"), \"vang\")\n",
    "    data[\"qmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_results + \"qmags.csv\"), \"qmag\")\n",
    "    data[\"linemags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_results + \"linemags.csv\"), \"linemag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_change = [\"loads-p_set\", \"snapshots\", \"loads-q_set\"]\n",
    "\n",
    "# set_sample_size(path_to_powerflow_data, data_to_change, sample_size, n_original_samples, seed=None)\n",
    "# network = run()\n",
    "\n",
    "\n",
    "data = {\"loads\": [], \"vmags\": [], \"vangs\": [], \"qmags\": [], \"linemags\": []}\n",
    "collect_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from custom_transformers import DataFrameSelector, RejectOutliers\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[\"loads\"].drop(\"load-name\", axis=1)\n",
    "labels = data[\"vangs\"].loc[:,[\"vang-632\", \"vang-671\", \"vang-675\"]]\n",
    "features_and_labels = features.join(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformations\n",
    "\n",
    "all_pipeline = Pipeline([\n",
    "    (\"outliers\", RejectOutliers(labels.columns)),\n",
    "])\n",
    "\n",
    "features_and_labels = pd.DataFrame(all_pipeline.fit_transform(features_and_labels)) \n",
    "features = features_and_labels[[col for col in features_and_labels if 'load' in col]]\n",
    "labels = features_and_labels[[col for col in features_and_labels if 'vang' in col]]\n",
    "\n",
    "feature_pipeline = Pipeline([\n",
    "#     (\"selector\", DataFrameSelector([\"load-671\", \"load-675\"])),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA())\n",
    "])\n",
    "feature_pipeline.set_params(pca__n_components=0.95)\n",
    "\n",
    "features = pd.DataFrame(feature_pipeline.fit_transform(features)) # usually columns=features.columns but with pca it doesn't always work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_percentage = 80\n",
    "n_samples = features.shape[0]\n",
    "n_training_samples = int(n_samples*(training_percentage/100))\n",
    "\n",
    "random_seed=0\n",
    "X_train = features.sample(n_training_samples, random_state=random_seed)\n",
    "y_train = labels.sample(n_training_samples, random_state=random_seed)\n",
    "X_val = features[~features.isin(X_train)].dropna()\n",
    "y_val = labels[~labels.isin(y_train)].dropna()\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_val = X_val.values\n",
    "y_val = y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stats: {'n_training_samples': 797}\n",
      "\n",
      " svr Stats: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainscore</th>\n",
       "      <th>trainscorevar</th>\n",
       "      <th>valscore</th>\n",
       "      <th>valscorevar</th>\n",
       "      <th>mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.762583</td>\n",
       "      <td>0.026486</td>\n",
       "      <td>0.756792</td>\n",
       "      <td>0.047527</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>50.0124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trainscore  trainscorevar  valscore  valscorevar       mae     time\n",
       "0    0.762583       0.026486  0.756792     0.047527 -0.000057  50.0124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " rf Stats: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainscore</th>\n",
       "      <th>trainscorevar</th>\n",
       "      <th>valscore</th>\n",
       "      <th>valscorevar</th>\n",
       "      <th>mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.582559</td>\n",
       "      <td>0.016742</td>\n",
       "      <td>0.57299</td>\n",
       "      <td>0.054713</td>\n",
       "      <td>-0.00011</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trainscore  trainscorevar  valscore  valscorevar      mae      time\n",
       "0    0.582559       0.016742   0.57299     0.054713 -0.00011  0.000075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " interp Stats: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainscore</th>\n",
       "      <th>valscore</th>\n",
       "      <th>mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [trainscore, valscore, mae, time]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svr training score - non crossvalidation:  0.683335363518906\n",
      "svr validation score - non crossvalidation:  0.6896891295959366\n",
      "rf training score - non crossvalidation:  0.9224637799921137\n",
      "rf validation score - non crossvalidation:  0.6480399664406761\n"
     ]
    }
   ],
   "source": [
    "training_stats = {\"n_training_samples\": n_training_samples}\n",
    "stats = {\"trainscore\": [], \n",
    "         \"trainscorevar\": [],\n",
    "         \"valscore\": [],\n",
    "         \"valscorevar\": [],\n",
    "         \"mae\": [],\n",
    "         \"time\": []}\n",
    "approx_type = {\"svr\": copy.deepcopy(stats),\n",
    "               \"rf\": copy.deepcopy(stats),\n",
    "               \"interp\": copy.deepcopy(stats)}\n",
    "approx_type[\"interp\"].pop(\"trainscorevar\")\n",
    "approx_type[\"interp\"].pop(\"valscorevar\")\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "### setup approximators\n",
    "\n",
    "\n",
    "## random forest\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "time_forest = time.time()\n",
    "approx_type[\"rf\"][\"time\"].append(time_forest-time_start)\n",
    "\n",
    "forest_xval_training_score = reject_outliers(cross_val_score(forest, X_train, y_train, cv=5, n_jobs=-1))\n",
    "forest_xval_val_score = reject_outliers(cross_val_score(forest, X_val, y_val, cv=5, n_jobs=-1))\n",
    "approx_type[\"rf\"][\"trainscore\"].append(forest_xval_training_score.mean())\n",
    "approx_type[\"rf\"][\"trainscorevar\"].append(forest_xval_training_score.std())\n",
    "approx_type[\"rf\"][\"valscore\"].append(forest_xval_val_score.mean())\n",
    "approx_type[\"rf\"][\"valscorevar\"].append(forest_xval_val_score.std())\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "approx_type[\"rf\"][\"mae\"].append(np.mean(y_val-forest.predict(X_val)))\n",
    "\n",
    "                                \n",
    "## support vector regression\n",
    "n_labels = y_train.shape[1]\n",
    "svr = copy.deepcopy(stats)\n",
    "svr_labels = {\"y_train\": None, \"y_val\": None}\n",
    "for idx in range(n_labels):\n",
    "    svr_labels[\"y_train\"] = y_train.T[idx].T\n",
    "    svr_labels[\"y_val\"] = y_val.T[idx].T\n",
    "    clf = SVR(gamma='scale', C=1.0, epsilon=0.0002, kernel='linear')\n",
    "    '''\n",
    "    Scikit-Learn cross-validation features expect a utility function (greater is better) rather than a cost function\n",
    "    (lower is better), so the scoring function is actually the opposite of the MSE (i.e., a negative value), \n",
    "    which is why the preceding code computes -scores before calculating the square root.\n",
    "    - A. Geron, Hands on Machine Learning pg 101 \n",
    "    '''\n",
    "    svr_xval_training_score = reject_outliers(cross_val_score(clf, X_train, svr_labels[\"y_train\"], cv=5, n_jobs=-1))\n",
    "    svr_xval_val_score = reject_outliers(cross_val_score(clf, X_val, svr_labels[\"y_val\"], cv=5, n_jobs=-1))    \n",
    "    svr[\"trainscore\"].append(svr_xval_training_score.mean())\n",
    "    svr[\"trainscorevar\"].append(svr_xval_training_score.std())\n",
    "    svr[\"valscore\"].append(svr_xval_val_score.mean())\n",
    "    svr[\"valscorevar\"].append(svr_xval_val_score.std())\n",
    "\n",
    "    clf.fit(X_train, svr_labels[\"y_train\"])\n",
    "    svr[\"mae\"].append(np.mean(svr_labels[\"y_val\"]-clf.predict(X_val)))\n",
    "\n",
    "    time_svr = time.time()\n",
    "    svr[\"time\"].append(time_svr - time_forest)\n",
    "\n",
    "approx_type[\"svr\"][\"trainscore\"].append(np.mean(svr[\"trainscore\"]))\n",
    "approx_type[\"svr\"][\"trainscorevar\"].append(np.mean(svr[\"trainscorevar\"]))\n",
    "approx_type[\"svr\"][\"valscore\"].append(np.mean(svr[\"valscore\"]))\n",
    "approx_type[\"svr\"][\"valscorevar\"].append(np.mean(svr[\"valscorevar\"]))\n",
    "approx_type[\"svr\"][\"mae\"].append(np.mean(svr[\"mae\"]))\n",
    "approx_type[\"svr\"][\"time\"].append(np.mean(svr[\"time\"]))\n",
    "\n",
    "\n",
    "## interpolation\n",
    "# interp training gets very slow as the number of features grows\n",
    "if X_train.shape[1] < 4:\n",
    "    interp = LinearNDInterpolator(X_train, y_train, fill_value=0)\n",
    "\n",
    "    time_interp = time.time()\n",
    "    approx_type[\"interp\"][\"time\"].append(time_interp-time_svr)\n",
    "\n",
    "    approx_type[\"interp\"][\"trainscore\"].append(r2_score(y_train, interp(X_train)))\n",
    "    approx_type[\"interp\"][\"valscore\"].append(r2_score(y_val, interp(X_val)))\n",
    "    approx_type[\"interp\"][\"mae\"].append(np.mean(y_val-interp(X_val)))\n",
    "\n",
    "\n",
    "## print stats\n",
    "print(\"Training Stats: {}\".format(training_stats))\n",
    "for t in approx_type:\n",
    "    print(\"\\n\", t + \" Stats: \\n\")\n",
    "    display(pd.DataFrame(approx_type[t]))\n",
    "\n",
    "print(\"svr training score - non crossvalidation: \", r2_score(svr_labels[\"y_train\"], clf.predict(X_train)))\n",
    "print(\"svr validation score - non crossvalidation: \", r2_score(svr_labels[\"y_val\"], clf.predict(X_val)))\n",
    "print(\"rf training score - non crossvalidation: \", r2_score(y_train, forest.predict(X_train)))\n",
    "print(\"rf validation score - non crossvalidation: \", r2_score(y_val, forest.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "from plotter import plot3d_approximation\n",
    "\n",
    "if X_train.shape[1] == 1:\n",
    "    plt.plot(X_train, clf.predict(X_train), \"x\", X_train, y_train, \"o\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(X_val, clf.predict(X_val), \"x\", X_val, y_val, \"o\")\n",
    "    plt.show()\n",
    "    \n",
    "elif X_train.shape[1] == 2:\n",
    "    plot3d_approximation(X_train.T, y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f02ff30c76f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPermutationImportance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0meli5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/eli5/ipython.py\u001b[0m in \u001b[0;36mshow_weights\u001b[0;34m(estimator, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mformat_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplain_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mexpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplain_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexplain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_as_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/eli5/formatters/html.py\u001b[0m in \u001b[0;36mformat_as_html\u001b[0;34m(explanation, include_styles, force_weights, show, preserve_density, highlight_spaces, horizontal_layout, show_feature_values)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemplate_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'explain.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhighlight_spaces\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mhighlight_spaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshould_highlight_spaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplanation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/eli5/formatters/utils.py\u001b[0m in \u001b[0;36mshould_highlight_spaces\u001b[0;34m(explanation)\u001b[0m\n\u001b[1;32m     67\u001b[0m         hl_spaces = hl_spaces or any(\n\u001b[1;32m     68\u001b[0m             \u001b[0m_has_invisible_spaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             for fw in explanation.feature_importances.importances)\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexplanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         hl_spaces = hl_spaces or any(\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/eli5/formatters/utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m         hl_spaces = hl_spaces or any(\n\u001b[1;32m     68\u001b[0m             \u001b[0m_has_invisible_spaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             for fw in explanation.feature_importances.importances)\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexplanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         hl_spaces = hl_spaces or any(\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/eli5/formatters/utils.py\u001b[0m in \u001b[0;36m_has_invisible_spaces\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_has_invisible_spaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(forest, random_state=1).fit(X_val, y_val)\n",
    "eli5.show_weights(perm, feature_names=features.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
