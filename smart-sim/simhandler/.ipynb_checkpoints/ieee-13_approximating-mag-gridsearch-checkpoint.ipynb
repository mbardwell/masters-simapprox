{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pypsa\n",
    "from n_dimensional_datasets import *\n",
    "from plotter import *\n",
    "\n",
    "from IPython.display import display # for better Pandas printing \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger = logging.getLogger(\"pypsa\")\n",
    "logger.setLevel(\"WARNING\")\n",
    "%matplotlib inline\n",
    "\n",
    "path_to_powerflow_example = \"../../pypsa/examples/ieee-13/\"\n",
    "path_to_powerflow_data = path_to_powerflow_example + \"/ieee-13-with-load-gen/\"\n",
    "path_to_powerflow_results = path_to_powerflow_data + \"results/\"\n",
    "\n",
    "sys.path.append(path_to_powerflow_example)\n",
    "from ieee13_pf import run\n",
    "\n",
    "from change_powerflow_data import set_sample_size\n",
    "\n",
    "def reject_outliers(data, m=3, return_positions=False):\n",
    "    positions = abs(data - np.mean(data)) < m * np.std(data)\n",
    "    if return_positions:\n",
    "        return positions\n",
    "    return data[positions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_original_samples = 2\n",
    "\n",
    "if n_original_samples < 2:\n",
    "    raise ValueError(\"n_original_samples must be an integer >1\")\n",
    "\n",
    "sample_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalise_column_names(df, name):\n",
    "        new_columns = []\n",
    "        for column in df.columns:\n",
    "            new_columns.append(name +  \"-\" + str(column))\n",
    "        df.columns = new_columns\n",
    "        return pd.DataFrame(df)\n",
    "\n",
    "def collect_data(data):\n",
    "    data[\"loads\"] = personalise_column_names(pd.read_csv(path_to_powerflow_data + \"loads-p_set.csv\"), \"load\")\n",
    "    data[\"vmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_results + \"vmags.csv\"), \"vmag\")\n",
    "    data[\"vangs\"] = personalise_column_names(pd.read_csv(path_to_powerflow_results + \"vangs.csv\"), \"vang\")\n",
    "    data[\"qmags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_results + \"qmags.csv\"), \"qmag\")\n",
    "    data[\"linemags\"] = personalise_column_names(pd.read_csv(path_to_powerflow_results + \"linemags.csv\"), \"linemag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_to_change = [\"loads-p_set\", \"snapshots\", \"loads-q_set\"]\n",
    "\n",
    "# set_sample_size(path_to_powerflow_data, data_to_change, sample_size, n_original_samples, seed=None)\n",
    "# network = run() # savefig=[\"real-loading\", \"\"reactive-loading\", \"generation\", \"line-loading\", \"reactive-feedin\"]\n",
    "\n",
    "\n",
    "data = {\"loads\": [], \"vmags\": [], \"vangs\": [], \"qmags\": [], \"linemags\": []}\n",
    "collect_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from custom_transformers import DataFrameSelector, RejectOutliers\n",
    "from sklearn.decomposition import PCA\n",
    "from scoring import rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[\"loads\"].drop(\"load-name\", axis=1)\n",
    "labels = data[\"vmags\"].drop([\"vmag-name\", \"vmag-Substation\"], axis=1) #loc[:,[\"vmag-632\", \"vmag-671\", \"vmag-675\"]]\n",
    "features_and_labels = features.join(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformations\n",
    "\n",
    "all_pipeline = Pipeline([\n",
    "    (\"outliers\", RejectOutliers(labels.columns)),\n",
    "])\n",
    "\n",
    "features_and_labels = pd.DataFrame(all_pipeline.fit_transform(features_and_labels)) \n",
    "features = features_and_labels[[col for col in features_and_labels if 'load' in col]]\n",
    "labels = features_and_labels[[col for col in features_and_labels if 'vmag' in col]]\n",
    "\n",
    "feature_pipeline = Pipeline([\n",
    "#     (\"selector\", DataFrameSelector([\"load-671\", \"load-675\"])),\n",
    "    (\"pca\", PCA()),\n",
    "#     (\"scaler\", StandardScaler()),\n",
    "])\n",
    "feature_pipeline.set_params(pca__n_components=0.95)\n",
    "\n",
    "attributes = list(labels.keys())\n",
    "attributes.remove(\"vmag-634\")\n",
    "attributes.remove(\"vmag-650\")\n",
    "label_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(attributes))\n",
    "])\n",
    "\n",
    "# features = pd.DataFrame(feature_pipeline.fit_transform(features)) #columns=features.columns\n",
    "labels = pd.DataFrame(label_pipeline.fit_transform(labels), columns=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_percentage = 80\n",
    "n_samples = features.shape[0]\n",
    "n_training_samples = int(n_samples*(training_percentage/100))\n",
    "\n",
    "random_seed=0\n",
    "X_train = features.sample(n_training_samples, random_state=random_seed)\n",
    "y_train = labels.sample(n_training_samples, random_state=random_seed)\n",
    "X_val = features[~features.isin(X_train)].dropna()\n",
    "y_val = labels[~labels.isin(y_train)].dropna()\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_val = X_val.values\n",
    "y_val = y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##grid search params\n",
    "grid_svr = {\"C\": [1, 10], \"epsilon\": [0.001, 0.0001, 0.00001], \"kernel\":[\"linear\", \"rbf\"]}\n",
    "grid_rf = {\"n_estimators\": [10, 100, 1000], \"oob_score\": [False, True]}\n",
    "grid_ann = {\"hidden_layer_sizes\": [1, 10, 100], \n",
    "            \"activation\": [\"relu\", \"logistic\"],\n",
    "            \"alpha\": [0.00001, 0.0001, 0.001, 0.01], \n",
    "            \"beta_1\":[0.09, 0.45, 0.9], \n",
    "            \"beta_2\": [0.0999, 0.45, 0.999]}\n",
    "grid_params = {\"svr\": grid_svr, \"rf\": grid_rf, \"ann\": grid_ann}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_stats = {\"n_training_samples\": n_training_samples,\n",
    "                  \"n_validation_samples\": n_samples-n_training_samples,\n",
    "                  \"n_features\": X_train.shape[1],\n",
    "                  \"n_labels\": y_train.shape[1],\n",
    "                  \"interp_run\": False}\n",
    "stats = {\"trainscore\": [], \n",
    "         \"trainscorevar\": [],\n",
    "         \"valscore\": [],\n",
    "         \"valscorevar\": [],\n",
    "         \"rmse\": [],\n",
    "         \"time\": []}\n",
    "approx_type = {\"svr\": copy.deepcopy(stats),\n",
    "               \"rf\": copy.deepcopy(stats),\n",
    "               \"ann\": copy.deepcopy(stats),\n",
    "               \"interp\": copy.deepcopy(stats)}\n",
    "approx_type[\"interp\"].pop(\"trainscorevar\")\n",
    "approx_type[\"interp\"].pop(\"valscorevar\")\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "### setup approximators\n",
    "\n",
    "\n",
    "## random forest\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "forest_xval_training_score = reject_outliers(cross_val_score(forest, X_train, y_train, cv=5, n_jobs=-1, scoring=make_scorer(r2_score)))\n",
    "forest_xval_val_score = reject_outliers(cross_val_score(forest, X_val, y_val, cv=5, n_jobs=-1, scoring=make_scorer(r2_score)))\n",
    "approx_type[\"rf\"][\"trainscore\"].append(forest_xval_training_score.mean())\n",
    "approx_type[\"rf\"][\"trainscorevar\"].append(forest_xval_training_score.std())\n",
    "approx_type[\"rf\"][\"valscore\"].append(forest_xval_val_score.mean())\n",
    "approx_type[\"rf\"][\"valscorevar\"].append(forest_xval_val_score.std())\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "approx_type[\"rf\"][\"rmse\"].append(rmse(forest.predict(X_val), y_val))\n",
    "\n",
    "time_forest = time.time()\n",
    "approx_type[\"rf\"][\"time\"].append(time_forest-time_start)\n",
    "\n",
    "grid = GridSearchCV(forest, grid_params[\"rf\"], cv=5, n_jobs=-1, scoring=make_scorer(r2_score), iid=False)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"\\n\\n rf grid: \\n\\n\")\n",
    "display(pd.DataFrame(grid.cv_results_))\n",
    "                                \n",
    "## support vector regression\n",
    "n_labels = y_train.shape[1]\n",
    "svr = copy.deepcopy(stats)\n",
    "svr_labels = {\"y_train\": None, \"y_val\": None}\n",
    "for idx in range(n_labels):\n",
    "    svr_labels[\"y_train\"] = y_train.T[idx].T\n",
    "    svr_labels[\"y_val\"] = y_val.T[idx].T\n",
    "    clf = SVR(gamma='scale', C=1.0, epsilon=0.0002, kernel='linear')\n",
    "    '''\n",
    "    Scikit-Learn cross-validation features expect a utility function (greater is better) rather than a cost function\n",
    "    (lower is better), so the scoring function is actually the opposite of the MSE (i.e., a negative value), \n",
    "    which is why the preceding code computes -scores before calculating the square root.\n",
    "    - A. Geron, Hands on Machine Learning pg 101 \n",
    "    '''\n",
    "    svr_xval_training_score = reject_outliers(cross_val_score(clf, X_train, svr_labels[\"y_train\"], cv=5, n_jobs=-1, scoring=make_scorer(r2_score)))\n",
    "    svr_xval_val_score = reject_outliers(cross_val_score(clf, X_val, svr_labels[\"y_val\"], cv=5, n_jobs=-1, scoring=make_scorer(r2_score)))    \n",
    "    svr[\"trainscore\"].append(svr_xval_training_score.mean())\n",
    "    svr[\"trainscorevar\"].append(svr_xval_training_score.std())\n",
    "    svr[\"valscore\"].append(svr_xval_val_score.mean())\n",
    "    svr[\"valscorevar\"].append(svr_xval_val_score.std())\n",
    "\n",
    "    clf.fit(X_train, svr_labels[\"y_train\"])\n",
    "    svr[\"rmse\"].append(rmse(clf.predict(X_val), svr_labels[\"y_val\"]))\n",
    "\n",
    "    time_svr = time.time()\n",
    "    svr[\"time\"].append(time_svr - time_forest)\n",
    "    \n",
    "    if idx == (n_labels-1):\n",
    "        display(\"rmse: \", svr[\"rmse\"])\n",
    "        label_results = pd.DataFrame(columns=labels.columns)\n",
    "        label_results.loc[0] = svr[\"trainscore\"]\n",
    "        display(label_results)\n",
    "\n",
    "approx_type[\"svr\"][\"trainscore\"].append(np.mean(svr[\"trainscore\"]))\n",
    "approx_type[\"svr\"][\"trainscorevar\"].append(np.mean(svr[\"trainscorevar\"]))\n",
    "approx_type[\"svr\"][\"valscore\"].append(np.mean(svr[\"valscore\"]))\n",
    "approx_type[\"svr\"][\"valscorevar\"].append(np.mean(svr[\"valscorevar\"]))\n",
    "approx_type[\"svr\"][\"rmse\"].append(np.mean(svr[\"rmse\"]))\n",
    "approx_type[\"svr\"][\"time\"].append(np.mean(svr[\"time\"]))\n",
    "\n",
    "\n",
    "## ann\n",
    "hidden_layer_size = 5\n",
    "ann = MLPRegressor(hidden_layer_sizes=(hidden_layer_size,),\n",
    "#                    activation=\"relu\",\n",
    "                   solver=\"lbfgs\",\n",
    "                   alpha=0.001,\n",
    "                   learning_rate_init=0.00000001,\n",
    "                   tol=1e-6,\n",
    "                   n_iter_no_change=1000\n",
    "                  )\n",
    "\n",
    "ann_xval_training_score = reject_outliers(cross_val_score(ann, X_train, y_train, cv=5, n_jobs=-1, scoring=make_scorer(r2_score)))\n",
    "ann_xval_val_score = reject_outliers(cross_val_score(ann, X_val, y_val, cv=5, n_jobs=-1, scoring=make_scorer(r2_score)))\n",
    "approx_type[\"ann\"][\"trainscore\"].append(ann_xval_training_score.mean())\n",
    "approx_type[\"ann\"][\"trainscorevar\"].append(ann_xval_training_score.std())\n",
    "approx_type[\"ann\"][\"valscore\"].append(ann_xval_val_score.mean())\n",
    "approx_type[\"ann\"][\"valscorevar\"].append(ann_xval_val_score.std())\n",
    "print(\"\\n\\nANN training scores: {}\\n\\n val scores: {}\".format(ann_xval_training_score, ann_xval_val_score))\n",
    "\n",
    "ann.fit(X_train, y_train)\n",
    "approx_type[\"ann\"][\"rmse\"].append(rmse(ann.predict(X_val), y_val))\n",
    "\n",
    "time_ann = time.time()\n",
    "approx_type[\"ann\"][\"time\"].append(time_ann-time_svr)\n",
    "\n",
    "grid = GridSearchCV(ann, grid_params[\"ann\"], cv=5, n_jobs=-1, scoring=make_scorer(r2_score), iid=False)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"\\n\\n ann grid: \\n\\n\")\n",
    "display(pd.DataFrame(grid.cv_results_))\n",
    "\n",
    "\n",
    "## interpolation\n",
    "# interp training gets very slow as the number of features grows\n",
    "if X_train.shape[1] < 4:\n",
    "    training_stats[\"interp_run\"] = True\n",
    "    interp = LinearNDInterpolator(X_train, y_train, fill_value=0)\n",
    "\n",
    "    time_interp = time.time()\n",
    "    approx_type[\"interp\"][\"time\"].append(time_interp-time_ann)\n",
    "\n",
    "    approx_type[\"interp\"][\"trainscore\"].append(r2_score(y_train, interp(X_train)))\n",
    "    approx_type[\"interp\"][\"valscore\"].append(r2_score(y_val, interp(X_val)))\n",
    "    approx_type[\"interp\"][\"rmse\"].append(rmse(interp(X_val), y_val))\n",
    "\n",
    "\n",
    "## print stats\n",
    "print(\"Training Stats\\n\\n{}\".format(pd.DataFrame(training_stats, index=[0])))\n",
    "for t in approx_type:\n",
    "    print(\"\\n\", t + \" Stats: \\n\")\n",
    "    display(pd.DataFrame(approx_type[t]).round(3))\n",
    "\n",
    "print(\"svr training score - non crossvalidation: \", r2_score(svr_labels[\"y_train\"], clf.predict(X_train)))\n",
    "print(\"svr validation score - non crossvalidation: \", r2_score(svr_labels[\"y_val\"], clf.predict(X_val)))\n",
    "print(\"rf training score - non crossvalidation: \", r2_score(y_train, forest.predict(X_train)))\n",
    "print(\"rf validation score - non crossvalidation: \", r2_score(y_val, forest.predict(X_val)))\n",
    "print(\"ann training score - non crossvalidation: \", r2_score(y_train, ann.predict(X_train)))\n",
    "print(\"ann validation score - non crossvalidation: \", r2_score(y_val, ann.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ann grid: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_beta_1</th>\n",
       "      <th>param_beta_2</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.110814</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.000955</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.096699</td>\n",
       "      <td>0.310742</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.568394</td>\n",
       "      <td>0.416887</td>\n",
       "      <td>0.516952</td>\n",
       "      <td>0.358329</td>\n",
       "      <td>0.532417</td>\n",
       "      <td>0.478596</td>\n",
       "      <td>0.078363</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.421671</td>\n",
       "      <td>1.027960</td>\n",
       "      <td>0.019862</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.542235</td>\n",
       "      <td>0.438345</td>\n",
       "      <td>0.536051</td>\n",
       "      <td>0.564247</td>\n",
       "      <td>0.632739</td>\n",
       "      <td>0.542723</td>\n",
       "      <td>0.062459</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.336871</td>\n",
       "      <td>0.401705</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.419023</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>0.499855</td>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.226613</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.074138</td>\n",
       "      <td>0.423886</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.358384</td>\n",
       "      <td>0.534117</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>0.586689</td>\n",
       "      <td>0.338011</td>\n",
       "      <td>0.483632</td>\n",
       "      <td>0.112985</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.251752</td>\n",
       "      <td>2.248055</td>\n",
       "      <td>0.025959</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.455817</td>\n",
       "      <td>0.514723</td>\n",
       "      <td>0.529652</td>\n",
       "      <td>0.596713</td>\n",
       "      <td>0.094028</td>\n",
       "      <td>0.438187</td>\n",
       "      <td>0.177826</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.084029</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>-0.000680</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.443947</td>\n",
       "      <td>0.507667</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.621309</td>\n",
       "      <td>0.347340</td>\n",
       "      <td>0.677044</td>\n",
       "      <td>0.174573</td>\n",
       "      <td>0.567382</td>\n",
       "      <td>0.477530</td>\n",
       "      <td>0.188300</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.777759</td>\n",
       "      <td>3.148471</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.006137</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.589365</td>\n",
       "      <td>0.557053</td>\n",
       "      <td>0.605290</td>\n",
       "      <td>-0.013030</td>\n",
       "      <td>0.632379</td>\n",
       "      <td>0.474211</td>\n",
       "      <td>0.244837</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.468842</td>\n",
       "      <td>0.537031</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.574802</td>\n",
       "      <td>0.466454</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.208095</td>\n",
       "      <td>0.257472</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.349184</td>\n",
       "      <td>0.568939</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.316348</td>\n",
       "      <td>0.461029</td>\n",
       "      <td>0.339703</td>\n",
       "      <td>0.399389</td>\n",
       "      <td>0.592049</td>\n",
       "      <td>0.421704</td>\n",
       "      <td>0.098880</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.096833</td>\n",
       "      <td>2.852519</td>\n",
       "      <td>0.021685</td>\n",
       "      <td>0.007673</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>-0.526109</td>\n",
       "      <td>0.563428</td>\n",
       "      <td>0.365656</td>\n",
       "      <td>0.264468</td>\n",
       "      <td>0.582646</td>\n",
       "      <td>0.250018</td>\n",
       "      <td>0.406158</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.095250</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.010453</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.157197</td>\n",
       "      <td>1.185017</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.605096</td>\n",
       "      <td>0.484344</td>\n",
       "      <td>0.497515</td>\n",
       "      <td>0.604554</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.438294</td>\n",
       "      <td>0.225046</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.192358</td>\n",
       "      <td>0.965848</td>\n",
       "      <td>0.021137</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.516889</td>\n",
       "      <td>0.434087</td>\n",
       "      <td>0.578734</td>\n",
       "      <td>0.586358</td>\n",
       "      <td>0.590813</td>\n",
       "      <td>0.541376</td>\n",
       "      <td>0.059956</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.368223</td>\n",
       "      <td>0.521177</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.528317</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.056537</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.094279</td>\n",
       "      <td>0.218116</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.161234</td>\n",
       "      <td>0.906662</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.225869</td>\n",
       "      <td>0.268105</td>\n",
       "      <td>0.342866</td>\n",
       "      <td>0.492851</td>\n",
       "      <td>0.579586</td>\n",
       "      <td>0.381855</td>\n",
       "      <td>0.134319</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12.594791</td>\n",
       "      <td>3.480283</td>\n",
       "      <td>0.023720</td>\n",
       "      <td>0.005841</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.385826</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.417614</td>\n",
       "      <td>-0.055982</td>\n",
       "      <td>0.397909</td>\n",
       "      <td>0.349203</td>\n",
       "      <td>0.217160</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.407357</td>\n",
       "      <td>0.410783</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.391688</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.594855</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.197232</td>\n",
       "      <td>0.250108</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.949925</td>\n",
       "      <td>0.436660</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.183809</td>\n",
       "      <td>0.224638</td>\n",
       "      <td>0.447349</td>\n",
       "      <td>0.615200</td>\n",
       "      <td>0.627052</td>\n",
       "      <td>0.419610</td>\n",
       "      <td>0.187442</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.026883</td>\n",
       "      <td>1.909340</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.503026</td>\n",
       "      <td>0.324854</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>0.461268</td>\n",
       "      <td>0.519221</td>\n",
       "      <td>0.374043</td>\n",
       "      <td>0.170416</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.338699</td>\n",
       "      <td>0.497860</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>0.591422</td>\n",
       "      <td>0.118040</td>\n",
       "      <td>0.236691</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.613270</td>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.643782</td>\n",
       "      <td>0.577708</td>\n",
       "      <td>0.308512</td>\n",
       "      <td>0.457770</td>\n",
       "      <td>0.552013</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>0.116234</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15.781595</td>\n",
       "      <td>1.134480</td>\n",
       "      <td>0.019606</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.498196</td>\n",
       "      <td>0.585153</td>\n",
       "      <td>0.470974</td>\n",
       "      <td>0.664484</td>\n",
       "      <td>0.611746</td>\n",
       "      <td>0.566111</td>\n",
       "      <td>0.071814</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.185442</td>\n",
       "      <td>0.237576</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.085200</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.017253</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.306433</td>\n",
       "      <td>1.445743</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>-0.000786</td>\n",
       "      <td>0.173680</td>\n",
       "      <td>0.585123</td>\n",
       "      <td>0.588692</td>\n",
       "      <td>0.574219</td>\n",
       "      <td>0.384186</td>\n",
       "      <td>0.249330</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14.003939</td>\n",
       "      <td>2.308253</td>\n",
       "      <td>0.021296</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'beta_1...</td>\n",
       "      <td>0.337610</td>\n",
       "      <td>0.605080</td>\n",
       "      <td>0.313146</td>\n",
       "      <td>0.384422</td>\n",
       "      <td>0.220161</td>\n",
       "      <td>0.372084</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.280208</td>\n",
       "      <td>0.394279</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'beta_...</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>0.311229</td>\n",
       "      <td>0.062001</td>\n",
       "      <td>0.124614</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.998577</td>\n",
       "      <td>0.887799</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'beta_...</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.256176</td>\n",
       "      <td>0.462518</td>\n",
       "      <td>0.456481</td>\n",
       "      <td>0.602275</td>\n",
       "      <td>0.468690</td>\n",
       "      <td>0.120552</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16.182804</td>\n",
       "      <td>2.334845</td>\n",
       "      <td>0.020753</td>\n",
       "      <td>0.005597</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'beta_...</td>\n",
       "      <td>0.560032</td>\n",
       "      <td>0.636366</td>\n",
       "      <td>0.406072</td>\n",
       "      <td>0.593818</td>\n",
       "      <td>0.616351</td>\n",
       "      <td>0.562528</td>\n",
       "      <td>0.082235</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.296753</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.001, 'be...</td>\n",
       "      <td>0.225904</td>\n",
       "      <td>0.300920</td>\n",
       "      <td>0.190479</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.127980</td>\n",
       "      <td>0.194428</td>\n",
       "      <td>0.065312</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.633742</td>\n",
       "      <td>0.169816</td>\n",
       "      <td>0.006885</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.001, 'be...</td>\n",
       "      <td>0.167175</td>\n",
       "      <td>-0.116197</td>\n",
       "      <td>-0.149911</td>\n",
       "      <td>0.551768</td>\n",
       "      <td>-0.002701</td>\n",
       "      <td>0.090027</td>\n",
       "      <td>0.256068</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.858024</td>\n",
       "      <td>0.102988</td>\n",
       "      <td>0.044698</td>\n",
       "      <td>0.011098</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.001, 'be...</td>\n",
       "      <td>0.124818</td>\n",
       "      <td>-0.111816</td>\n",
       "      <td>-0.844661</td>\n",
       "      <td>-0.236850</td>\n",
       "      <td>-0.092053</td>\n",
       "      <td>-0.232112</td>\n",
       "      <td>0.327636</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.417612</td>\n",
       "      <td>0.141635</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.423547</td>\n",
       "      <td>0.386131</td>\n",
       "      <td>0.372585</td>\n",
       "      <td>-0.011616</td>\n",
       "      <td>0.118496</td>\n",
       "      <td>0.257829</td>\n",
       "      <td>0.172689</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.596902</td>\n",
       "      <td>0.247943</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.172333</td>\n",
       "      <td>0.294165</td>\n",
       "      <td>0.492977</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.526709</td>\n",
       "      <td>0.310362</td>\n",
       "      <td>0.178530</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.022377</td>\n",
       "      <td>0.188436</td>\n",
       "      <td>0.055371</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>-0.669107</td>\n",
       "      <td>-0.072648</td>\n",
       "      <td>-0.105602</td>\n",
       "      <td>-0.069565</td>\n",
       "      <td>-0.257210</td>\n",
       "      <td>-0.234826</td>\n",
       "      <td>0.227777</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.747754</td>\n",
       "      <td>0.252623</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.153590</td>\n",
       "      <td>0.255393</td>\n",
       "      <td>0.561062</td>\n",
       "      <td>0.581400</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.394849</td>\n",
       "      <td>0.167847</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.878995</td>\n",
       "      <td>0.133840</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.423487</td>\n",
       "      <td>0.165694</td>\n",
       "      <td>0.324389</td>\n",
       "      <td>-0.035147</td>\n",
       "      <td>0.159763</td>\n",
       "      <td>0.207637</td>\n",
       "      <td>0.156982</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.155001</td>\n",
       "      <td>0.111225</td>\n",
       "      <td>0.042681</td>\n",
       "      <td>0.007785</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>-0.381598</td>\n",
       "      <td>-0.242231</td>\n",
       "      <td>-0.316950</td>\n",
       "      <td>0.135364</td>\n",
       "      <td>-0.436492</td>\n",
       "      <td>-0.248382</td>\n",
       "      <td>0.202550</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.471038</td>\n",
       "      <td>0.182535</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.212963</td>\n",
       "      <td>0.132877</td>\n",
       "      <td>0.384690</td>\n",
       "      <td>-0.042726</td>\n",
       "      <td>0.247285</td>\n",
       "      <td>0.187018</td>\n",
       "      <td>0.140778</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.795906</td>\n",
       "      <td>0.101037</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.066047</td>\n",
       "      <td>0.247887</td>\n",
       "      <td>-0.187219</td>\n",
       "      <td>0.164008</td>\n",
       "      <td>0.278121</td>\n",
       "      <td>0.113769</td>\n",
       "      <td>0.167567</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.141697</td>\n",
       "      <td>0.157640</td>\n",
       "      <td>0.047174</td>\n",
       "      <td>0.015069</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>-0.568253</td>\n",
       "      <td>-0.282688</td>\n",
       "      <td>-0.189196</td>\n",
       "      <td>-0.309873</td>\n",
       "      <td>-0.140361</td>\n",
       "      <td>-0.298074</td>\n",
       "      <td>0.148392</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.604383</td>\n",
       "      <td>0.271097</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.043432</td>\n",
       "      <td>0.284608</td>\n",
       "      <td>0.154819</td>\n",
       "      <td>-0.018996</td>\n",
       "      <td>0.321410</td>\n",
       "      <td>0.157054</td>\n",
       "      <td>0.132054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.637612</td>\n",
       "      <td>0.086655</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.145483</td>\n",
       "      <td>0.104022</td>\n",
       "      <td>0.048288</td>\n",
       "      <td>0.261131</td>\n",
       "      <td>0.223766</td>\n",
       "      <td>0.156538</td>\n",
       "      <td>0.077534</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.987754</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.027969</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>-0.260425</td>\n",
       "      <td>-0.716915</td>\n",
       "      <td>-0.002649</td>\n",
       "      <td>-0.395580</td>\n",
       "      <td>-0.022913</td>\n",
       "      <td>-0.279696</td>\n",
       "      <td>0.263687</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.619867</td>\n",
       "      <td>0.227890</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.249343</td>\n",
       "      <td>0.048901</td>\n",
       "      <td>0.163429</td>\n",
       "      <td>0.644915</td>\n",
       "      <td>0.325214</td>\n",
       "      <td>0.222813</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.444623</td>\n",
       "      <td>0.233486</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.351665</td>\n",
       "      <td>0.558687</td>\n",
       "      <td>0.072299</td>\n",
       "      <td>0.314576</td>\n",
       "      <td>0.127839</td>\n",
       "      <td>0.285013</td>\n",
       "      <td>0.173300</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1.437379</td>\n",
       "      <td>0.775998</td>\n",
       "      <td>0.044507</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>-0.120773</td>\n",
       "      <td>-0.107591</td>\n",
       "      <td>-0.571167</td>\n",
       "      <td>0.543034</td>\n",
       "      <td>-0.143270</td>\n",
       "      <td>-0.079953</td>\n",
       "      <td>0.356607</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.308952</td>\n",
       "      <td>0.224882</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.362255</td>\n",
       "      <td>0.497441</td>\n",
       "      <td>0.189943</td>\n",
       "      <td>0.076684</td>\n",
       "      <td>0.067813</td>\n",
       "      <td>0.238827</td>\n",
       "      <td>0.167356</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.640025</td>\n",
       "      <td>0.275764</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>-0.007599</td>\n",
       "      <td>0.541070</td>\n",
       "      <td>0.445922</td>\n",
       "      <td>0.499152</td>\n",
       "      <td>-0.081272</td>\n",
       "      <td>0.279455</td>\n",
       "      <td>0.267187</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1.325892</td>\n",
       "      <td>0.902524</td>\n",
       "      <td>0.034991</td>\n",
       "      <td>0.015441</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>-0.400241</td>\n",
       "      <td>-0.138285</td>\n",
       "      <td>-0.803022</td>\n",
       "      <td>-0.451992</td>\n",
       "      <td>0.532213</td>\n",
       "      <td>-0.252265</td>\n",
       "      <td>0.445762</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.205709</td>\n",
       "      <td>0.134653</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.556223</td>\n",
       "      <td>-0.030651</td>\n",
       "      <td>-0.002011</td>\n",
       "      <td>0.322076</td>\n",
       "      <td>0.010982</td>\n",
       "      <td>0.171324</td>\n",
       "      <td>0.231267</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.577834</td>\n",
       "      <td>0.308017</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.045437</td>\n",
       "      <td>0.467813</td>\n",
       "      <td>0.175126</td>\n",
       "      <td>-0.033847</td>\n",
       "      <td>-0.471861</td>\n",
       "      <td>0.036534</td>\n",
       "      <td>0.306172</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2.216873</td>\n",
       "      <td>1.353641</td>\n",
       "      <td>0.049533</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>-0.045824</td>\n",
       "      <td>-0.473705</td>\n",
       "      <td>0.553445</td>\n",
       "      <td>-0.256951</td>\n",
       "      <td>0.575279</td>\n",
       "      <td>0.070449</td>\n",
       "      <td>0.425430</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.501939</td>\n",
       "      <td>0.276105</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.254007</td>\n",
       "      <td>0.278073</td>\n",
       "      <td>0.086041</td>\n",
       "      <td>0.471047</td>\n",
       "      <td>0.043209</td>\n",
       "      <td>0.226476</td>\n",
       "      <td>0.152672</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.803646</td>\n",
       "      <td>0.304703</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.079831</td>\n",
       "      <td>0.257197</td>\n",
       "      <td>0.280319</td>\n",
       "      <td>0.394828</td>\n",
       "      <td>0.241575</td>\n",
       "      <td>0.250750</td>\n",
       "      <td>0.100967</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.042577</td>\n",
       "      <td>0.119215</td>\n",
       "      <td>0.048486</td>\n",
       "      <td>0.019974</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>-0.229664</td>\n",
       "      <td>-0.164963</td>\n",
       "      <td>-0.419449</td>\n",
       "      <td>-0.616677</td>\n",
       "      <td>-0.248550</td>\n",
       "      <td>-0.335861</td>\n",
       "      <td>0.163678</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.543882</td>\n",
       "      <td>0.138755</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>0.151517</td>\n",
       "      <td>0.553421</td>\n",
       "      <td>0.270664</td>\n",
       "      <td>0.538154</td>\n",
       "      <td>0.109198</td>\n",
       "      <td>0.324591</td>\n",
       "      <td>0.188271</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.852372</td>\n",
       "      <td>0.297949</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>-0.030211</td>\n",
       "      <td>0.127306</td>\n",
       "      <td>0.398127</td>\n",
       "      <td>0.361919</td>\n",
       "      <td>0.403895</td>\n",
       "      <td>0.252207</td>\n",
       "      <td>0.174183</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.980184</td>\n",
       "      <td>0.161953</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>0.020798</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>100</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.01, 'bet...</td>\n",
       "      <td>-0.338133</td>\n",
       "      <td>-0.579269</td>\n",
       "      <td>-0.592183</td>\n",
       "      <td>-0.525839</td>\n",
       "      <td>-0.301016</td>\n",
       "      <td>-0.467288</td>\n",
       "      <td>0.123202</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.110814      0.092080         0.004718        0.002441   \n",
       "1         2.096699      0.310742         0.002508        0.001954   \n",
       "2        10.421671      1.027960         0.019862        0.004948   \n",
       "3         0.336871      0.401705         0.003071        0.001095   \n",
       "4         2.074138      0.423886         0.002770        0.002429   \n",
       "5        11.251752      2.248055         0.025959        0.005271   \n",
       "6         0.084029      0.007519         0.003780        0.000756   \n",
       "7         2.443947      0.507667         0.002993        0.002044   \n",
       "8        11.777759      3.148471         0.021973        0.006137   \n",
       "9         0.468842      0.537031         0.004223        0.000681   \n",
       "10        2.349184      0.568939         0.002077        0.000199   \n",
       "11       10.096833      2.852519         0.021685        0.007673   \n",
       "12        0.095250      0.020542         0.004222        0.001062   \n",
       "13        2.157197      1.185017         0.004601        0.004498   \n",
       "14       14.192358      0.965848         0.021137        0.007845   \n",
       "15        0.368223      0.521177         0.004813        0.000572   \n",
       "16        3.161234      0.906662         0.002232        0.000126   \n",
       "17       12.594791      3.480283         0.023720        0.005841   \n",
       "18        0.407357      0.410783         0.004689        0.001030   \n",
       "19        2.949925      0.436660         0.002168        0.000094   \n",
       "20       14.026883      1.909340         0.020380        0.007871   \n",
       "21        0.338699      0.497860         0.005526        0.002963   \n",
       "22        2.613270      0.974643         0.003748        0.001990   \n",
       "23       15.781595      1.134480         0.019606        0.011869   \n",
       "24        0.185442      0.237576         0.005924        0.002244   \n",
       "25        3.306433      1.445743         0.005322        0.003402   \n",
       "26       14.003939      2.308253         0.021296        0.003920   \n",
       "27        0.280208      0.394279         0.005865        0.002624   \n",
       "28        2.998577      0.887799         0.002235        0.000207   \n",
       "29       16.182804      2.334845         0.020753        0.005597   \n",
       "..             ...           ...              ...             ...   \n",
       "186       0.296753      0.071289         0.004273        0.001335   \n",
       "187       0.633742      0.169816         0.006885        0.004388   \n",
       "188       0.858024      0.102988         0.044698        0.011098   \n",
       "189       0.417612      0.141635         0.003792        0.001388   \n",
       "190       0.596902      0.247943         0.004749        0.003452   \n",
       "191       1.022377      0.188436         0.055371        0.007375   \n",
       "192       0.747754      0.252623         0.009156        0.003444   \n",
       "193       0.878995      0.133840         0.002818        0.001646   \n",
       "194       1.155001      0.111225         0.042681        0.007785   \n",
       "195       0.471038      0.182535         0.004192        0.001325   \n",
       "196       0.795906      0.101037         0.012367        0.002551   \n",
       "197       1.141697      0.157640         0.047174        0.015069   \n",
       "198       0.604383      0.271097         0.005024        0.001294   \n",
       "199       0.637612      0.086655         0.003530        0.002138   \n",
       "200       0.987754      0.091400         0.027969        0.011934   \n",
       "201       0.619867      0.227890         0.006032        0.000629   \n",
       "202       0.444623      0.233486         0.002037        0.000351   \n",
       "203       1.437379      0.775998         0.044507        0.019269   \n",
       "204       0.308952      0.224882         0.002590        0.001178   \n",
       "205       0.640025      0.275764         0.005402        0.005804   \n",
       "206       1.325892      0.902524         0.034991        0.015441   \n",
       "207       0.205709      0.134653         0.003215        0.002196   \n",
       "208       0.577834      0.308017         0.004021        0.004331   \n",
       "209       2.216873      1.353641         0.049533        0.012996   \n",
       "210       0.501939      0.276105         0.002707        0.000746   \n",
       "211       0.803646      0.304703         0.001896        0.000090   \n",
       "212       1.042577      0.119215         0.048486        0.019974   \n",
       "213       0.543882      0.138755         0.005519        0.001120   \n",
       "214       0.852372      0.297949         0.001994        0.000100   \n",
       "215       0.980184      0.161953         0.027792        0.020798   \n",
       "\n",
       "    param_activation param_alpha param_beta_1 param_beta_2  \\\n",
       "0               relu       1e-05         0.09       0.0999   \n",
       "1               relu       1e-05         0.09       0.0999   \n",
       "2               relu       1e-05         0.09       0.0999   \n",
       "3               relu       1e-05         0.09         0.45   \n",
       "4               relu       1e-05         0.09         0.45   \n",
       "5               relu       1e-05         0.09         0.45   \n",
       "6               relu       1e-05         0.09        0.999   \n",
       "7               relu       1e-05         0.09        0.999   \n",
       "8               relu       1e-05         0.09        0.999   \n",
       "9               relu       1e-05         0.45       0.0999   \n",
       "10              relu       1e-05         0.45       0.0999   \n",
       "11              relu       1e-05         0.45       0.0999   \n",
       "12              relu       1e-05         0.45         0.45   \n",
       "13              relu       1e-05         0.45         0.45   \n",
       "14              relu       1e-05         0.45         0.45   \n",
       "15              relu       1e-05         0.45        0.999   \n",
       "16              relu       1e-05         0.45        0.999   \n",
       "17              relu       1e-05         0.45        0.999   \n",
       "18              relu       1e-05          0.9       0.0999   \n",
       "19              relu       1e-05          0.9       0.0999   \n",
       "20              relu       1e-05          0.9       0.0999   \n",
       "21              relu       1e-05          0.9         0.45   \n",
       "22              relu       1e-05          0.9         0.45   \n",
       "23              relu       1e-05          0.9         0.45   \n",
       "24              relu       1e-05          0.9        0.999   \n",
       "25              relu       1e-05          0.9        0.999   \n",
       "26              relu       1e-05          0.9        0.999   \n",
       "27              relu      0.0001         0.09       0.0999   \n",
       "28              relu      0.0001         0.09       0.0999   \n",
       "29              relu      0.0001         0.09       0.0999   \n",
       "..               ...         ...          ...          ...   \n",
       "186         logistic       0.001          0.9        0.999   \n",
       "187         logistic       0.001          0.9        0.999   \n",
       "188         logistic       0.001          0.9        0.999   \n",
       "189         logistic        0.01         0.09       0.0999   \n",
       "190         logistic        0.01         0.09       0.0999   \n",
       "191         logistic        0.01         0.09       0.0999   \n",
       "192         logistic        0.01         0.09         0.45   \n",
       "193         logistic        0.01         0.09         0.45   \n",
       "194         logistic        0.01         0.09         0.45   \n",
       "195         logistic        0.01         0.09        0.999   \n",
       "196         logistic        0.01         0.09        0.999   \n",
       "197         logistic        0.01         0.09        0.999   \n",
       "198         logistic        0.01         0.45       0.0999   \n",
       "199         logistic        0.01         0.45       0.0999   \n",
       "200         logistic        0.01         0.45       0.0999   \n",
       "201         logistic        0.01         0.45         0.45   \n",
       "202         logistic        0.01         0.45         0.45   \n",
       "203         logistic        0.01         0.45         0.45   \n",
       "204         logistic        0.01         0.45        0.999   \n",
       "205         logistic        0.01         0.45        0.999   \n",
       "206         logistic        0.01         0.45        0.999   \n",
       "207         logistic        0.01          0.9       0.0999   \n",
       "208         logistic        0.01          0.9       0.0999   \n",
       "209         logistic        0.01          0.9       0.0999   \n",
       "210         logistic        0.01          0.9         0.45   \n",
       "211         logistic        0.01          0.9         0.45   \n",
       "212         logistic        0.01          0.9         0.45   \n",
       "213         logistic        0.01          0.9        0.999   \n",
       "214         logistic        0.01          0.9        0.999   \n",
       "215         logistic        0.01          0.9        0.999   \n",
       "\n",
       "    param_hidden_layer_sizes  \\\n",
       "0                          1   \n",
       "1                         10   \n",
       "2                        100   \n",
       "3                          1   \n",
       "4                         10   \n",
       "5                        100   \n",
       "6                          1   \n",
       "7                         10   \n",
       "8                        100   \n",
       "9                          1   \n",
       "10                        10   \n",
       "11                       100   \n",
       "12                         1   \n",
       "13                        10   \n",
       "14                       100   \n",
       "15                         1   \n",
       "16                        10   \n",
       "17                       100   \n",
       "18                         1   \n",
       "19                        10   \n",
       "20                       100   \n",
       "21                         1   \n",
       "22                        10   \n",
       "23                       100   \n",
       "24                         1   \n",
       "25                        10   \n",
       "26                       100   \n",
       "27                         1   \n",
       "28                        10   \n",
       "29                       100   \n",
       "..                       ...   \n",
       "186                        1   \n",
       "187                       10   \n",
       "188                      100   \n",
       "189                        1   \n",
       "190                       10   \n",
       "191                      100   \n",
       "192                        1   \n",
       "193                       10   \n",
       "194                      100   \n",
       "195                        1   \n",
       "196                       10   \n",
       "197                      100   \n",
       "198                        1   \n",
       "199                       10   \n",
       "200                      100   \n",
       "201                        1   \n",
       "202                       10   \n",
       "203                      100   \n",
       "204                        1   \n",
       "205                       10   \n",
       "206                      100   \n",
       "207                        1   \n",
       "208                       10   \n",
       "209                      100   \n",
       "210                        1   \n",
       "211                       10   \n",
       "212                      100   \n",
       "213                        1   \n",
       "214                       10   \n",
       "215                      100   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'activation': 'relu', 'alpha': 1e-05, 'beta_1...          -0.000679   \n",
       "1    {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.568394   \n",
       "2    {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.542235   \n",
       "3    {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.419023   \n",
       "4    {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.358384   \n",
       "5    {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.455817   \n",
       "6    {'activation': 'relu', 'alpha': 1e-05, 'beta_1...          -0.000680   \n",
       "7    {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.621309   \n",
       "8    {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.589365   \n",
       "9    {'activation': 'relu', 'alpha': 1e-05, 'beta_1...          -0.000679   \n",
       "10   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.316348   \n",
       "11   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...          -0.526109   \n",
       "12   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...          -0.000679   \n",
       "13   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.605096   \n",
       "14   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.516889   \n",
       "15   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.528317   \n",
       "16   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.225869   \n",
       "17   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.385826   \n",
       "18   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.391688   \n",
       "19   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.183809   \n",
       "20   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.503026   \n",
       "21   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...          -0.000679   \n",
       "22   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.643782   \n",
       "23   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.498196   \n",
       "24   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...          -0.000679   \n",
       "25   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...          -0.000786   \n",
       "26   {'activation': 'relu', 'alpha': 1e-05, 'beta_1...           0.337610   \n",
       "27   {'activation': 'relu', 'alpha': 0.0001, 'beta_...          -0.000679   \n",
       "28   {'activation': 'relu', 'alpha': 0.0001, 'beta_...           0.566000   \n",
       "29   {'activation': 'relu', 'alpha': 0.0001, 'beta_...           0.560032   \n",
       "..                                                 ...                ...   \n",
       "186  {'activation': 'logistic', 'alpha': 0.001, 'be...           0.225904   \n",
       "187  {'activation': 'logistic', 'alpha': 0.001, 'be...           0.167175   \n",
       "188  {'activation': 'logistic', 'alpha': 0.001, 'be...           0.124818   \n",
       "189  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.423547   \n",
       "190  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.172333   \n",
       "191  {'activation': 'logistic', 'alpha': 0.01, 'bet...          -0.669107   \n",
       "192  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.153590   \n",
       "193  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.423487   \n",
       "194  {'activation': 'logistic', 'alpha': 0.01, 'bet...          -0.381598   \n",
       "195  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.212963   \n",
       "196  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.066047   \n",
       "197  {'activation': 'logistic', 'alpha': 0.01, 'bet...          -0.568253   \n",
       "198  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.043432   \n",
       "199  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.145483   \n",
       "200  {'activation': 'logistic', 'alpha': 0.01, 'bet...          -0.260425   \n",
       "201  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.519481   \n",
       "202  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.351665   \n",
       "203  {'activation': 'logistic', 'alpha': 0.01, 'bet...          -0.120773   \n",
       "204  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.362255   \n",
       "205  {'activation': 'logistic', 'alpha': 0.01, 'bet...          -0.007599   \n",
       "206  {'activation': 'logistic', 'alpha': 0.01, 'bet...          -0.400241   \n",
       "207  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.556223   \n",
       "208  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.045437   \n",
       "209  {'activation': 'logistic', 'alpha': 0.01, 'bet...          -0.045824   \n",
       "210  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.254007   \n",
       "211  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.079831   \n",
       "212  {'activation': 'logistic', 'alpha': 0.01, 'bet...          -0.229664   \n",
       "213  {'activation': 'logistic', 'alpha': 0.01, 'bet...           0.151517   \n",
       "214  {'activation': 'logistic', 'alpha': 0.01, 'bet...          -0.030211   \n",
       "215  {'activation': 'logistic', 'alpha': 0.01, 'bet...          -0.338133   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            -0.000955          -0.000197          -0.000285   \n",
       "1             0.416887           0.516952           0.358329   \n",
       "2             0.438345           0.536051           0.564247   \n",
       "3            -0.000065          -0.000197          -0.000283   \n",
       "4             0.534117           0.600962           0.586689   \n",
       "5             0.514723           0.529652           0.596713   \n",
       "6            -0.000062          -0.000197          -0.000283   \n",
       "7             0.347340           0.677044           0.174573   \n",
       "8             0.557053           0.605290          -0.013030   \n",
       "9            -0.000065           0.574802           0.466454   \n",
       "10            0.461029           0.339703           0.399389   \n",
       "11            0.563428           0.365656           0.264468   \n",
       "12           -0.010453          -0.000197          -0.000283   \n",
       "13            0.484344           0.497515           0.604554   \n",
       "14            0.434087           0.578734           0.586358   \n",
       "15           -0.000065          -0.056537          -0.000283   \n",
       "16            0.268105           0.342866           0.492851   \n",
       "17            0.600649           0.417614          -0.055982   \n",
       "18           -0.000065           0.594855          -0.000283   \n",
       "19            0.224638           0.447349           0.615200   \n",
       "20            0.324854           0.061845           0.461268   \n",
       "21           -0.000065          -0.000197          -0.000283   \n",
       "22            0.577708           0.308512           0.457770   \n",
       "23            0.585153           0.470974           0.664484   \n",
       "24           -0.000065          -0.085200          -0.000283   \n",
       "25            0.173680           0.585123           0.588692   \n",
       "26            0.605080           0.313146           0.384422   \n",
       "27           -0.000065          -0.000197          -0.000283   \n",
       "28            0.256176           0.462518           0.456481   \n",
       "29            0.636366           0.406072           0.593818   \n",
       "..                 ...                ...                ...   \n",
       "186           0.300920           0.190479           0.126858   \n",
       "187          -0.116197          -0.149911           0.551768   \n",
       "188          -0.111816          -0.844661          -0.236850   \n",
       "189           0.386131           0.372585          -0.011616   \n",
       "190           0.294165           0.492977           0.065625   \n",
       "191          -0.072648          -0.105602          -0.069565   \n",
       "192           0.255393           0.561062           0.581400   \n",
       "193           0.165694           0.324389          -0.035147   \n",
       "194          -0.242231          -0.316950           0.135364   \n",
       "195           0.132877           0.384690          -0.042726   \n",
       "196           0.247887          -0.187219           0.164008   \n",
       "197          -0.282688          -0.189196          -0.309873   \n",
       "198           0.284608           0.154819          -0.018996   \n",
       "199           0.104022           0.048288           0.261131   \n",
       "200          -0.716915          -0.002649          -0.395580   \n",
       "201           0.249343           0.048901           0.163429   \n",
       "202           0.558687           0.072299           0.314576   \n",
       "203          -0.107591          -0.571167           0.543034   \n",
       "204           0.497441           0.189943           0.076684   \n",
       "205           0.541070           0.445922           0.499152   \n",
       "206          -0.138285          -0.803022          -0.451992   \n",
       "207          -0.030651          -0.002011           0.322076   \n",
       "208           0.467813           0.175126          -0.033847   \n",
       "209          -0.473705           0.553445          -0.256951   \n",
       "210           0.278073           0.086041           0.471047   \n",
       "211           0.257197           0.280319           0.394828   \n",
       "212          -0.164963          -0.419449          -0.616677   \n",
       "213           0.553421           0.270664           0.538154   \n",
       "214           0.127306           0.398127           0.361919   \n",
       "215          -0.579269          -0.592183          -0.525839   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            -0.000036        -0.000430        0.000337              170  \n",
       "1             0.532417         0.478596        0.078363               18  \n",
       "2             0.632739         0.542723        0.062459                5  \n",
       "3             0.499855         0.183667        0.226613              116  \n",
       "4             0.338011         0.483632        0.112985               17  \n",
       "5             0.094028         0.438187        0.177826               34  \n",
       "6            -0.000036        -0.000252        0.000232              162  \n",
       "7             0.567382         0.477530        0.188300               20  \n",
       "8             0.632379         0.474211        0.244837               23  \n",
       "9            -0.000036         0.208095        0.257472              105  \n",
       "10            0.592049         0.421704        0.098880               39  \n",
       "11            0.582646         0.250018        0.406158               87  \n",
       "12           -0.000036        -0.002330        0.004067              172  \n",
       "13           -0.000038         0.438294        0.225046               33  \n",
       "14            0.590813         0.541376        0.059956                6  \n",
       "15           -0.000036         0.094279        0.218116              138  \n",
       "16            0.579586         0.381855        0.134319               49  \n",
       "17            0.397909         0.349203        0.217160               58  \n",
       "18           -0.000036         0.197232        0.250108              107  \n",
       "19            0.627052         0.419610        0.187442               40  \n",
       "20            0.519221         0.374043        0.170416               51  \n",
       "21            0.591422         0.118040        0.236691              132  \n",
       "22            0.552013         0.507957        0.116234                9  \n",
       "23            0.611746         0.566111        0.071814                3  \n",
       "24           -0.000036        -0.017253        0.033974              173  \n",
       "25            0.574219         0.384186        0.249330               48  \n",
       "26            0.220161         0.372084        0.128205               53  \n",
       "27            0.311229         0.062001        0.124614              152  \n",
       "28            0.602275         0.468690        0.120552               25  \n",
       "29            0.616351         0.562528        0.082235                4  \n",
       "..                 ...              ...             ...              ...  \n",
       "186           0.127980         0.194428        0.065312              109  \n",
       "187          -0.002701         0.090027        0.256068              141  \n",
       "188          -0.092053        -0.232112        0.327636              190  \n",
       "189           0.118496         0.257829        0.172689               82  \n",
       "190           0.526709         0.310362        0.178530               66  \n",
       "191          -0.257210        -0.234826        0.227777              191  \n",
       "192           0.422800         0.394849        0.167847               46  \n",
       "193           0.159763         0.207637        0.156982              106  \n",
       "194          -0.436492        -0.248382        0.202550              194  \n",
       "195           0.247285         0.187018        0.140778              114  \n",
       "196           0.278121         0.113769        0.167567              134  \n",
       "197          -0.140361        -0.298074        0.148392              203  \n",
       "198           0.321410         0.157054        0.132054              121  \n",
       "199           0.223766         0.156538        0.077534              123  \n",
       "200          -0.022913        -0.279696        0.263687              201  \n",
       "201           0.644915         0.325214        0.222813               61  \n",
       "202           0.127839         0.285013        0.173300               74  \n",
       "203          -0.143270        -0.079953        0.356607              180  \n",
       "204           0.067813         0.238827        0.167356               92  \n",
       "205          -0.081272         0.279455        0.267187               77  \n",
       "206           0.532213        -0.252265        0.445762              195  \n",
       "207           0.010982         0.171324        0.231267              117  \n",
       "208          -0.471861         0.036534        0.306172              156  \n",
       "209           0.575279         0.070449        0.425430              149  \n",
       "210           0.043209         0.226476        0.152672               98  \n",
       "211           0.241575         0.250750        0.100967               86  \n",
       "212          -0.248550        -0.335861        0.163678              208  \n",
       "213           0.109198         0.324591        0.188271               62  \n",
       "214           0.403895         0.252207        0.174183               84  \n",
       "215          -0.301016        -0.467288        0.123202              215  \n",
       "\n",
       "[216 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = GridSearchCV(ann, grid_params[\"ann\"], cv=5, n_jobs=-1, scoring=make_scorer(r2_score), iid=False)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"\\n\\n ann grid: \\n\\n\")\n",
    "display(pd.DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "from plotter import plot3d_approximation\n",
    "\n",
    "if X_train.shape[1] == 1:\n",
    "    plt.plot(X_train, clf.predict(X_train), \"x\", X_train, y_train, \"o\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(X_val, clf.predict(X_val), \"x\", X_val, y_val, \"o\")\n",
    "    plt.show()\n",
    "    \n",
    "elif X_train.shape[1] == 2:\n",
    "    plot3d_approximation(X_train.T, y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.8771\n",
       "                \n",
       "                    &plusmn; 0.0362\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.5016\n",
       "                \n",
       "                    &plusmn; 0.0303\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0516\n",
       "                \n",
       "                    &plusmn; 0.0096\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.77%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0163\n",
       "                \n",
       "                    &plusmn; 0.0072\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x8\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.97%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0127\n",
       "                \n",
       "                    &plusmn; 0.0023\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.08%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0107\n",
       "                \n",
       "                    &plusmn; 0.0027\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0080\n",
       "                \n",
       "                    &plusmn; 0.0044\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x7\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0062\n",
       "                \n",
       "                    &plusmn; 0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0027\n",
       "                \n",
       "                    &plusmn; 0.0018\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(forest, random_state=1).fit(X_val, y_val)\n",
    "eli5.show_weights(perm) #feature_names=features.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "base_path = \"/home/ubuntu/Downloads/pypsa/examples/ieee-13/ieee-13-with-load-gen-uniform-data-100000-samples/results/\"\n",
    "foo = pd.read_csv(base_path + \"approximating_with_dnn_results-100_samples-2019-09-12-04-36.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
